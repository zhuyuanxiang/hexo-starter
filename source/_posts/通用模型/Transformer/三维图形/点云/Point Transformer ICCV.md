---
title: Point Transformer
excerpt: 
categories:
  - 点云特征
tags:
  - Point Cloud
  - Transformer
  - ScanNet
  - S3DIS
  - ModelNet40
date: 2023-12-20
updated: 
toc: true
typora-root-url: D:\Projects\Github\zhuyuanxiang\hexo_pages\hexo-starter\source\_posts\
---

# Point Transformer

Bibtex：Zhao H, Jiang L, Jia J, et al. Point transformer[C]//Proceedings of the IEEE/CVF international conference on computer vision. 2021: 16259-16268.

[原始论文](http://openaccess.thecvf.com/content/ICCV2021/papers/Zhao_Point_Transformer_ICCV_2021_paper.pdf)

[中文翻译](medias/通用模型/Transformer/三维图形/Point%20Transformer%20ICCV.pdf)

[原始代码_PyTorch](https://github.com/POSTECH-CVLab/point-transformer)

# 摘要

自注意力网络已经彻底改变了自然语言处理技术，并在图像分类和目标检测等图像分析任务上取得了令人印象深刻的进步。受此成功的启发，我们研究了自注意力网络在 3D 点云处理中的应用。我们为点云设计了自注意力层，并利用这些层来构建用于语义场景分割、目标部件分割和目标分类等任务的自注意力网络。我们的 Point Transformer 设计改进了先前的跨领域和跨任务的工作。例如，在具有挑战性的大规模语义场景分割的 S3DIS 数据集上， Point Transformer 在 Area 5上的 mIoU 为 $70.4\%$，比最强的先验模型高出 $3.3$ 个绝对百分点，并首次超过了 $70\%$ 的 mIoU 阈值。

![图1](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20ICCV/image-20231220181630778.png)

图1：Point Transformer 可以作为各种 3D 点云理解任务的骨干网，如：对象分类、对象部件分割和语义场景分割。

# Ch01 简介

 3D 数据出现在许多应用领域，如：自动驾驶、增强现实和机器人技术。与排列在规则像素栅格上的图像不同， 3D 点云被嵌入在连续的空间中。这使得 3D 点云在结构上与图像不同，也就无法立即应用那些在计算机视觉中已经成为设计标准的深度网络，如：基于离散卷积算子设计的网络。

为了应对这一挑战，已经出现了各种关于 3D 点云的深度学习的方法。一些体素化的 3D 空间对 3D 离散卷积的应用[^23,32]。这导致了大量的计算和内存成本，并没有充分利用 3D 点集的稀疏性。稀疏卷积网络通过只操作非空的体素来缓解这些限制[^9,3]。其他设计直接对点进行操作，并通过池化运算符[^25,27]或连续卷积[^42,37]传播信息。另一种方法将点集连接成一个用于传递消息的图[^44,19]。

在本文中，我们开发了一种用于点云的深度学习方法，这种方法是受到 Transformer 在自然语言处理[^39,45,5,4,51]和图像分析[^10,28,54]中成功应用的启发。 Transformer 模型特别适用于点云处理，因为作为 Transformer 网络核心的自注意力算子本质上是一个集合算子：它对输入元素的排列和基数是不变的。因此，对于嵌入在 3D 空间中的 3D 点云的应用也是相当自然的。

我们发展了这种直觉，开发了一个用于 3D 点云处理的自注意力层。在此基础上，我们构建了用于各种 3D 理解任务的 Point Transformer 网络。我们研究了自注意力算子的形式、自注意力在每个点周围的局部邻域上的应用，以及在网络中编码位置信息的方式。由此产生的网络纯粹是基于自注意力，并且逐点计算的。

我们证明了， Point Transformer 在 3D 深度学习任务中非常有效，无论是在详细的对象分析和大规模场景的大规模解析的水平上。特别是， Point Transformer 在 S3DIS 数据集的大规模语义分割问题（区域5的$70.4\%$）、在 ModelNet 40 数据集的形状分类问题（总体准确率$93.7\%$）和在 ShapeNetPart 数据集的对象部件分割问题（实例mIoU的$86.6\%$）取得了新的进展。我们的全部实现和训练的模型将在论文接受后发布。概括起来，我们的主要贡献包括以下内容：

- 我们设计了一个表现能力强的点云处理的 Point Transformer 层。该层对集合的排列和基数保持不变的，因此本质上是满足点云处理的需要。
- 在 Point Transformer 层的基础上，构建了高性能的 Point Transformer 网络，用于点云的分类和稠密预测。这些网络可以作为 3D 场景理解的通用骨干网。
- 我们报告了在多个领域和数据集上的广泛实验。我们进行了控制研究，以检测 Point Transformer 设计中的具体选择，并在多个高度竞争的基准上设置新的标准，结果优于之前的长期工作。

# Ch02 相关工作

为了理解 2D 图像，像素被放置在规则的栅格中，并且可以用经典的卷积进行处理。相比之下， 3D 点云在 3D 空间中是无序和分散的：它们本质上属于集合。基于学习的处理 3D 点云的网络可以分为以下几种类型：基于投影、基于体素和基于点。

## 基于投影的网络

对于处理像点云这样的不规则输入，一种直观的方法是将不规则表示转换为规则表示。考虑到 2D CNN 的成功，一些方法[^34,18,2,14,16]采用了多视图投影，即将 3D 点云投影到不同的图像平面上。然后利用 2D CNN 提取这些图像平面上的特征表示，然后进行多视图特征融合，形成最终的输出表示。在一种相关的方法中， TangentConv[^35] 将局部表面几何图形投影到每个点的切线平面上，形成可以通过 2D 卷积处理的切线图像。然而，这种方法严重依赖于切线估计。在基于投影的框架中，点云内部的几何信息在投影阶段被重叠。当在投影平面上形成稠密的像素栅格时，这些方法也可能没有充分利用点云的稀疏性。投影平面的选择可能会严重影响 3D 识别的性能，而遮挡可能会影响 3D 识别的精度。

## 基于体素的网络

将不规则点云转换为规则表示的另一种方法是 3D 体素化[^23,32]，然后再对其 3D 卷积。由于体素数量是分辨率的三次方增长，当在应用中只使用其基础功能时，这种策略可能会导致大量的计算和内存成本。解决方案是利用稀疏性，因为大多数体素通常是不被占用的。例如，OctNet [^29]使用带有分层分区的不平衡八叉树。基于稀疏卷积的方法，其中卷积核只在被占用的体素上进行计算，可以进一步减少计算和内存需求[^9,3]。这些方法已经证明了其良好的精度，但仍有可能因为在体素网格上的量化而失去几何细节。

## 基于点的网络

相比投影或量化到 2D 或 3D 的规则栅格上，研究人员设计了深度网络结构用于直接吸收不规则的点云，将之嵌入在连续空间中。PointNet [^25]利用具有排列不变性的算子，如：点态 MLP 和池化层（Pooling）来聚合一个集合中的特征。PointNet++ [^27]将这些想法应用于一个分层的空间结构中，以增加对局部几何结构的敏感性。这种模型受益于点集的有效采样，[^27,7,46,50,11]已经开发了多种采样策略。

许多方法将点集连接到一个图中，并在这个图上进行消息传递。DGCNN [^44]对kNN图进行图卷积。PointWeb[^55]稠密地连接局部邻域点。ECC [^31]使用动态的边界条件滤波器，其中卷积核是基于点云内部的边生成的。SPG [^15]在一个表示上下文关系的超点图上进行操作。KCNet [^30]利用了核的相关性和图池化函数。Wang等人[^40]研究了局部的谱的图卷积。GACNet [^41]采用了图注意力卷积，HPEIN [^13]构建了一个层次化的点-边交互架构。DeepGCNs [^19]探索了图卷积网络的深度在 3D 场景理解中的优势。

许多方法是基于连续卷积，并且直接应用于没有量化的 3D 点集上。PCCN [^42] 将卷积内核表示为 MLP。SpiderCNN [^49] 将核权值定义为一类多项式函数。球面 CNN [^8] 设计了球面卷积来解决 3D 旋转的同变性问题（变化相等）。PointConv[^46] 和 KPConv [^37] 基于输入坐标构造卷积权值。InterpCNN[^22] 利用坐标来插值点态的核权重值。PointCNN[^20] 提出了用特殊算子对输入的无序点云重新排序。Ummenhofer等人[^38]应用连续卷积来学习基于粒子的流体力学。

## Transformer 和自注意力

Transformer 和自注意力模型已经彻底改变了机器翻译和自然语言处理[^39,45,5,4,51]。这启发了自注意力网络在 2D 图像识别中的发展[^10,28,54,6]。Hu等人[^10]和Ramachandran等人[^28]在局部图像块中应用标量点积自注意力。Zhao等人[^54]开发了一个向量自注意力算子族。Dosovitskiy等人[^6]将图像视为图像块序列。

我们的工作受到以下发现的启发：Transformer 和自注意力网络的性能可以在序列数据和 2D 图像上达到甚至超越卷积网络。自注意力在我们的设置中具有特别有趣的性质，因为它本质上是一个集合运算符：作为集合进行处理的元素提供了位置信息这种属性[^39,54]。因为 3D 点云本质上是具有位置属性的点集，所以自注意力机制似乎特别适合于这种类型的数据。因此，我们开发了一个 Point Transformer 层，应用自注意力的 3D 点云。

以前有许多工作[^48,21,50,17]是利用注意力来进行点云分析。它们将全局注意力应用于整个点云，结果引入了大量的计算，使这些方法不适用于大规模的 3D 场景理解。它们还利用标量点积注意力，其中不同的通道共享相同的聚合权重值。相比之下，我们在局部应用自注意力，从而在具有数百万个点的大型场景中具有扩展性，还使用了向量注意力机制，并且展示了这种机制对于获得高精度的重要性。我们还演示了适当的位置编码在大规模点云理解中的重要性，因为以前的方法省略了位置信息。总的来说，我们证明了适当设计的自注意力网络可以扩展到大尺度并且复杂的 3D 场景，并能大大提高大规模点云理解的技术水平。

# Ch03 Point Transformer

首先，我们简要地回顾了 Point Transformer 和自注意力算子的通用公式。然后，提出了用于 3D 点云处理的 Point Transformer 层。最后，提出了用于 3D 场景理解的网络架构。

## 3.1. 背景

Transformer 和自注意力网络已经彻底改变了自然语言处理的方式[^39,45,5,4,51]，并在 2D 图像分析[^10,28,54,6]中显示出了令人印象深刻的结果。自注意力算子可分为两种类型：标量注意力[^39]和向量注意力[^54]。

设 $\mathcal{X}=\{\mathbf{x}_i\}_i$ 是一组特征向量。标准的标量点积注意力层可以表示如下：
$$
\begin{equation}
\mathbf{y}_i=\sum_{\mathbf{x}_j\in\mathcal{X}}
\rho(\varphi(\mathbf{x}_i)^\top\psi(\mathbf{x}_j)+\delta)\alpha(\mathbf{x}_j)
\end{equation}
$$
其中，$\mathbf{y}_i$是输出特征；$\varphi,\psi,\alpha$是点态特征变换函数（如：线性投影或者 MLP）；$\delta$是位置编码函数；$\rho$是归一化函数（如：softmax）。标量注意力层计算两个输出特征（通过$\varphi,\psi$变换输出的特征）的标量积，并且使用这个标量积作为注意力权重值来聚合另一个输出的特征（通过$\alpha$变换输出的特征）。

在向量注意力中，注意力权重值的计算有所不同。特别是，注意力权重值是可以调制混合独立的特征通道的*向量*：
$$
\begin{equation}
\mathbf{y}_i=\sum_{\mathbf{x}_j\in\mathcal{X}}
\rho(\gamma(\beta(\varphi(\mathbf{x}_i),\psi(\mathbf{x}_j))+\delta))\odot\alpha(\mathbf{x}_j)
\end{equation}
$$
其中，$\beta$是关系函数（如：减法）；$\gamma$是映射函数（如：MLP），用于输出注意力向量用于特征聚合。

标量自注意力与向量自注意力都是集合算子。这个集合可以成为表示完整信号（如：语句或者图像）的特征向量的合集[^39,6]或者表示信号内部局部片段（如：图像块）的特征向量的合集[^10,28,54]。

## 3.2. Point Transformer 层

自注意力是点云的自然匹配，因为点云本质上是不规则地嵌入在度量空间中的集合。我们的 Point Transformer 层是基于向量自注意力的。我们使用减法关系，并在注意力向量$γ$和转换向量$α$上添加一个位置编码$δ$：
$$
\begin{equation}
\mathbf{y}_i=\sum_{\mathbf{x}_j\in\mathcal{X}}
\rho(\gamma(\varphi(\mathbf{x}_i)-\psi(\mathbf{x}_j)+\delta)\odot(\alpha(\mathbf{x}_j)+\delta)
\end{equation}
$$
这里的子集$\mathcal{X}(i)⊆\mathcal{X}$是一个在$\mathbf{x}_i$的局部邻域（特别是$k$个最近邻）中的点集合。因此，在每个数据点的局部邻域中，我们采用了最新的自注意力网络进行图像分析[^10,28,54]。映射函数$γ$是一个具有两个线性层和一个非线性 ReLU 的 MLP。 Point Transformer 层如图2所示。

![图2](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20ICCV/image-20231220181526350.png)

图2：Point Transformer 层

## 3.3. 位置编码

位置编码在自注意力中起着重要的作用，使得算子能够适应数据中的局部结构[^39]。用于序列数据和图像栅格的标准的位置编码方案是手工制作的，例如：基于正弦函数和余弦函数或归一化的范围值[^39,54]。在 3D 点云处理中， 3D 点坐标本身就是位置编码的自然候选对象。我们通过引入可训练的、参数化的位置编码来超越这个候选对象。我们的位置编码函数 $δ$ 的定义如下：
$$
\begin{equation}
\delta=\theta(\mathbf{p}_i-\mathbf{p}_j)
\end{equation}
$$
这里的 $\mathbf{p}_i$ 和 $\mathbf{p}_j$ 是点 $i$ 和点 $j$ 的 3D 点坐标。编码函数 $θ$ 是一个具有两个线性层和一个非线性 ReLU 的 MLP。值得注意的是，我们发现位置编码对于注意力生成分支和特征转换分支都很重要。因此，等式(3)在这两个分支中都添加了可训练的位置编码。将位置编码的 $θ$ 与其他子网一起进行端到端训练。

## 3.4. Point Transformer 块

如图4(a)所示，我们构造了一个核心为 Point Transformer 层的残差 Point Transformer 块。该 Point Transformer 块集成了自注意力层、线性投影（降维和加速处理）和一个残差连接。输入是包含相关的 3D 坐标 $\mathbf{p}$ 的特征向量 $\mathbf{x}$ 的集合。Point Transformer 块促进了这些局部化的特征向量之间的信息交换，用于所有数据点产生新的特征向量作为其输出。信息聚合同时适应了特征向量的内容和其在 3D 空间中的结构。

## 3.5. 网络结构

基于 Point Transformer 块，构造了完整的 3D 点云理解网络。请注意，Point Transformer 是整个网络中的主要特征聚合算子。我们的网络不在预处理分支或辅助分支中使用卷积：即网络完全基于 Point Transformer 层、点态变换和池化（网络架构如图3所示）。

![图3](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20ICCV/image-20231221095034953.png)

图3：用于语义分割（上）和分类（下）的 Point Transformer 的网络。

### 骨干网络结构

在 Point Transformer 网络中，用于语义分割和分类的特征编码器有五个阶段，它们可以对点集进行逐步降采样的操作。各阶段的降采样率为 $[1,4,4,4,4]$，因此每个阶段产生的点集的基数为 $[N, N/4, N/16, N/64, N/256]$，其中 $N$ 为输入点的个数。请注意，阶段的数量和降采样率可以根据应用程序的需要而变化，例如去构建用于快速处理的轻量级骨干网。连续的阶段通过转换模块连接：向下转换用于特征编码，向上转换用于特征解码。

### 向下转换

向下转换模块的一个关键功能是根据需要降低点集的基数，例如从第一阶段到第二阶段的转换过程中，点集的基数从 $N$ 降低到 $N/4$。在转换模块中，假设输入点集表示是 $P_1$，输出点集表示是 $P_2$。我们在 $P_1$ 中执行最远点采样[^27]，以确定一个具有必要基数的，并且具有良好分布的子集 $P_2⊂P_1$。为了将特征向量从 $P_1$ 汇集到 $P_2$ 上，我们在 $P_1$ 上使用了一个 $k$NN 图。(这与[第3.2节]中的 $k$ 相同。我们在整个过程中使用 $k = 16$，并在[第4.4节]中报告了该超参数的对照研究)。每个输入特征都经过一个线性变换，然后是批归一化和 ReLU，然后是从 $P_1$ 中的 $k$ 个邻居到 $P_2$ 中的每个点上的最大池化。向下转换模块如图4(b)所示。

### 向上转换

对于语义分割等稠密数据的预测任务，我们采用 U-Net 设计，其中编码器（上小节描述的）与解码器（与编码器对称的）耦合[^27,3]。解码器中的连续阶段由“向上转换”模块连接。它们的主要功能是将特征从降采样的输入点集 $P_2$ 映射到其超集 $P_1⊃P_2$上。为此，每个输入点的特征都通过线性层处理，然后进行批归一化和 ReLU，再通过三线性插值将特征映射到更高分辨率的点集 $P_1$上。这些来自前一个解码器阶段的插值特征与相应的编码器阶段通过跳跃连接提供的特征进行汇总。向上转换模块的结构如图4(c)所示。

![图4](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20ICCV/image-20231221103337071.png)

图4：细化的每个模块的设计结构。

### 输出头

对于语义分割，在解码器的最后阶段为输入点集中的每个点产生一个特征向量。我们应用一个 MLP 来将这个特征映射到最终的 logits 概率。对于分类问题，我们对点态特征执行全局平均池化，得到整个点集的全局特征向量。这个全局特征通过一个 MLP 来获得全局分类的 logits 概率。

# Ch04 实验

我们评估了所提出的 Point Transformer 设计在许多领域和任务上的有效性。对于 3D 语义分割，我们使用了具有挑战性的斯坦福大规模三维室内空间（S3DIS）数据集[^1]。对于 3D 形状分类，我们基于的是广泛采用的 ModelNet40 数据集[^47]。对于对象部件分割分割，我们基于的是 ShapeNetPart[^52]。

### 实现细节

我们在PyTorch [^24]中实现了 Point Transformer 。使用 SGD 优化器，动量和权重衰减分别设置为 `momentum=0.9` 和 `weight_decay=0.0001`。对于 S3DIS 上的语义分割，我们训练了 $40K$ 次迭代，初始学习率为 `lr=0.5`，在步骤 $24K$ 和 $32K$ 时下降了 $10$ 倍。对于 ModelNet40 上的 3D 形状分类和 ShapeNetPart 上的 3D 对象部件分割，我们训练了 $200$ 个迭代。初始学习率设置为 `lr=0.05`，在第 $120$ 个迭代和第 $160$ 个迭代时下降了 $10$ 倍。

## 4.1. 语义分割

### 数据和评估

用于语义场景解析的 S3DIS [^1] 数据集由来自三个不同建筑的 $6$ 个区域的 $271$ 个房间组成。扫描中的每个点都从 $13$ 个类别（天花板、地板、桌子等）中分配了一个语义标签。遵循一个通用的协议[^36,27]，我们以两种模式来评估所提出的方法： (a) Area 5在训练期间被保留，用于测试，以及(b) $6$ 倍交叉验证。对于评估指标，我们使用平均类间联合交集（mean class-wise Intersection over Union, mIoU）、类间精度的平均值（mean of class-wise Accuracy, mAcc）和总体点态精度（Overall pointwise Accuracy, OA）。

### 性能比较

结果如表1和表2所示。在两种评估模式下， Point Transformer 在所有指标上都优于先前模型。在Area 5条件下， Point Transformer 的 mIoU/mAcc/OA 分别达到 $70.4\%/76.5\%/90.8\%$，在每个指标上比先前的工作都多出了多个百分点。 Point Transformer 是第一个通过 $70\%$ mIoU 的模型，在 mIoU 中比先前的技术水平高出了 $3.3$ 个绝对百分点。 Point Transformer 的性能优于基于 MLP 的框架（如：PointNet[^25]），基于体素的架构（如：SegCloud [^36]），基于图的方法（如：SPGraph [^15]），基于注意力的方法（如：PAT [^50]），稀疏卷积网络（如：MinkowskiNet[^3]），以及连续卷积网络（如：KPConv [^37]）。在 $6$ 倍交叉验证下， Point Transformer 的性能也大大优于所有之前的模型。这种模式下的 mIoU 为 $73.5\%$，比之前的最优模型（KPConv）高出 $2.9$ 个绝对百分点。 Point Transformer 中的参数数量（4.9M）比目前的高性能架构（如：KPConv（14.9M）和 SparseConv（30.1M））要小得多。

![表1](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20ICCV/image-20231221113514110.png)

表1：在 S3DIS 数据集上，评价 Area 5 的语义分割结果。

![表2](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20ICCV/image-20231221113554895.png)

表2：在 S3DIS 数据集上，评估 $6$ 倍交叉验证的语义分割结果。

### 可视化

Point Transformer 的预测（图5所示）可以看出其非常接近于基准的真实结果。 Point Transformer 在复杂的 3D 场景中捕捉详细的语义结构，如：椅子的腿、海报板的轮廓和门口周围的装饰。

![图5](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20ICCV/image-20231221113810467.png)

图5：在 S3DIS 数据集上语义分割结果的可视化。

## 4.2. 形状分类

### 数据和评估

ModelNet40 [^47] 数据集包含 $12,311$ 个 CAD 模型和 $40$ 个对象类别。它们被分成 $9843$ 个模型用于训练，$2468$ 个模型用于测试。我们遵循Qi等人[^27]的数据处理程序，对每个 CAD 模型中的点与对象栅格中的法向量均匀采样。对于评估指标，我们使用每个类别内的平均精度（mAcc）和所有类别内的总体精度（OA）。

### 性能比较

Point Transformer 设置了两个指标的最佳模型（如表3所示）。ModelNet40 上的 Point Transformer 的总体精度为 $93.7\%$，优于基于图的强模型（如：DGCNN [^44]），基于注意力的模型（如：A-SCN [^48]和 Point2Sequence[^21]），以及基于点的强模型（如：KPConv [^37]）。

![表3](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20ICCV/image-20231221133315231.png)

 表3：在 ModelNet40数据集上形状分类的结果。

### 可视化

为了探究 Point Transformer 学习到的表示方式，我们通过检索 Point Transformer 产生的输出特征空间中的最近邻来进行形状检索。图6所示，一些结果表明检索到的形状与查询非常相似；一些结果与查询不同是因为这些结果接收到的语义性显著区别太少（如：桌子的腿）。

![图6](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20ICCV/image-20231221134924293.png)

图6：在 ModelNet40 数据集上获取的形状结果的可视化。最左边展示的是输入查询，其他列展示的是获取的模型。

## 4.3. 对象部件分割

### 数据和评估

ShapeNetPart 数据集[^52]被注释用于 3D 对象部件分割。它包括来自 $16$ 个形状类别的 $16880$ 个 3D 模型，其中 $14006$ 个用于训练，$2874$ 个用于测试。每个类别的零件数量在 $2$ 到 $6$ 个之间，总共有 $50$ 个不同的零件。我们使用Qi等人[^27]产生的采样点集对我们的网络和之前的工作进行公平的比较。对于评估指标，我们报告了类别mIoU和实例mIoU。

### 性能比较

表4所示，Point Transformer 优于所有之前的模型。（请注意，损失平衡可以提高类别mIoU，但是在训练中没有使用。）

![表4](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20ICCV/image-20231221143600759.png)

表4：在 ShapeNetPart 数据集上对象部件分割的结果。

### 可视化

图7所示，在许多模型上的对象部件分割结果中，Point Transformer 的部件分割预测是干净的，并且接近真实的基准结果。

![图7](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20ICCV/image-20231221143851403.png)

图7：在 ShapeNetPart 数据集上对象部件分割结果的可视化。真实的基准结果在顶行，Point Transformer 预测的结果在底行。

## 4.4. 消融研究

我们现在进行一些控制实验，以检查 Point Transformer 在设计中的具体决策。这些研究是在 S3DIS 数据集的语义分割任务上进行的，并在 Area 5 上进行了测试。

### 近邻数量

我们首先研究的是如何设置邻居数 $k$ ，因为 $k$ 是用于确定每个点周围的局部邻域。表5所示：

- 当 $k$ 设置为 $16$ 时，性能最好；
- 当邻域较小时（$k = 4或k = 8$），模型可能没有足够的上下文进行预测，所以精度不高；
- 当邻域较大时（$k = 32或k = 64$），每个自注意力层都有大量的数据点，其中许多数据点可能离目标点更远、更不相关。这可能会在处理过程中引入过多的噪声，从而降低模型的精度。

![表5](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20ICCV/image-20231221144526139.png)

表5：消融研究：邻居数 $k$ 在局部邻域中的定义。

### Softmax正则化

我们对等式(3)中的归一化函数 $ρ$ 进行了消融研究。在 S3DIS 的 Area 5 上不带 softmax 正则化时，网络的性能 m3IoU/mAcc/OA 分别为 $66.5\%/72.8\%/89.3\%$，这个结果远远低于使用 softmax 正则化的性能 $70.4\%/76.5\%90.8\%$。这表明，在这种情况下，归一化是必要的。

### 位置编码

我们现在研究如何选择位置编码函数 $δ$ 。表6所示：

- 如果没有位置编码，性能就会显著下降；
- 采用绝对位置编码时，性能高于无位置编码；
- 当相对位置编码只添加到注意力生成分支时(等式(3)中的第一项)，性能再次下降；
- 当相对位置编码只添加到特征转换分支(在等式(3)中的第二项)，性能再次下降；
- 采用相对位置编码时，性能最好，说明同时向两个分支添加相对位置编码是很重要的。

![表6](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20ICCV/image-20231221155726048.png)

表6：消融研究：位置编码。

### 注意力类型

最后，我们研究了在 Point Transformer 层中使用的自注意力的类型，结果如表7所示。我们研究了四个条件：

1. “MLP”：是无注意力基线。它用点态 MLP 取代了 Point Transformer 块中的 Point Transformer 层。
2. “MLP+池”：是更先进的无注意力基线。在每个 $k$NN邻域中，使用点态 MLP 后跟最大池化取代了 Point Transformer 层：这样保证在每个点都执行了特征变换，使得每个点在其局部邻域内都参与了信息交换，但是没有使用注意力机制。
3. “标量注意力”：通过等式(1)中的标量注意力（原始的 Transformer 设计[^39]）取代了等式(3)中的向量注意力。
4. “向量注意力”：是我们在等式(3)中使用的公式。

通过表7可以看出，“向量注意力”优于“标量注意力”，并且都比无注意力的基线更有表现力。“向量注意力”和“标量注意力”之间的性能差距很显著： $70.4\%$ 对 $64.6\%$，提高了 $5.8$ 个绝对百分点。“向量注意力”更具表现力是因为它可以自适应地调制单个通道的特征，而不仅仅是整个特征向量。这种表现力似乎在 3D 数据处理中非常有效。

![表7](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20ICCV/image-20231221155958789.png)

表7：消融研究：自注意力算子的形式。

# Ch05 结论

Transformer 已经彻底改变了自然语言处理技术，并在 2D 图像分析方面取得了令人印象深刻的进步。受此进展的启发，我们开发了一个针对 3D 点云的 Point Transformer 架构。与语言或图像处理相比，Transformer 处理点云可能更自然，因为点云本质上是嵌入在度量空间中的集合，而 Point Transformer 网络核心的自注意力算子本质上是一个集合算子。我们已经证明，除了这种概念上的兼容性之外，Transformer 在点云处理方面也非常有效，其效果优于来自各种类型的最先进的设计：基于图的模型、稀疏卷积网络、连续卷积网络及其他网络结构。我们希望我们的工作将进一步激发 Point Transformer 的特性研究，新的算子和网络设计的开发，以及 Point Transformer 在其他任务（如： 3D 目标检测）中的应用。

# A. 附录

### 更多详细的结果

在表A.1中，我们展示了在 $6$ 倍交叉验证设置下，S3DIS数据集[^1]上的语义分割结果的详细比较。我们得到的最高 mIoU 为 $73.5\%$，大大优于以前的方法（如：RandLA-Net [^11]和KPConv [^37]）。对于大多数类别（如：墙、柱、台等），我们的方法得到了最好的精度。我们将很快向社区发布所有的实现细节和训练过的模型。

![表A.1.](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20ICCV/image-20231221161938570.png)

表A.1. 在 S3DIS 数据集上使用 $6$ 倍交叉验证评估语义分割结果。

### 推理时间和内存消耗

我们在一个具有不同大小的输入点云的数据集上，基于 Quadro RTX 6000 测试了 Point Transformer 的推理时间和内存消耗。对于 10k/ 20k/ 40k/ 80k 输入点，推理时间为 44ms/ 86ms/ 222ms/ 719ms ，内存消耗为 1702M/ 2064M/ 2800M/ 4266M，并且通过优化还可以进一步减少占用的资源。

### $k$NN的有效性

对于 $k$NN，在构建局部点云区域时，以前的方法（如：KPConv [^37]和 RandLA-Net [^11]）使用了预先计算的 $k$NN 索引，这限制了整个框架的灵活性。在我们的体系结构中，我们使用堆排序算法实现了一个针对 $k$NN 的高效解决方案。我们在一个 Quadro RTX 6000 上测试了我们的高效解决方案的运行时间（结果列在表A.2中）。我们还测试了一些朴素的实现，当给予 10k/ 20k 点时，运行时间是56ms/ 228ms，这比我们的方法要慢得多。此外，当给定的点云较大时，朴素的实现会耗尽内存。

![表A.2.](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20ICCV/image-20231221162046707.png)

表A.2. 利用堆排序算法实现的高效的 $k$NN。最左边的列表示点的数量，最上面的行表示最近的邻居的数量。报告的运行时间以毫秒为单位。
