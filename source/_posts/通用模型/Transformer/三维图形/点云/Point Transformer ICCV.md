---
title: Point Transformer
excerpt: 
categories:
  - 点云特征
tags:
  - Point Cloud
  - Transformer
  - ScanNet
  - S3DIS
  - ModelNet40
date: 2023-12-20
updated: 
toc: true
typora-root-url: D:\Projects\Github\zhuyuanxiang\hexo_pages\hexo-starter\source\_posts\
---

# Point Transformer

Bibtex：Zhao H, Jiang L, Jia J, et al. Point transformer[C]//Proceedings of the IEEE/CVF international conference on computer vision. 2021: 16259-16268.

[原始论文](http://openaccess.thecvf.com/content/ICCV2021/papers/Zhao_Point_Transformer_ICCV_2021_paper.pdf)

[中文翻译]()

[原始代码_PyTorch](https://github.com/POSTECH-CVLab/point-transformer)

TODO：点转换器→ Point Transformer ，点变压器→ Point Transformer ，变压器→ Transformer ，点变形器→ Point Transformer ，二维→2D，三维→3D，逐点→点态

# 摘要

自注意力网络已经彻底改变了自然语言处理技术，并在图像分类和目标检测等图像分析任务上取得了令人印象深刻的进步。受此成功的启发，我们研究了自注意力网络在三维点云处理中的应用。我们为点云设计了自注意力层，并利用这些层来构建用于语义场景分割、目标部件分割和目标分类等任务的自注意力网络。我们的 Point Transformer 设计改进了先前的跨领域和跨任务的工作。例如，在具有挑战性的大规模语义场景分割的 S3DIS 数据集上， Point Transformer 在区域5上的mIoU为$70.4\%$，比最强的先验模型高出$3.3$个绝对百分点，并首次超过了$70\%$的mIoU阈值。

![image-20231220181630778](/%E9%80%9A%E7%94%A8%E6%A8%A1%E5%9E%8B/Transformer/%E4%B8%89%E7%BB%B4%E5%9B%BE%E5%BD%A2/%E7%82%B9%E4%BA%91/images/Point%20Transformer%20ICCV/image-20231220181630778.png)

图1：Point Transformer 可以作为各种 3D 点云理解任务的骨干网，如：对象分类、对象部件分割和语义场景分割。

# Ch01 简介

三维数据出现在许多应用领域，如自动驾驶、增强现实和机器人技术。与排列在规则像素栅格上的图像不同，三维点云被嵌入在连续的空间中。这使得三维点云在结构上与图像不同，也就无法立即应用那些在计算机视觉中已经成为设计标准的深度网络，例如：基于离散卷积算子设计的网络。

为了应对这一挑战，已经出现了各种关于三维点云的深度学习的方法。一些体素化的三维空间对三维离散卷积的应用[23,32]。这导致了大量的计算和内存成本，并没有充分利用三维点集的稀疏性。稀疏卷积网络通过只操作非空的体素来缓解这些限制[9,3]。其他设计直接对点进行操作，并通过池化运算符[25,27]或连续卷积[42,37]传播信息。另一种方法将点集连接成一个用于传递消息的图[44,19]。

在本文中，我们开发了一种用于点云的深度学习方法，这种方法是受到 Transformer 在自然语言处理[39,45,5,4,51]和图像分析[10,28,54]中成功应用的启发。 Transformer 模型特别适用于点云处理，因为作为 Transformer 网络核心的自注意力算子本质上是一个集合算子：它对输入元素的排列和基数是不变的。因此，对于嵌入在 3D 空间中的 3D 点云的应用也是相当自然的。

我们发展了这种直觉，开发了一个用于三维点云处理的自注意层。在此基础上，我们构建了用于各种三维理解任务的点变压器网络。我们研究了自注意力算子的形式、自注意力在每个点周围的局部邻域上的应用，以及在网络中编码位置信息的方式。由此产生的网络纯粹是基于自注意力，并且逐点计算的。

我们证明了，点变形器在三维深度学习任务中非常有效，无论是在详细的对象分析和大规模场景的大规模解析的水平上。特别是，点变形器在 S3DIS 数据集的大规模语义分割问题（区域5的$70.4\%$）、在 ModelNet 40 数据集的形状分类问题（总体准确率$93.7\%$）和在 ShapeNetPart 数据集的对象部件分割问题（实例mIoU的$86.6\%$）取得了新的进展。我们的全部实现和训练的模型将在论文接受后发布。概括起来，我们的主要贡献包括以下内容：

- 我们设计了一个表现能力强的点云处理的 Point Transformer 层。该层对集合的排列和基数保持不变的，因此本质上是满足点云处理的需要。
- 在点变压器层的基础上，构建了高性能的点变压器网络，用于点云的分类和稠密预测。这些网络可以作为 3D 场景理解的通用骨干网。
- 我们报告了在多个领域和数据集上的广泛实验。我们进行了控制研究，以检测点变压器设计中的具体选择，并在多个高度竞争的基准上设置新的标准，结果优于之前的长期工作。

# Ch02 相关工作

为了理解 2D 图像，像素被放置在规则的栅格中，并且可以用经典的卷积进行处理。相比之下，三维点云在三维空间中是无序和分散的：它们本质上属于集合。基于学习的处理三维点云的网络可以分为以下几种类型：基于投影、基于体素和基于点。

## 基于投影的网络

对于处理像点云这样的不规则输入，一种直观的方法是将不规则表示转换为规则表示。考虑到 2D CNN 的成功，一些方法[34,18,2,14,16]采用了多视图投影，即将三维点云投影到不同的图像平面上。然后利用 2D CNN 提取这些图像平面上的特征表示，然后进行多视图特征融合，形成最终的输出表示。在一种相关的方法中， TangentConv[35] 将局部表面几何图形投影到每个点的切线平面上，形成可以通过二维卷积处理的切线图像。然而，这种方法严重依赖于切线估计。在基于投影的框架中，点云内部的几何信息在投影阶段被重叠。当在投影平面上形成稠密的像素栅格时，这些方法也可能没有充分利用点云的稀疏性。投影平面的选择可能会严重影响三维识别的性能，而遮挡可能会影响三维识别的精度。

## 基于体素的网络

将不规则点云转换为规则表示的另一种方法是三维体素化[23,32]，然后再对其三维卷积。由于体素数量是分辨率的三次方增长，当在应用中只使用其基础功能时，这种策略可能会导致大量的计算和内存成本。解决方案是利用稀疏性，因为大多数体素通常是不被占用的。例如，OctNet [29]使用带有分层分区的不平衡八叉树。基于稀疏卷积的方法，其中卷积核只在被占用的体素上进行计算，可以进一步减少计算和内存需求[9,3]。这些方法已经证明了其良好的精度，但仍有可能因为在体素网格上的量化而失去几何细节。

## 基于点的网络

相比投影或量化到 2D 或 3D 的规则栅格上，研究人员设计了深度网络结构用于直接吸收不规则的点云，将之嵌入在连续空间中。PointNet [25]利用具有排列不变性的算子，如：逐点 MLP 和池化层（Pooling）来聚合一个集合中的特征。PointNet++ [27]将这些想法应用于一个分层的空间结构中，以增加对局部几何结构的敏感性。这种模型受益于点集的有效采样，[27,7,46,50,11]已经开发了多种采样策略。

许多方法将点集连接到一个图中，并在这个图上进行消息传递。DGCNN [44]对kNN图进行图卷积。PointWeb[55]稠密地连接局部邻域点。ECC [31]使用动态的边界条件滤波器，其中卷积核是基于点云内部的边生成的。SPG [15]在一个表示上下文关系的超点图上进行操作。KCNet [30]利用了核的相关性和图池化函数。Wang等人[40]研究了局部的谱的图卷积。GACNet [41]采用了图注意力卷积，HPEIN [13]构建了一个层次化的点-边交互架构。DeepGCNs [19]探索了图卷积网络的深度在三维场景理解中的优势。

许多方法是基于连续卷积，并且直接应用于没有量化的 3D 点集上。PCCN [42]将卷积内核表示为 MLP。SpiderCNN [49]将核权值定义为一类多项式函数。球面CNN [8]设计了球面卷积来解决三维旋转的同变性问题（变化相等）。PointConv[46]和KPConv [37]基于输入坐标构造卷积权值。InterpCNN[22]利用坐标来插值逐点的核权值。PointCNN[20]提出了用特殊算子对输入的无序点云重新排序。Ummenhofer等人[38]应用连续卷积来学习基于粒子的流体力学。

## Transformer 和自注意力

Transformer 和自注意力模型已经彻底改变了机器翻译和自然语言处理[39,45,5,4,51]。这启发了自注意力网络在 2D 图像识别中的发展[10,28,54,6]。Hu等人[10]和Ramachandran等人[28]在局部图像块中应用标量点积自注意力。Zhao等人[54]开发了一个向量自注意力算子族。Dosovitskiy等人[6]将图像视为图像块序列。

我们的工作受到以下发现的启发：Transformer 和自注意力网络的性能可以在序列数据和 2D 图像上达到甚至超越卷积网络。自注意力在我们的设置中具有特别有趣的性质，因为它本质上是一个集合运算符：作为集合进行处理的元素提供了位置信息这种属性[39,54]。因为三维点云本质上是具有位置属性的点集，所以自注意力机制似乎特别适合于这种类型的数据。因此，我们开发了一个点变压器层，应用自注意力的三维点云。

以前有许多工作[48,21,50,17]是利用注意力来进行点云分析。它们将全局注意力应用于整个点云，结果引入了大量的计算，使这些方法不适用于大规模的三维场景理解。它们还利用标量点积注意力，其中不同的通道共享相同的聚合权重值。相比之下，我们在局部应用自注意力，从而在具有数百万个点的大型场景中具有扩展性，还使用了向量注意力机制，并且展示了这种机制对于获得高精度的重要性。我们还演示了适当的位置编码在大规模点云理解中的重要性，因为以前的方法省略了位置信息。总的来说，我们证明了适当设计的自注意力网络可以扩展到大尺度并且复杂的 3D 场景，并能大大提高大规模点云理解的技术水平。

# Ch03 Point Transformer

首先，我们简要地回顾了变压器和自注意力算子的通用公式。然后，提出了用于三维点云处理的点变压器层。最后，提出了用于三维场景理解的网络架构。

## 3.1. 背景

Transformer 和自注意力网络已经彻底改变了自然语言处理的方式[39,45,5,4,51]，并在二维图像分析[10,28,54,6]中显示出了令人印象深刻的结果。自注意力算子可分为两种类型：标量注意力[39]和向量注意力[54]。

设 $\mathcal{X}=\{\mathbf{x}_i\}_i$ 是一组特征向量。标准的标量点积注意力层可以表示如下：
$$
\begin{equation}
\mathbf{y}_i=\sum_{\mathbf{x}_j\in\mathcal{X}}
\rho(\varphi(\mathbf{x}_i)^\top\psi(\mathbf{x}_j)+\delta)\alpha(\mathbf{x}_j)
\end{equation}
$$
其中，$\mathbf{y}_i$是输出特征；$\varphi,\psi,\alpha$是逐点特征变换函数（如：线性投影或者 MLP）；$\delta$是位置编码函数；$\rho$是归一化函数（如：softmax）。标量注意力层计算两个输出特征（通过$\varphi,\psi$变换输出的特征）的标量积，并且使用这个标量积作为注意力权重值来聚合另一个输出的特征（通过$\alpha$变换输出的特征）。

在向量注意力中，注意力权重值的计算有所不同。特别是，注意力权重值是可以调制混合独立的特征通道的*向量*：
$$
\begin{equation}
\mathbf{y}_i=\sum_{\mathbf{x}_j\in\mathcal{X}}
\rho(\gamma(\beta(\varphi(\mathbf{x}_i),\psi(\mathbf{x}_j))+\delta))\odot\alpha(\mathbf{x}_j)
\end{equation}
$$
其中，$\beta$是关系函数（如：减法）；$\gamma$是映射函数（如：MLP），用于输出注意力向量用于特征聚合。

标量自注意力与向量自注意力都是集合算子。这个集合可以成为表示完整信号（如：语句或者图像）的特征向量的合集[39,6]或者表示信号内部局部片段（如：图像块）的特征向量的合集[10,28,54]。

## 3.2. Point Transformer 层

自注意力是点云的自然匹配，因为点云本质上是不规则地嵌入在度量空间中的集合。我们的点变压器层是基于向量自注意力的。我们使用减法关系，并在注意力向量$γ$和转换向量$α$上添加一个位置编码$δ$：
$$
\begin{equation}
\mathbf{y}_i=\sum_{\mathbf{x}_j\in\mathcal{X}}
\rho(\gamma(\varphi(\mathbf{x}_i)-\psi(\mathbf{x}_j)+\delta)\odot(\alpha(\mathbf{x}_j)+\delta)
\end{equation}
$$
这里的子集$\mathcal{X}(i)⊆\mathcal{X}$是一个在$\mathbf{x}_i$的局部邻域（特别是$k$个最近邻）中的点集合。因此，在每个数据点的局部邻域中，我们采用了最新的自注意力网络进行图像分析[10,28,54]。映射函数$γ$是一个具有两个线性层和一个非线性 ReLU 的 MLP。点变压器层如图2所示。

![image-20231220181526350](/%E9%80%9A%E7%94%A8%E6%A8%A1%E5%9E%8B/Transformer/%E4%B8%89%E7%BB%B4%E5%9B%BE%E5%BD%A2/%E7%82%B9%E4%BA%91/images/Point%20Transformer%20ICCV/image-20231220181526350.png)

图2：Point Transformer 层

## 3.3. 位置编码

位置编码在自注意力中起着重要的作用，使得算子能够适应数据中的局部结构[39]。用于序列数据和图像栅格的标准的位置编码方案是手工制作的，例如：基于正弦函数和余弦函数或归一化的范围值[39,54]。在三维点云处理中，三维点坐标本身就是位置编码的自然候选对象。我们通过引入可训练的、参数化的位置编码来超越这个候选对象。我们的位置编码函数$δ$的定义如下：
$$
\begin{equation}
\delta=\theta(\mathbf{p}_i-\mathbf{p}_j)
\end{equation}
$$
这里的$\mathbf{p}_i$和$\mathbf{p}_j$是点$i$和点$j$的三维点坐标。编码函数$θ$是一个具有两个线性层和一个非线性ReLU的MLP。值得注意的是，我们发现位置编码对于注意力生成分支和特征转换分支都很重要。因此，等式(3)在这两个分支中都添加了可训练的位置编码。将位置编码的$θ$与其他子网一起进行端到端训练。

## 3.4. Point Transformer 块

如图4(a)所示，我们构造了一个核心为点变压器层的残差点变压器块。该变压器块集成了自注意力层、线性投影（降维和加速处理）和一个残差连接。输入是包含相关的三维坐标$\mathbf{p}$的特征向量$\mathbf{x}$的集合。点转换器块促进了这些局部化的特征向量之间的信息交换，用于所有数据点产生新的特征向量作为其输出。信息聚合同时适应了特征向量的内容和其在 3D 空间中的结构。

## 3.5. 网络结构

基于点变压器块，构造了完整的三维点云理解网络。请注意，点转换器是整个网络中的主要特征聚合算子。我们的网络不在预处理分支或辅助分支中使用卷积：即网络完全基于点变压器层、逐点变换和池化。网络架构如图3所示。

![image-20231221095034953](/%E9%80%9A%E7%94%A8%E6%A8%A1%E5%9E%8B/Transformer/%E4%B8%89%E7%BB%B4%E5%9B%BE%E5%BD%A2/%E7%82%B9%E4%BA%91/images/Point%20Transformer%20ICCV/image-20231221095034953.png)

图3：用于语义分割（上）和分类（下）的 Point Transformer 的网络。

### 骨干网络结构

在点转换器网络中，用于语义分割和分类的特征编码器有五个阶段，它们可以对点集进行逐步降采样的操作。各阶段的降采样率为$[1,4,4,4,4]$，因此每个阶段产生的点集的基数为$[N、N/4、N/16、N/64、N/256]$，其中$N$为输入点的个数。请注意，阶段的数量和降采样率可以根据应用程序的需要而变化，例如去构建用于快速处理的轻量级骨干网。连续的阶段通过转换模块连接：向下转换用于特征编码，向上转换用于特征解码。

### 向下转换

向下转换模块的一个关键功能是根据需要降低点集的基数，例如从第一阶段到第二阶段的转换过程中，点集的基数从$N$降低到$N/4$。在转换模块中，假设输入点集表示是 $P_1$，输出点集表示是 $P_2$。我们在 $P_1$ 中执行最远点采样[27]，以确定一个具有必要基数的，并且具有良好分布的子集$P_2⊂P_1$。为了将特征向量从 $P_1$ 汇集到 $P_2$ 上，我们在 $P_1$ 上使用了一个 kNN 图。(这与[第3.2节]中的 k 相同。我们在整个过程中使用k = 16，并在[第4.4节]中报告了该超参数的对照研究)。每个输入特征都经过一个线性变换，然后是批归一化和 ReLU，然后是从 $P_1$ 中的 k 个邻居到 $P_2$ 中的每个点上的最大池化。向下转换模块如图4(b)所示。

### 向上转换

对于语义分割等稠密数据的预测任务，我们采用 U-Net 设计，其中编码器（上小节描述的）与解码器（与编码器对称的）耦合[27,3]。解码器中的连续阶段由“向上转换”模块连接。它们的主要功能是将特征从降采样的输入点集 $P_2$ 映射到其超集 $P_1⊃P_2$上。为此，每个输入点的特征都通过线性层处理，然后进行批归一化和 ReLU，再通过三线性插值将特征映射到更高分辨率的点集 $P_1$上。这些来自前一个解码器阶段的插值特征与相应的编码器阶段通过跳跃连接提供的特征进行汇总。向上转换模块的结构如图4(c)所示。

![image-20231221103337071](/%E9%80%9A%E7%94%A8%E6%A8%A1%E5%9E%8B/Transformer/%E4%B8%89%E7%BB%B4%E5%9B%BE%E5%BD%A2/%E7%82%B9%E4%BA%91/images/Point%20Transformer%20ICCV/image-20231221103337071.png)

图4：细化的每个模块的设计结构。

### 输出头

对于语义分割，在解码器的最后阶段为输入点集中的每个点产生一个特征向量。我们应用一个 MLP 来将这个特征映射到最终的 logits 概率。对于分类问题，我们对点态特征执行全局平均池化，得到整个点集的全局特征向量。这个全局特征通过一个 MLP 来获得全局分类的 logits 概率。

