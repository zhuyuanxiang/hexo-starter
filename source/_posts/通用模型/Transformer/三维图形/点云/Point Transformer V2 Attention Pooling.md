---
title: Point Transformer V2：分组的向量注意力和基于分区的池化
excerpt: 作为探索Transformer架构用于3D点云理解的开创性工作，Point Transformer在多个高度竞争的基准测试上取得了令人印象深刻的结果。在本文中，我们分析了Point Transformer的局限性，并提出了全新的、强大的和高效的Point Transformer V2模型的设计，克服了以前的工作中存在的局限性。特别地，我们首先提出了分组的向量注意力，它比之前的向量注意力更有效。我们继承了先前工作中可学习的加权编码和多头注意力这两个长处，通过新的分组加权编码层，提出了更高效的分组向量注意力的实现方式。我们还通过一个附加的位置编码乘法算子来强化位置信息的注意力。此外，我们设计了新的、轻量级的基于分区的池化方法，使得网络具有更好的空间对齐和更有效的采样。大量的实验表明，我们的模型取得了比先前模型更好的性能，并在几个具有挑战性的3D点云理解的基准测试上取得了最先进的性能，包括在ScanNet v2和S3DIS上的3D点云分割，以及ModelNet40上的3D点云分类。
categories:
  - 点云特征
tags:
  - Point Cloud
  - Transformer
  - ScanNet
  - S3DIS
  - ModelNet40
date: 2023-12-14
updated: 
toc: true
typora-root-url: D:\Projects\Github\zhuyuanxiang\hexo_pages\hexo-starter\source\_posts\
---

# Point Transformer V2：分组的向量注意力和基于分区的池化

Bibtex：Wu X, Lao Y, Jiang L, et al. Point transformer v2: Grouped vector attention and partition-based pooling[J]. Advances in Neural Information Processing Systems, 2022, 35: 33330-33342.

[原始论文](https://proceedings.neurips.cc/paper_files/paper/2022/file/d78ece6613953f46501b958b7bb4582f-Paper-Conference.pdf)

[中文翻译](medias/通用模型/Transformer/三维图形/Point%20Transformer%20V2%20Attention%20Pooling.pdf)

[原始代码_PyTorch](https://github.com/Pointcept/PointTransformerV2)

# 摘要

作为探索Transformer架构用于3D点云理解的开创性工作，Point Transformer在多个高度竞争的基准测试上取得了令人印象深刻的结果。在本文中，我们分析了Point Transformer的局限性，并提出了全新的、强大的和高效的Point Transformer V2模型的设计，克服了以前的工作中存在的局限性。特别地，我们首先提出了分组的向量注意力，它比之前的向量注意力更有效。我们继承了先前工作中可学习的加权编码和多头注意力这两个长处，通过新的分组加权编码层，提出了更高效的分组向量注意力的实现方式。我们还通过一个附加的位置编码乘法算子来强化位置信息的注意力。此外，我们设计了新的、轻量级的基于分区的池化方法，使得网络具有更好的空间对齐和更有效的采样。大量的实验表明，我们的模型取得了比先前模型更好的性能，并在几个具有挑战性的3D点云理解的基准测试上取得了最先进的性能，包括在ScanNet v2和S3DIS上的3D点云分割，以及ModelNet40上的3D点云分类。

# Ch01 简介

点变换器（PTv1）[^1]将自注意力网络引入到3D点云的理解中。PTv1将向量注意力[^2]与U-Net风格的编码器-解码器框架相结合，在形状分类、目标部件分割和语义场景分割等多个3D点云识别任务中都取得了显著的性能。

在本文中，我们分析了Point Transformer（PTv1）[^1]的局限性，并提出了一种新的优雅而强大的骨干网，称作Point Transformer V2（PTv2）。我们的PTv2对PTv1进行了几种新的设计，包括：改进了位置编码的高级分组向量注意力，以及高效的基于分区的池化方案。

PTv1中的向量注意力层使用MLP作为加权编码，将查询和键的减法关系映射到一个注意力权重向量中，该向量可以独立地调整值向量的通道。然而，随着模型的深入和通道数量的增加，加权编码参数的数量也急剧增加，导致严重的过拟合，限制了模型的深度。为了解决这个问题，我们提出了一个更有效的参数公式的分组向量注意力，其中向量注意力被划分为具有共享向量注意力权重的组。同时，我们还展示了著名的多头注意力[^3]和向量注意力[^2,1]是我们提出的分组向量注意力的退化情况。我们提出的分组向量注意力同时继承了多头注意力和向量注意力的优点，因此更加高效。

此外，点位置为3D语义理解提供了重要的几何信息。因此，3D点之间的位置关系比2D像素更重要。然而，以往的3D位置编码方案大多遵循2D位置编码方案，并没有充分利用3D坐标系中的几何知识。为此，我们通过对关系向量应用一个附加的位置编码乘法算子来加强位置编码机制。这种设计加强了模型中的位置关系信息，并在实验中验证了其有效性。

此外，值得注意的是，空间分布的点是不规则和不均匀的，这种性质是处理点云的池化模块所面临的重大挑战。以前的点云池化方法依赖于采样方法（例如最远点采样[^4]或栅格采样[^5]）和邻居查询方法（例如kNN或半径查询）的组合，这是耗时的，并且在空间上没有很好地对齐。为了克服这个问题，我们超越了将采样和查询相结合的池化范式，而是将点云划分为不重叠的分区，从而将同一分区内的点直接融合。我们采用均匀栅格作为分区分隔器，并取得了显著的改进。

总之，我们提出了Point Transformer V2，它从几个角度改进了Point Transformer[^1]：

- 我们提出了一种有效的分组向量注意力（Grouped Vector Attention，GVA），具有一种新的加权编码层，使得有效信息在注意力群组的组内和组间交换。
- 我们引入了一种改进的位置编码方案，从而更好地利用点云坐标，进一步提高了模型的空间推理能力。
- 与以前的方法相比，我们设计了基于分区的池化策略，以实现更加有效的和空间上对齐得更好的信息聚合。

我们进行了广泛的分析和对照实验来验证我们的设计。结果表明，PTv2优于之前的工作，并在各种3D理解任务上成为了新的最先进的技术标杆。

# Ch02 相关工作

## 图像Transformers

随着ViT [^6]的巨大成功，视觉Transformer动摇了视觉任务中卷积的绝对优势，成为了2D图像理解[^7,8,9,10]的一种趋势。ViT通过将图像块（Image Patch）作为标记，将NLP中影响广泛的缩放点积自注意力和多头自注意力理论[^3]引入到视觉中。然而，对整个图像执行全局注意力会消耗过多的内存。为了解决内存消耗问题，Swin Transformer[^7]引入了基于栅格的局部注意力机制，在一系列滑动窗口中操作Transformer块。

## 点云理解

基于学习的方法处理3D点云可以分为以下几种类型：基于投影、基于体素和基于点的网络。处理不规则输入（如：点云）的一种直观方法就是将不规则表示转换为规则表示。基于投影的方法就是将3D点云投影到不同的图像平面上，并利用基于2D CNN的骨干网来提取特征表示[^11,12,13,14]。基于体素的方法是通过将不规则的点云转换为规则的体素表示[^15,16]来实现3D卷积，但是受到点云的稀疏性影响所以效率低下，直到引入和实现稀疏卷积[^17,18]之后才有所改善。基于点的方法是直接从点云中提取特征，而不是将不规则的点云投影或量化到2D或3D [^19,4,20,5]的规则栅格上。在下一段中介绍的最近提出的基于Transformer的点云理解方法，也被分为基于点的方法。

## 点云Transformer

基于Transformer的网络属于基于点网络的范畴，用于点云理解任务。在视觉Transformer的研究热潮中，几乎在同一时期，Zhao等人[^1]和Guo等人[^21]发表了他们在点云理解任务上应用注意力的探索，成为这一方向的先驱。Guo等人提出的PCT [^21]直接对点云进行全局关注。他们的工作（类似于ViT）受到了内存占用和计算机复杂度的限制。同时，基于SAN [^2]等人提出的向量注意力理论，Zhao等人提出了基于点的Transformer[^1]，模型直接在每个点与其相邻点之间实现局部注意力，缓解了上述的内存占用问题。Point Transformer在多个点云理解任务中取得了显著的结果，并在几类竞争挑战中取得了最先进的结果。在本文中，我们分析了Point Transformer[^1]的局限性，并提出了几种新的注意力机制和池化模块的架构设计，以提高Point Transformer的质量和效率。我们提出的模型，Point Transformer V2，在各种3D场景理解任务中比Point Transformer表现得更好。

# Ch03 Point Transformer V2

我们分析了Point Transformer V1（PTv1）[^1]的局限性，并提出了我们的Point Transformer V2（PTv2），包括在PTv1上的几个改进模块。我们首先引入了数学定义，并重新讨论了在PTv1中使用的向量自注意力机制（[第3.1.节]）。基于对PTv1的观察发现参数随着模型深度和通道大小的增加而急剧增加，于是我们提出了强大而有效的分组向量注意力机制（[第3.2.节])。此外，我们还介绍了改进的位置编码（[第3.3.节]）、新的池化方法（[第3.4.节]）。最后，我们描述了网络的架构（[第3.5.节]）。

## 3.1. 问题的形式化定义和背景

### 问题的形式化定义

设$\mathcal{M}=(\mathcal{P,F})$是一个3D点云场景，其中包括一组点$\mathbf{x}_i=(\mathbf{p}_i,\mathbf{f}_i)\in\mathcal{M}$，其中$\mathbf{p}_i∈\mathbb{R}^3$表示点位置，$\mathbf{f}_i\in\mathbb{R}^c$表示点特征。点云语义分割旨在为每个点$\mathbf{x}_i$预测一个类标签，而场景分类的目标是为每个场景$\mathcal{M}$预测一个类标签。$\mathcal{M}(\mathbf{p})$表示一个映射函数，作用是遇到位置$\mathbf{p}$上的一个点到$\mathcal{M}$上称为“参考集”的子集。接下来，我们将回顾在PTv1 [^1]中使用的自注意力机制。

### 局部注意力机制

对一个场景中的所有点执行全局注意力[^6,21]，其计算成本是高昂的，并且对于大规模的3D场景是不可行的。因此，我们应用局部注意力，其中每个点$\mathbf{x}_i$的注意力在一个点的子集中工作，即：参考点集$\mathcal{M}(\mathbf{p}_i)$。

*滑动栅格注意力*[^7]，即注意力是交替地应用在两组不重叠的图像栅格上，已经成为图像Transformer的常见做法[^22,23,24,25]。3D空间也可以分割成均匀的不重叠的栅格单元，参考集定义为同一栅格内的点，即$\mathcal{M}=\{(\mathbf{p}_i,\mathbf{f}_i)|\mathbf{p}_i\}$。然而，这种注意力操作依赖于一个繁琐的滑动栅格操作来获得一个全局的感受野，并且它要求数据集中的点云内的所有栅格的点密度必须一致。

PTv1采用*邻域注意力*机制，其中参考点集是给定点的局部邻域，即$\mathcal{M}(\mathbf{p}_i)= \{(\mathbf{p}_j,\mathbf{f}_j)| \mathbf{p}_j∈邻域(\mathbf{p}_i)\}$。具体地说，邻域点集$\mathcal{M}(\mathbf{p}_i)$被定义为PTv1中$\mathbf{p}_i$的k个最近邻点（k Nearest Neighboring, kNN）。我们的实验([第4.3.节])表明我们所采用的邻域注意力比滑动栅格注意力更有效。

### 标量注意力与向量注意力

给定一个点$\mathbf{x}_i=(\mathbf{p}_i,\mathbf{f}_i)\in\mathcal{M}$，应用线性投影或者MLPTransformer将点特征$\mathbf{f}_i$按照$c_h$的每个通道投影为查询$\mathbf{q}_i$、键$\mathbf{k}_i$和值$\mathbf{v}_i$的特征向量。在点$\mathbf{x}_i$及其参考点集$\mathcal{M}(\mathbf{p}_i)$上实现的标准的*标量注意力*（Scalar Attention, SA）定义如下：
$$
\begin{equation}
w_{ij}=\langle\mathbf{q}_i,\mathbf{k}_j\rangle/\sqrt{c_h},\quad
\mathbf{f}^{注意力}_i=\sum_{\mathbf{x}_i\in\mathcal{M}(\mathbf{p}_i)}
\text{Softmax}(\mathbf{w}_i)_j\mathbf{v}_j
\end{equation}
$$
其中，注意力权重是从查询向量和键向量的缩放的点积[^3]中计算的标量。多头标量注意力（Multi-head Scalar Attention, MSA）[^3]是标量注意力（SA）的扩展，其本质是并行地执行多个标量注意力。MSA被广泛地应用在Transformer中，我们将在[第3.2.节]中展示MSA属于我们提出的分组向量注意力的退化形式。

PTv1应用*向量注意力*，而不是标量注意力权重值。在PTv1中的注意力权重值是可以调节单个特征通道的向量。在SA中，标量注意力是通过查询向量和键向量之间的缩放点积来计算的。在向量注意力中，加权编码函数对查询向量与键向量之间的关系进行编码。向量注意力[^2]的公式如下：
$$
\begin{equation}
w_{ij}=\omega(\gamma(\mathbf{q}_i,\mathbf{k}_j)),\quad
\mathbf{f}^{注意力}_i=\sum_{\mathbf{x}_i\in\mathcal{M}(\mathbf{p}_i)}
\text{Softmax}(\mathbf{W}_i)_j\odot\mathbf{v}_j
\end{equation}
$$
其中，$\odot$是Hadamard积；$\gamma$是关系函数（如：相减关系）；$\omega:\mathbb{R}^c\mapsto\mathbb{R}^c$是一个可以学习的加权编码（如：MLPTransformer），用于计算注意力向量，从而在聚合前通过通道得到再分配的权重值$\mathbf{v}_j$。图2(a)展示了一种使用线性加权编码的向量注意力方法。

## 3.2. 分组向量注意力机制

在向量注意力中，随着网络变深和特征编码通道的增加，加权编码层的参数数量急剧增加。由于参数数量较大，限制了模型的效率和泛化能力。为了克服向量注意力的局限性，我们引入了分组的向量注意力机制，如图1（左）所示。

![image-20231213162318183](/%E9%80%9A%E7%94%A8%E6%A8%A1%E5%9E%8B/Transformer/Graph.%E4%B8%89%E7%BB%B4%E5%9B%BE%E5%BD%A2/PointCloud.%E7%82%B9%E4%BA%91/images/Point%20Transformer%20V2%20Attention%20Pooling/image-20231213162318183.png)

图1：比较PTv1和PTv2之间的注意力、位置编码和池化机制。左上：PTv1中具有位置编码（[第3.3.节]）的向量注意力（[第3.1.节]）；左下：PTv2中具有改进的位置编码（[第3.3.节]）的分组向量注意力（[第3.2.节]）；右上：基于采样的池化和基于插值的反池化；右下：PTv2中基于分区的池化和反池化（[第3.4.节]）

### 注意力分组

我们将值向量$\mathbf{v}∈\mathbb{R}^c$的通道均匀地划分为$g$组（$1≤g≤c$）。加权编码层输出一个具有$g$个通道而不是$c$个通道的分组注意力向量。同一注意力分组内的值向量$\mathbf{v}$的通道共享着同一标量注意力权重，这个权重是从分组的注意力向量中得到。数学定义：
$$
\begin{equation}
w_{ij}=\omega(\gamma(\mathbf{q}_i,\mathbf{k}_j)),\quad
\mathbf{f}^{注意力}_i=
\sum^{\mathcal{M}(\mathbf{p}_i)}_{\mathbf{x}_j}
\sum^g_{l=1}
\sum^{c/g}_{m=1}
\text{Softmax}(\mathbf{W}_i)_{jl}\mathbf{v}^{lc/g+m}_j
\end{equation}
$$
其中，$\gamma$是关系函数；$\omega:\mathbb{R}^c\mapsto\mathbb{R}^g$是可学习的*分组加权编码*，这个编码将在下一段中定义。等式(3)中的第二个公式是*分组向量聚合*。图2(a)展示了一个由全连接加权编码实现的普通GVA，与图2(b)中的向量注意力相比，分组加权编码函数的参数数量变少了，从而形成了一个更加强大和更加高效的模型。

![image-20231213151122816](/%E9%80%9A%E7%94%A8%E6%A8%A1%E5%9E%8B/Transformer/Graph.%E4%B8%89%E7%BB%B4%E5%9B%BE%E5%BD%A2/PointCloud.%E7%82%B9%E4%BA%91/images/Point%20Transformer%20V2%20Attention%20Pooling/image-20231213151122816.png)

图2：各类加权编码函数的比较。每个正方形代表一个标量，其中的每一行代表一个向量。从上到下的三行分别表示关系向量、权重向量和值向量。注意力分组用虚线分开。为了进行演示，我们假设特征维度为4，注意力分组的数量为2（适用于b、c、d）。不同颜色的线表示不同的操作，**蓝线**表示可学习的参数作用于输入的关系标量，而**红线**表示乘以输入的关系标量，橙线表示哪个值特征受到输入的标量权重的影响。

### VA和MSA的泛化定义GVA

当$g = c$时，我们的GVA退化为向量注意力（VA）；当等式(3)中的$ω$定义如下时，则退化为多头自注意力（MSA）：
$$
\begin{equation}
\omega(\mathbf{r})=\mathbf{r}
\underbrace{
\begin{bmatrix}
\pmb{1}_{1\times c_g}&\pmb{0}_{1\times c_g}&\dots&\pmb{0}_{1\times c_g}\\
\pmb{0}_{1\times c_g}&\pmb{1}_{1\times c_g}&\dots&\pmb{0}_{1\times c_g}\\
\vdots&\vdots&\ddots&\vdots\\
\pmb{0}_{1\times c_g}&\pmb{0}_{1\times c_g}&\dots&\pmb{1}_{1\times c_g}
\end{bmatrix}}_{g\times c_g}
\frac1{\sqrt{c_g}}
\end{equation}
$$
其中，$c_g=c/g$和$\mathbf{r}\in\mathbb{R}^{1\times c}$

### 线性分组

受MSA的加权编码函数的启发，我们设计了分组线性层$ζ(r):\mathbb{R}^c\mapsto\mathbb{R}^g$，其中不同的参数独立地投影不同组的输入向量。分组线性进一步减少了加权编码函数中的参数数量。最终，我们采用的分组加权编码函数由分组线性层、归一化层、激活层和全链接层组成，其中全链接层允许组间的信息交换。数学定义如下：
$$
\begin{equation}
\zeta(\mathbf{r})=\mathbf{r}
\underbrace{
\begin{bmatrix}
\mathbf{p}_1&\pmb{0}_{1\times c_g}&\dots&\pmb{0}_{1\times c_g}\\
\pmb{0}_{1\times c_g}&\mathbf{p}_2&\dots&\pmb{0}_{1\times c_g}\\
\vdots&\vdots&\ddots&\vdots\\
\pmb{0}_{1\times c_g}&\pmb{0}_{1\times c_g}&\dots&\mathbf{p}_g
\end{bmatrix}}_{g\times c_g}
\frac1{\sqrt{c_g}}
\end{equation}
$$

$$
\begin{equation}
\omega(\mathbf{r})=\text{Linear}\circ\text{Act}\circ\text{Norm}(\zeta(\mathbf{r}))
\end{equation}
$$

其中，$c_g=c/g,\mathbf{p}_1,\cdots,\mathbf{p}_g\in\mathbb{R}^c_g$表示可以学习的参数；$\circ$表示复合函数。

## 3.3. 位置编码乘法算子

与2D图像中离散的、规则栅格的像素不同，3D点云中的点在连续欧氏度量空间中的分布不均匀，使得3D点云中的空间关系比2D图像复杂得多。在Transformer和注意力模块中，空间信息是将位置编码$δ_{bias}(\mathbf{p}_i−\mathbf{p}_j)$作为偏差加入到关系向量$γ(\mathbf{q}_i,\mathbf{k}_j)$中获得的。

由于[第3.2.节]中提到的PTv1中向量注意力的泛化限制，为向量注意力添加更多位置编码的能力不能提高性能。在PTv2中，分组向量注意力具有减少过拟合和增强泛化的效果。由于分组向量注意力限制了注意力机制的能力，我们对关系向量中的位置编码通过一个附加的乘法算子来加强其能力，使之聚集于学习复杂的点云位置关系。如图1（左）所示，我们改进的位置编码定义如下：
$$
\begin{equation}
\mathbf{w}_{ij}=\omega
(
\delta_{mul}(\mathbf{p}_i-\mathbf{p}_j)\odot
\gamma(\mathbf{q}_i,\mathbf{k}_j)+
\delta_{bias}(\mathbf{p}_i-\mathbf{p}_j)
)
\end{equation}
$$
其中，$\odot$表示Hadamard积；$\delta_{mul}:\mathbb{R}^d\mapsto\mathbb{R}^d$和$\delta_{bias}:\mathbb{R}^d\mapsto\mathbb{R}^d$是两个MLPTransformer的位置编码函数，其输入是相关位置。位置编码乘法算子补全了分组向量注意力，获得了网络能力更好的平衡。

## 3.4. 基于分区的池化

其他基于点的方法采用的是传统的基于采样的池化过程，这类过程是采样和查询方法的组合。在采样阶段，使用最远点采样[^4]或栅格采样[^5]来表示后续编码阶段需要保留的采样点。对于每个采样点，执行一个邻居查询来聚合来自相邻点的信息。在这些基于采样的池化过程中，由于每个查询集之间的信息密度和重叠是不可控的，因此点的查询集不是空间对齐的。为了解决这个问题，我们提出了一种更有效的基于分区的池化方法，如图1所示。

### 池化操作

给定一个点集$\mathcal{M}=(\mathcal{P,F})$，通过把空间分割为不同的区间将$\mathcal{M}$分为子集$[\mathcal{M_1,M_2,\cdots,M_{n'}}]$。依据下面的公式基于单个分区融合成点的子集$\mathcal{M}_i=(\mathcal{P}_i,\mathcal{F}_i)$：
$$
\begin{equation}
\mathbf{f}'_i=\text{MaxPool}(\{\mathbf{f}_j \mathbf{U}|\mathbf{f}_j\in\mathcal{F}_i\})
\end{equation}
$$
其中，$(\mathbf{p}'_i,\mathbf{f}'_i)$是从子集$\mathcal{M}_i$中聚合的池化点的位置和特征；$\mathbf{U}\in\mathbb{R}^{c\times c'}$是线性投影。从$n'$个子集中收集池化点，我们就可以下一阶段编码的点集$\mathcal{M}'=\{\mathbf{p}'_i,\mathbf{f}'_i\}^{n'}_{i=1}$。在网络的实现中，我们使用统一的栅格来划分点云空间，因此基于分区的池化也称为栅格池化。

### 反池化操作

插值是反池化的常见做法，也适用于基于分区的池化。这里我们介绍了一种更直接和更有效的反池化方法。将融合后的点集$\mathcal{M}'$反池化回$\mathcal{M}$，关于$\mathcal{M}$中点的位置在池化过程中记录下来，并且我们仅仅需要$\mathcal{M}$中每个点的特征。在池化阶段，基于栅格的分区$[\mathcal{M_1,M_2,\cdots,M_{n'}}]$可以在相同的子集中将点特征映射到所有的点。
$$
\begin{equation}
\mathbf{f}^{up}_i=\mathbf{f}'_j,\quad 如果(\mathbf{p}_i,\mathbf{f}_i)\in\mathcal{M}_j
\end{equation}
$$

## 3.5. 网络架构

### 骨干网结构

根据先前的工作[^18,1]，我们采用了具有跳跃连接的U-Net架构。编码器和解码器分别包含四个阶段，其块深度为$[2,2,6,2]$和$[1,1,1,1]$。这四个阶段的栅格乘法算子的大小是[x3.0、x2.5、x2.5、x2.5]，表示前一个池化阶段后的扩展比率。注意力应用在局部邻域中，描述为“邻域注意力”（[第3.1.节]）。在[第4.3.节]，我们比较了邻域注意力和滑动栅格注意力。

首先，我们将输入通道嵌入到特征中（特征维度初始化为$48$），其中每个基本块拥有$6$个注意力分组。然后，在每次进入下一个编码阶段时，我们都将这个特征维度和注意力分组加倍。越过四个编码阶段后，特征维度为[^96,192,384,384]，对应的注意力分组为[^12,24,48,48]。

### 输出头

对于点云语义分割，我们应用MLPTransformer将骨干网产生的点特征映射到输入点集中每个点的最终对数上。对于点云分类，我们在编码阶段产生的点特征上应用全局平均池化，得到一个全局特征向量，然后使用一个MLPTransformer分类器进行预测。

# Ch04 实验结果

为了验证该方法的有效性，我们对ScanNet v2 [^44]和S3DIS [^45]进行了语义分割，对ModelNet40 [^46]进行了形状分类，从而完成实验评估。实施细节可在附录中提供。

## 4.1. 语义分割

### 数据和度量

对于语义分割，我们在ScanNet v2 [^44]和S3DIS [^45]上进行了实验。ScanNet v2数据集包含从RGB-D帧重建的房间扫描。该数据集被分为1,201个场景用于训练，312个场景用于验证。模型输入的点云从重建网格的顶点中采样，每个采样点分配一个语义标签，语义标签来自于20个类别（墙、地板、表等）。用于语义场景解析的S3DIS数据集由来自三个不同建筑的6个区域的271个房间组成。根据一个通用的协议[^36,4,1]，区域5在训练期间被保留并用于测试。与ScanNet v2不同的是，S3DIS的点在网格表面上密集采样，并标注为13个类别。根据标准协议[^4]，我们使用类平均交并比（mIoU）作为ScanNet v2的验证和测试集的评估度量。我们使用类平均交并比（mIoU）、类平均精度（Mean Accuracy，mAcc）和点总体精度（Overall Accuracy，OA）来评估S3DIS区域5的性能。

### 性能比较

表1和表2分别显示了我们的PTv2模型与之前的方法在ScanNet v2和S3DIS上相比较的结果。我们的PTv2模型在所有评估指标上都优于之前的方法。值得注意的是，在ScanNet v2验证集上，PTv2的性能显著比PTv1 [^1]高出4.8%的mIoU。

表1：在ScanNet v2数据集上的语义分割，表2：在S3DIS数据集上区域5的语义分割

![表1和表2](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20V2%20Attention%20Pooling/image-20231214103641918.png)

### 可视化

点云语义分割的定性结果如图3和图4所示。我们的PTv2模型能够预测非常接近基准的语义分割结果。值得注意的是，我们的模型可以捕获结构的细节信息，并为具有挑战性的场景预测正确的语义。例如，在带椅子的S3DIS场景中，PTv2能够清晰地预测椅子的腿和扶手。

## 4.2. 形状分类

### 数据和度量

我们在ModelNet40数据集上测试了我们提出的用于3D点云分类的PTv2模型。ModelNet40 [^46]数据集由属于$40$个对象类别的$12,311$个CAD模型组成。$9843$个模型被分开用于训练，剩下的$2468$个模型被保留用于测试。按照社区中的常见做法，我们报告了在测试集上的类平均准确度（mAcc）和总体准确度（OA）。

### 性能比较

我们测试了PTv2模型，并在ModelNet40数据集上与之前的模型模型进行了形状分类的比较。结果如表3所示，表明我们提出的PTv2模型在ModelNet40形状分类上取得了最先进的性能。

表3：在ModelNet40数据集上的形状分类

![表3](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20V2%20Attention%20Pooling/image-20231214104102283.png)

## 4.3. 消融研究

我们进行了消融研究，以检验我们的设计中每个模块的有效性。消融研究的结果报告在ScanNet v2验证集上。

### 注意力类型

我们首先研究了不同的注意力设计的影响。我们实验了在[第3.1.节]中引入的两种类型的局部注意力，分别是滑动栅格注意力和邻域注意力。然后，为了验证我们提出的分组向量注意力（记为“GVA”）的有效性，我们将其与常用的多头自注意力（记为“MSA”）进行了比较。在表4中的所有实验中，我们都使用了PTv1 [^1]中的基础的位置编码方案和我们提出的基于分区的池化方案。结果表明，邻域注意力明显优于滑动栅格注意力，说明邻域注意力更适合于非均匀分布的点云。此外，我们提出的分组向量注意力始终优于常用的多头自注意力，即使多头自注意力添加了滑动栅格注意力和邻域注意力，所以我们的分组向量注意力比多头自注意力拥有更好的质量与效率。GVA和MSA的比较证明在[第3.2.节]中分组的加权编码的分组的线性层中的可学习参数的有效性。

表4：注意力类型的消融研究

![image-20231214105730294](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20V2%20Attention%20Pooling/image-20231214105730294.png)

### 加权编码

我们在表6中研究了不同的加权编码函数$ω$的影响。在[第3.1.节]和[第3.2.节]中介绍了加权编码函数，以及不同的加权编码函数应用在不同的注意力机制中。我们在表6的所有实验中都使用了PTv1 [^1]中的基础位置编码和我们提出的栅格池方案。我们试验了以下加权编码函数：

1. 等式(4)中多头标量注意力的加权编码，记为“MSA”。
2. 加权编码为一个线性层，表示为“L”。
3. 分组的线性层，等式(5)中的$ζ$，记为“GL”。
4. 线性层+批归一化层+激活层+线性层，记为“L+N+A+L”。
5. 分组的线性层+批归一化层+激活层+线性层，记为“GL+N+A+L”。它也是我们用于分组向量注意力的分组加权编码函数，以$\omega$的方式引入到等式(5)中。

表6中的结果表明，我们的分组加权编码函数优于其他设计。具体来说，对比(1)、(3)和(5)，GL的性能略优于MSA，但添加额外的组间信息交换，结合适当的归一化和激活，可以使性能更加优于MSA。此外，(5)和(4)之间的比较以及(3)和(2)之间的比较都表明，尽管分组的线性层的参数少g倍，计算量也更少，但我们的性能仍然优于原始的线性层。

表6：加权编码的消融研究

![image-20231214112008421](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20V2%20Attention%20Pooling/image-20231214112008421.png)

### 池化方法

在[第3.4.节]中，我们讨论了PTv1中基于采样的池化存在的潜在局限性，并提出了一种新的基于非重叠分区的池化和解池化方案。我们的基于分区的池化是简单和有效的基于栅格的实现，并将其称为栅格池化。为了进一步检验我们的方法的优越性，我们在表5中实验了不同的池化与解池化方案。

表5：池化方法的消融研究

![image-20231214112827356](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20V2%20Attention%20Pooling/image-20231214112827356.png)

对于由栅格实现的基于分区的池化，基本栅格大小为0.02米，这与数据预处理时的体素化栅格的大小相同。栅格大小的乘法算子是在前一个池化阶段上的栅格大小的扩展比率。例如：[×4.0、×2.0、×2.0、×2.0]表示栅格尺寸分别为：[0.08、0.16、0.32、0.64]米。我们为初始栅格尺寸选择了一个相对较大的值（×3.0和×4.0），以提供足够大的感受野，这类似于图像Transformer[^6]中的常见做法。对于随后的池化阶段，我们观察到×2.0栅格大小的比率导致点云的池化比约为4，而×2.5栅格大小的比率导致池化比约为6。在基于采样的池化阶段，我们选择相同的4和6的采样比，以确保公平的比较。

表5中的结果表明，我们的基于分区的池化比基于采样的方法获得了更高的mIoU。对于由最远点采样实现的基于采样池化，当采样比率从4增加到6时，性能显著下降。但是，对于由栅格实现的基于分区的池化，我们观察到初始栅格大小和随后的栅格大小乘法算子对总体性能没有显著影响，因此我们可以使用更大的栅格大小来减少每个阶段的点数，从而节约内存占用。

### 模块设计

我们消融了PTv2中引入的不同模块：分组向量注意力（VGA）、位置编码乘法算子（PE Mul）、由栅格实现的基于分区的池化（栅格池化）和分区映射解池化（Map Unpool），结果如表7所示。实验Ⅰ中采用的模型为PTv1 [^1]，并将其作为我们设计的基线结果。得益于结构参数的调整和更好的数据处理，我们的基线结果从$70.6\%$增加到$72.3\%$，数据处理的结果也与其他实验共享。实验Ⅱ到实验Ⅴ依次添加我们提出的每个组件，逐渐将我们的基线结果增加到$75.4\%$。增加的mIOU表示了各组件的有效性。

表7：模型设计的消融研究

![image-20231214150842818](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20V2%20Attention%20Pooling/image-20231214150842818.png)

## 4.4. 模型的复杂度与延迟

我们进一步进行模型复杂性和延迟研究，以检验在我们的工作中几种设计的卓越的效率。我们在ScanNet v2验证集上，基于单个的TITAN RTX，设置批大小`batch_size=4`，记录了每次扫描摊销的前向传播时间。

### 池化方法

表8显示了不同池化方法和池化比率下PTv2的前向传播时间和mIoU。我们比较了提出的池化方法和两种经典的基于采样的池化方法（FPS-kNN和Grid-kNN）。FPS-kNN池化[^4,1]使用最远点采样（FPS）来采样指定数量的点，然后查询k个最近邻点来进行池化。我们将Strided KPConv [^5]中的池化方法称为栅格池化，因为它使用统一的栅格来采样点，然后将kNN方法应用于索引邻居。这导致了池化感受野的重叠无法控制。如表中所示，我们的栅格池方法不仅速度更快，而且实现了更高的mIoU。

表8：不同池化方法的模型参数的延迟平摊

![image-20231214154240362](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20V2%20Attention%20Pooling/image-20231214154240362.png)

### 模型设计

表9汇总了在ScanNet v2验证集上的模型复杂性、时间消耗和性能评估的比较结果。同时，我们放弃了为GPU做准备提供的第一批数据的转发时间。在表9中，GVA表示分组的向量注意力。L表示由单个线性层实现的分组加权编码。GL表示由分组线性算法实现的分组加权编码。GL-N-A-L表示分组的线性层+批归一化+激活层+线性层作为分组的加权编码函数。GP表示由栅格实现的基于分区的池化结构。PEM表示位置编码乘法算子。为了确保公平的比较，PTv1被设置为与我们的PTv2模型架构相同的深度和特征维度。通过比较实验①和实验②，我们可以研究GVA的作用。实验③、实验④和实验⑤也基于同样的思路，每个实验都增加了一个额外的模块，这样我们就可以分别研究所添加的模块的效果。

通过实验①、②、③和④比较表明，采用分组加权编码的分组向量注意力（GVA）显著地提高了模型性能，并略微减少了执行时间。通过实验④和⑤的比较表明，栅格池策略可以显著加快网络速度，进一步提高模型的泛化能力。位置编码乘法算子是唯一能增加模型参数数量的设计，但实验⑥证明了其在提高性能方面的有效性。与此同时，与基于体素的骨干网（如：具有37.9M参数的MinkUNet42 [^18]）相比，我们的模型仍然是轻量级的。

表9：几种网络中的模型参数和延迟平摊

![image-20231214154102421](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20V2%20Attention%20Pooling/image-20231214154102421.png)

# Ch05 结论

我们提出了Point Transformer V2（PTv2），一个强大和高效的基于Transformer的骨干网，用于3D点云的理解。我们的工作在Point Transformer V1 [^1]上做了几个重要的改进，包括分组向量注意力、改进的位置编码和基于分区的池化。我们的PTv2模型在点云分类和语义分割基准测试上取得了最先进的性能。

# 附录

在附录中，我们在[附录A]中提供了更多的实验细节，在[附录B]提供了更多的实验结果。

# 附录A 实验细节

本节描述了实验中采用的模型架构，并详细描述了每个数据集的实验设置。

## A.1. 模型架构

在图5中，我们展示了用于语义分割和形状分类的网络架构的细节。每个阶段块下的元组表示的是采样点的数量和注意力块的特征维度，其中采样点的数量由栅格大小决定（详见论文正文）。

![image-20231214155344045](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20V2%20Attention%20Pooling/image-20231214155344045.png)

图5：语义分割（上）和分类（下）的网络架构

## A.2. 实验配置

### 实验环境

软件与硬件环境：

- CUDA 版本：11.1
- cuDNN 版本：8.0.5
- PyTorch 版本：1.10.1
- GPU：Nvidia RTX A6000 x 4
- CPU：Intel Xeon Platinum 8180 @ 2.50 GHz x 2

### 数据授权

我们的实验使用了广泛应用于3D识别研究的开源数据集。ScanNet v2 [^44]数据集属于MIT许可，而S3DIS [^45]和ModelNet40 [^46]拥有只允许学术使用的自定义许可。

### 数据预处理和增强

对于S3DIS和ModelNet40数据集，我们采用了PTv1 [^1]的数据预处理，但对数据增强略有调整。对于ScanNet v2，我们估计了点的法向量作为额外的特征输入。对于每个数据集，其数据增强策略都不相同（详见表10）。每种类型的数据增强的详细设置都可以在我们的开源代码中获得。

表10：数据增强

![image-20231214160006583](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20V2%20Attention%20Pooling/image-20231214160006583.png)

### 训练细节

我们训练模型的具体设置见表11。对于分割任务，使用AdamW来减少模型的过拟合。具有余弦退火策略的调度器在ScanNet v2上有更好的性能，它比S3DIS有更多的数据。我们在所有的实验中都使用了交叉熵损失。

表11：训练设置

![image-20231214160030198](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20V2%20Attention%20Pooling/image-20231214160030198.png)

# 附录B 附加的量化结果

在本节中，我们将提供更多的定量结果来验证和分析我们提出的网络架构。

## B.1 解码器块的深度

我们在表12中展示了对使用不同解池化方法的每个解码器块的深度的消融实验。在每个解码阶段中至少应用一个注意力块可以显著提高模型的性能，而这种现象在使用我们的映射池化时更加明显。但是更深的解码器（每个解码器块的深度为1到2）并不能提高性能。这些现象是合理的，因为朴素的解池化方法，如：插值和映射，需要一个可学习的块来优化采样特征。在2D空间中，步幅反卷积被广泛用于同时解池化和优化特征，而这种过程通常不需要深度网络。

表12：不同解码器深度用于两个上采样策略的结果（mIoU%）

![image-20231214160525879](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20V2%20Attention%20Pooling/image-20231214160525879.png)

## B.2 位置编码乘法算子的消融研究

表13显示了对PE乘法算子的一个附加的消融研究。PE乘法算子在PTv1下不能很好地工作，因为PTv1已经对训练集过拟合了。为PTv1增加更多的容量也无助于提高性能。在PTv2上，群体向量注意力（GVA）具有减少过拟合和增强泛化的效果。由于GVA限制了注意力机制的能力，PE乘法算子的加入可以专注于学习点云的复杂的位置关系。PE乘法算子辅助分组向量注意力，以获得一个良好的网络容量平衡。

表13：位置编码乘法算子的消融研究

![image-20231214160642618](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20V2%20Attention%20Pooling/image-20231214160642618.png)

## B.3 池化方法的比较

我们比较了三种不同的特征级池化方法： FPS-kNN、Grid-kNN，以及我们提出的由栅格实现的基于分区的池化。FPS-kNN池化[^4,1]使用最远点采样（FPS）来采样指定数量的点，然后查询k个最近邻点来进行池化。Strided KPConv [^5]使用均匀的栅格来采样点，然后应用kNN方法来对邻居进行索引，导致池化感受野的重叠不可控。我们将这种方法命名为栅格-kNN池化（Grid-kNN Pooling）。我们的方法在每个非重叠的栅格单元内计算不重叠的感受野和融合点。为了区别于以前的基于采样的方法，我们将其命名为栅格池化（Grid Pooling）。

### 合成数据的基准

表14提供了不同池化方法使用合成数据得到的基准测试结果。我们在单位立方体空间中均匀地、随机地生成n个点。抽样比r是样本量除以总体数量。为了进行比较，我们保持不同池化方法的采样比r相同。对于栅格-kNN池化和栅格池化，由于点云是均匀随机采样的，所以栅格大小定义为$(n\times r)^{-\frac13}$ 。我们展示了这三种方法组合池化和解池化的时间。

表14：池化与解池化组合后的时间比较

![image-20231214161941580](images/通用模型/Transformer/三维图形/点云/Point%20Transformer%20V2%20Attention%20Pooling/image-20231214161941580.png)
