---
title: FoldingNet：通过深度栅格变形技术实现的点云自动编码器
excerpt: 形状补全，是许多视觉和机器人应用的核心问题。目标是从部分观测中估计对象的完整几何形状。在本文中，我们提出了点补全网络（Point Completion Network, PCN），一种新颖的基于学习的形状补全方法。与现有的形状补全方法不同，PCN直接对原始点云进行操作，没有任何关于底层形状的结构假设（如：对称性）或者标注（如：语义类别）。它的特点是一个解码器的设计，能够生成细粒度的补全，同时维护少量的参数。我们的实验表明，PCN在基于不同水平的不完整数据和噪声的输入（包括来自KITTI数据集中使用激光雷达扫描得到的汽车数据）下都在现实结构的缺失区域中补全了稠密的、完整的点云。
categories:
  - 点云特征
tags:
  - 点云特征
  - 折叠网络
  - FoldingNet
  - ShapeNet
  - ModelNet
date: 2023-11-28
updated: 2023-11-28
toc: true
typora-root-url: D:\Projects\Github\zhuyuanxiang\hexo_pages\hexo-starter\source\_posts\
---

# FoldingNet：通过深度栅格变形技术实现的点云自动编码器

Yang Y, Feng C, Shen Y, et al.  Foldingnet: Point cloud auto-encoder via deep grid  deformation[C]//Proceedings of the IEEE conference on computer vision  and pattern recognition. 2018: 206-215.

[原始论文](https://arxiv.org/pdf/1712.07262v2.pdf)

[中文翻译](https://zhuyuanxiang.github.io/pdfs/机器学习/计算机视觉/三维处理/点云/FoldingNet/FoldingNet：通过深度栅格变形技术实现的点云自动编码器.pdf)

[原始代码_PyTorch](https://github.com/AnTao97/UnsupervisedPointCloudReconstruction)

[论文作者实验室主页]([Software & Data Downloads | Mitsubishi Electric Research Laboratories (merl.com)](https://www.merl.com/research/license#FoldingNet))

ToDo:网格→栅格；重构→重建；折叠网→FoldingNet；

# 摘要

最近的深度网络，直接处理点集中的点，例如：PointNet，已经成为有监督的点云学习任务（如：分类和分割）中最先进的方法。在本文中，我们提出了一种全新的基于深度学习的端到端的自动编码器来解决点云上的无监督学习问题。在编码器方面，强制执行基于图的增强，以促进点网之上的局部结构。然后，一种新型的基于折叠的解码器将规范的二维栅格变形到点云的潜在三维对象表面上，即使对于具有精细结构的物体，也能获得较低的重建误差。该解码器只使用全连接神经网络解码器的约7%的参数，然而获得了更具识别力的表示，实现了比基准（线性SVM）更高的分类精度。此外，所提出的解码器结构在理论上是一种通用的，能够从二维栅格重建任意点云的架构。

# Ch01 简介

三维点云的处理和理解通常被认为比二维图像更具挑战性，这主要是因为点云样本具有不规则的结构，而二维图像样本（像素）依赖于图像平面上具有规则间距的二维栅格。点云几何通常是由一组稀疏的三维点表示。这种数据格式使得传统的深度学习框架难以应用。例如，对于每个样本，传统的卷积神经网络（CNN）要求其相邻的样本出现在一些固定的空间方向和距离上，以方便卷积。不幸的是，点云样本通常不满足这样的约束条件。缓解这个问题的一种方法是模拟图像的表示方式对点云进行体素化，然后对体素进行操作。体素化的缺点是，要么牺牲表示精度，要么接受巨大的冗余。选择的结果，要么性能受损，要么处理的复杂度快速增加，这都可能会在后续的操作中造成不必要的成本。相关技术的回顾参见（Sec1.1.）。

在本文中，我们关注的是新兴领域的无监督学习的点云。我们提出了一种自动编码器（Auto-Encoder，AE），它被称为折叠网络（FoldingNet）。从自动编码器中的瓶颈层得到的输出称为码字（codeword），可以用作输入点云的高维嵌入。我们将展示一个二维的栅格结构，其不仅是一个影像的采样结构，实际上还可以通过提出的折叠（folding）操作来构建一个点云。基于我们感兴趣的三维点云观察得出了三维点云重建的结论，这些三维点云是从物体表面获得的：要么是从CAD/计算机图形中的边界的离散化表示得到，要么是从像激光雷达这样的视线传感器采样得到。直观地说，任何三维物体表面都可以通过某些操作：切割、压缩和拉伸等转换为二维平面。反过程是通过某些折叠操作将这些二维点样本粘合回物体表面，这些折叠操作被初始化为二维栅格样本。如表1所示，为了重建一个点云，需要连接起来的、连续的折叠操作来再现表面结构。这些点被着色，以显示初始的二维栅格样本与重建的三维点样本之间的对应关系。利用基于折叠的方法，通过在解码器中直接引入这种隐式二维栅格约束，可以很好地解决点云不规则结构的挑战，避免了其他工作[56]中三维体素化的计算成本。稍后将证明，如果有适当的码字，折叠操作可以构建任意曲面。请注意，当数据来自体素格式而不是二维曲面时，三维栅格可能会表现得更好。

![image-20231128170958341](/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%B8%89%E7%BB%B4%E5%A4%84%E7%90%86/%E7%82%B9%E4%BA%91/%E7%82%B9%E4%BA%91%E7%89%B9%E5%BE%81/FoldingNet/images/FoldingNet%20Point%20Cloud%20Auto-encoder%20via%20Deep%20Grid%20Deformation/image-20231128170958341.png)

表1：两步折叠解码的说明。第一列：包含了来自ShapeNet数据集[57]的原始点云示例。第二列：说明了在解码过程中要折叠的二维栅格点。第三列：包含了一次折叠操作后的输出。第四列：包含了两次折叠操作后的输出。这个输出也是重建的点云。我们使用一个颜色梯度来说明第二列中的二维栅格与最后两列中折叠操作后重建的点云之间的对应关系。使用颜色得到最佳观察。

尽管折叠操作在重构点云方面具有很强的表达力，但其本质很简单：它首先用从编码器获得的码字来增强二维栅格点，然后通过一个3层感知器进行处理。所提出的解码器是两个折叠操作的连接。这种设计使所提出的解码器在参数尺寸上比最近在[1]中提出的全连接解码器要小得多。在(Sec4.6.)中，我们展示了基于折叠的解码器的参数数量约为[1]中全连接解码器的7%。虽然提出的解码器结构简单，但是我们依然在定理3.2中从理论上证明了这种基于折叠的结构的普适性，因为仅使用2层感知器的折叠操作已经可以生成任意的点云结构。因此，我们的FoldingNet自动编码器利用两个连续的折叠操作可以产生复杂的结构就不足为奇了。

为了展示折叠网自动编码器在无监督表示学习中的效率，我们遵循了[1]中的实验设置，并测试了从ShapeNet数据集[7]到ModelNet数据集[57]的按类别的转换精度。利用ShapeNet数据集训练折叠网自动编码器，并通过从ModelNet数据集中提取码字进行测试。然后，我们训练一个线性SVM分类器来测试所提取的码字的识别有效性。在具有40个形状类别的ModelNet数据集上，转换后分类准确率为88.4%。这种分类化精度甚至接近于最先进的监督训练结果[41]。为了获得最佳的分类性能和最小的重构损失，我们使用了一种不同于[41]的基于图形的编码器结构。这个基于图形的编码器是基于局部特征池操作的思想，能够沿着图的结构检索和传播局部结构信息。

为了直观地解释我们的网络设计：我们想要使二维栅格基于一个“虚拟力”来变形/切割/拉伸到三维物体表面，这种变形力应该受到点阵邻域产生的互连的影响或调节。由于解码器中的中间折叠步骤和训练过程可以用重建点来说明，因此可以通过可视化地折叠力来观察它的逐渐变化。

现在，我们总结一下我们在这项工作中的贡献：

- 我们训练了一个直接使用无序点云的端到端深度自动编码器。
- 我们提出了一种新的折叠解码操作，并从理论上证明了它在点云重建中是通用的，同时将重建点的顺序作为唯一的副产品。
- 我们在主要数据集上的实验表明，折叠将比其他非监督方法获得更高的分类精度。

## 1.1. 相关工作

学习在点云上的应用包括形状补全和识别[57]、无人驾驶汽车[36]、三维目标检测、识别和分类[9,33,40,41,48,49,53]、轮廓检测[21]、布局推理[18]、场景标记[31]、类别发现[60]、点云分类、稠密标记和分割[3,10,13,22,25,27,37,41,54,55,58]。

大多数为三维点云设计的深度神经网络都是基于将三维空间划分为规则体素并将二维CNN扩展到体素的想法，如[4,11,37]，包括三维生成对抗网络[56]的工作。基于体素的网络的主要问题是神经网络的规模随着空间分辨率的增大而快速增长。其他一些为三维点云设计的深度神经网络则是：基于八叉树的[44]和基于KD树的[29]。最近，有研究表明，基于纯三维点表示的神经网络[1,41-43]对点云的工作相当有效。基于点的神经网络可以减少将点云转换为其他数据格式（如八叉树和体素）的开销，同时避免了转换造成的信息损失。

我们所知道的关于直接处理点云的端到端深度自动编码器的唯一工作是[1]。在[1]中设计的自动编码器是为了提取生成网络的特征。为了进行编码，它使用字典顺序对三维点进行排序，并对点序列应用一维CNN。为了解码，它应用了一个三层全连接的网络。在从ShapeNet数据集到ModelNet数据集[1]转移的分类精度方面，这个简单的结构优于所有现有的无监督工作。我们的方法具有一个基于图的编码器和一个基于折叠的解码器，在ModelNet40数据集[1]上转移的分类精度方面优于该方法[^1]。此外，与[1]相比，我们设计的自动编码器更容易解释：编码器学习局部形状信息并且与近邻图上的最大池化信息合并，而解码器使用获得的信息学习一个“力”两次，并将该力用于折叠二维栅格从而扭曲栅格成点云的形状。另一个密切相关的工作是从2D图像中重建点云[^17]。虽然[^17]中解卷积网络需要一个2D图像作为边缘信息，我们发现我们的折叠操作的另一种实现是有用的。我们将FoldingNet与基于反卷积的折叠网络进行了比较，结果表明FoldingNet在重建误差方面的表现略好（见补充部分9）。

纯粹的基于点的神经网络很难提取出点周围的局部邻域结构，即相邻点的特征，而不是单个点的特征。在[1,42]中有些研究已经进行了一些尝试。在本项工作中，我们利用一个基于图的框架来利用局部邻域特征。对图结构数据的深度学习并不是一个全新的想法，有大量的工作讨论了将深度学习应用于不规则数据。虽然使用图作为点云深度学习的处理框架是一个自然的想法，但只有几个开创性的工作在这个方向上做了尝试。这些工作试图将卷积操作从二维图像推广到图形中。然而，由于很难在图上定义卷积操作，我们使用了一个简单的基于图的神经网络层，这与以前的工作不同：我们构造了k-最近邻图（K-Nearest Neighbor Graph, KNNG），并在每个节点的邻域重复进行最大池操作，这是对[41]中提出的全局最大池操作的泛化操作，即最大池只应用于每个局部邻域来生成局部数据签名。与上述基于图的卷积网络相比，我们的设计更简单，计算效率更高。K-NNGs也被用于其他没有深度学习框架的点云的应用，如：表面检测、三维对象识别、三维对象分割与压缩[20,50,51]。

从二维栅格重建曲面的折叠操作本质上建立了从二维规则域到三维点云的映射。一个疑问油然而生：我们是否可以用兼容的网格来参数化三维点，这些网格不一定是规则的栅格，比如交叉参数化[30]。从表2来看，FoldingNet似乎可以学习在二维栅格上生成“切割”，并且生成的曲面与二维栅格并非拓扑等价，从而使二维栅格的表示在某种程度上是通用的。尽管如此，当原始表面太复杂时，重建的点仍然可能存在逐类别的扭曲。例如，在表2中，我们看到了重建平面上缺失的小翼和重建椅背上缺失的孔。为了恢复这些更精细的细节，可能需要更多的输入点样本和更复杂的编码器/解码器网络。另一种学习表面嵌入的方法是学习[16]中的度量对齐层，这可能在训练过程中需要对计算进行密集的内部优化。

![image-20231130165006521](/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%B8%89%E7%BB%B4%E5%A4%84%E7%90%86/%E7%82%B9%E4%BA%91/%E7%82%B9%E4%BA%91%E7%89%B9%E5%BE%81/FoldingNet/images/FoldingNet%20Point%20Cloud%20Auto-encoder%20via%20Deep%20Grid%20Deformation/image-20231130165006521.png)

表2：训练过程的描述。随机2D流形逐渐地变换到点云表面。

## 1.2. 前置条件和符号

我们经常用$S$表示点集。用小写加粗字母来表示向量，如$\mathbf{x}$；用大写加粗字母表示矩阵，如$\mathbf{A}$。码字总是用$\mathbf{\theta}$表示。如果一个矩阵有$m$行和$n$列，我们称它为`m-by-n`或$m\times n$。

# Ch02 点云上的FoldingNet自动编码器

现在我们提出了FoldingNet深度自动编码器。自动编码器的结构如图1所示。编码器的输入是一个n乘3的矩阵。矩阵的每一行都由三维坐标$(x,y,z)$组成。输出是一个m乘3的矩阵，表示重建的点的位置。重建点的个数m不一定与输入点的个数n相同。假设输入点集为$S$，重建点集为$\hat{S}$。然后，使用定义为（扩展的）倒角距离的层来计算$\hat{S}$的重建误差：
$$
\begin{equation}
d_{CH}(S,\hat{S})=
\max\{
\frac1{|S|}\sum_{\mathbf{x}\in S}\min_{\hat{\mathbf{x}}\in\hat{S}}\|\mathbf{x}-\hat{\mathbf{x}}\|_2,
\frac1{|S|}\sum_{\hat{\mathbf{x}}\in\hat{S}}\min_{\mathbf{x}\in S}\|\hat{\mathbf{x}}-\mathbf{x}\|_2
\}
\end{equation}
$$
其中，$\min_{\hat{\mathbf{x}}\in\hat{S}}\|\mathbf{x}-\hat{\mathbf{x}}\|_2$强制原始点云中的任何三维点$\mathbf{x}$在重建的点云中都有一个匹配的三维点$\hat{\mathbf{x}}$，而$\min_{\mathbf{x}\in S}\|\hat{\mathbf{x}}-\mathbf{x}$强制了相反的匹配。$\max()$运算强制执行从$S$到$\hat{S}$的正向距离和反向距离必须同时较小。编码器计算每个输入点云的表示（码字），解码器使用这个码字重构点云。在我们的实验中，根据[1]，将码字长度设置为512。

![image-20231130172538536](/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%B8%89%E7%BB%B4%E5%A4%84%E7%90%86/%E7%82%B9%E4%BA%91/%E7%82%B9%E4%BA%91%E7%89%B9%E5%BE%81/FoldingNet/images/FoldingNet%20Point%20Cloud%20Auto-encoder%20via%20Deep%20Grid%20Deformation/image-20231130172538536.png)

图1：FoldingNet 架构。图网络层是基于图的最大池化层，详见[Sec2.1.]()的等式(2)。第1个折叠与第2个折叠都是通过将码字拼接到特征向量上，然后再后接一个三层感知器来实现的。每个感知器独立地应用于单个点的特征向量上，就如[^41]中将感知器应用到$m\times n$矩阵的行上。

## 2.1. 基于图的编码器架构

基于图的编码器遵循了[46]中类似的设计，在[^46]中侧重于使用点云邻域图进行监督学习。编码器是一个多层感知器（MLP）和基于图的最大池化层的拼接。图是由输入点集中节点的三维坐标构造出来的K-NNG。在实验中，我们选择了$K = 16$。首先，对于每一个单点$v$，我们计算其大小为3乘3的局部协方差矩阵，并将其向量化为1乘9。$v$的局部协方差是利用K-NNG中节点$v$（包含$v$）的一跳邻居的点的三维坐标来计算的。我们将大小为$n\times3$的点坐标矩阵和所有大小为$n\times9$的点的局部协方差矩阵拼接成一个大小为$n\times12$的矩阵，并将它们输入到一个3层感知器。感知器并行地应用到大小 为$n\times12$的输入矩阵的每一行。它可以看作是每个三维点上的单点函数。感知器的输出被输入到两个连续的图网络层，其中的每一层都对每个节点的邻域执行最大池化。更具体地说，假设K-NN图具有邻接矩阵$\mathbf{A}$，并且图网络层的输入矩阵为$\mathbf{X}$，则输出矩阵为：
$$
\begin{equation}
\mathbf{Y}=\mathbf{A}_{\max}(\mathbf{X})\mathbf{K}
\end{equation}
$$
其中，$\mathbf{K}$是特征映射矩阵，矩阵$\mathbf{A}_{\max}(\mathbf{X})$的第$(i,j)$项：
$$
\begin{equation}
(\mathbf{A}_{\max}(\mathbf{X}))_{ij}=\mathbf{ReLU}(\max_{k\in\mathcal{N}(i)}x_{kj})
\end{equation}
$$
等式(3)中局部最大池化操作$\max_{k\in\mathcal{N}(i)}x_{kj1}$在本质上是基于图结构的计算一个局部签名。此签名可以表示局部领域的（聚合的）拓扑信息。通过对基于图的最大池化层的拼接，网络将拓扑信息传播到更大的区域。

## 2.2. 基于折叠的解码器结构

该解码器使用两个连续的三层感知器将一个固定的二维栅格扭曲成输入点云的形状。输入码字是从基于图的编码器中获得的。在我们将码字输入解码器之前，我们将它复制$m$次，并将$m\times512$矩阵与一个$m\times2$矩阵拼接起来，该矩阵包含一个以原点为中心的正方形上的$m$个栅格点。拼接的结果是一个大小为$m\times514$的矩阵。该矩阵由一个$3$层感知器逐行处理，输出为一个大小为$m\times3$的矩阵。在那之后，我们再次将复制的码字连接到$m\times3$输出中，并将其输入一个3层感知器。这个输出是重建的点云。参数$n$是根据输入点云的大小来设置的，如我们的实验中的$n = 2048$，它与[1]相同。我们在一个平方中选择$m$个栅格点，所以选择$m=2025$，这是最接近$2048$的平方数。

定义1。我们将复制的码字拼接到低维的栅格点，然后紧接一个逐点MLP称为折叠操作。

折叠操作本质上形成了一个通用的2D到3D的映射。为了直观地理解其本质，用矩阵$U$表示输入的二维栅格点。$U$的每一行都是一个二维栅格点，用$\mathbf{u}_i$表示$U$的第$i$行，用$θ$表示编码器输出的码字。然后，在拼接后，输入到MLP的矩阵的第i行为$[\mathbf{u}_i,θ]$。由于MLP并行应用于输入矩阵的每一行，因此输出矩阵的第$i$行可以写成$f（[\mathbf{u}_i，θ]）$，其中$f$表示由MLP执行的函数。该函数可以看作是一个具有码字$θ$的参数化高维函数，参数$\theta$用于指导函数（折叠操作）的结构。由于MLP很擅长逼近非线性函数，它们可以在二维栅格上执行复杂的折叠操作。高维码字本质上存储了进行折叠所需的力，这使得折叠操作更加多样化。

所提出的解码器有两个连续的折叠操作。第一个是将二维栅格折叠到三维空间，第二个是在三维空间内折叠。我们在表1中显示了这两个折叠操作之后的输出。从表1中的C列和D列可以看出，每个折叠操作都相对简单，这两种折叠操作的组合可以产生相当复杂的表面形状。虽然第一次折叠似乎比第二次折叠更简单，但它们组合在一起导致最终输出的实质性变化。如果需要更精细的表面形状，则可以应用更多的连续折叠操作。解码器的更多变化，包括栅格尺寸的变化和折叠操作的数量，可以在补充部分8中找到。

# Ch03 理论分析

定理3.1. 提出的编码器结构是排列不变的。即：虽然输入点云矩阵的行被重新排列，但是码字保持不变。

证明：详见[补充部分第6节]()。

然后，我们提出了一个关于所提出的基于折叠的解码器的普遍性的定理。它证明了存在一个基于折叠的解码器，通过改变码字$θ$，输出可以是一个任意的点云。

定理3.2. 存在一个2层感知器，它可以使用折叠操作从二维栅格中重建任意的点云。

更具体地说，假设输入是一个大小为$m\times2$的矩阵$U$，这样的$U$的每一行都是大小为$m$的二维栅格上的一个点的二维坐标。然后，存在一个显式构造的2层感知器（手工设置系数），对于任意大小为$m\times3$的三维点云矩阵$S$（其每一行是点云中点的$(x,y,z)$坐标），存在一个码字向量$θ$，如果我们将$θ$与$U$的每一行拼接，然后并行地应用到两层感知器上，就可以从感知器的输出得到点云矩阵$S$。

证明框架：完整的证明见[补充部分第7节]()。在证明中，我们通过显式地构造一个满足所述性质的2层感知器来证明它的存在性。其主要思想表明，在最坏的情况下，二维栅格中的点作为一个选择性的逻辑门，将栅格中的二维点映射到点云中相应的三维点。

请注意，上面的证明只是一个基于存在性的证明，以表明我们的解码器结构是通用的。它并不表明在FoldingNet自动编码器内部实际上发生了什么。理论上构建的解码器需要$3m$个隐藏单元，而实际上，我们使用的解码器的大小要小得多。此外，定理3.2中的构造导致了点云的无损重建，而FoldingNet自动编码器只能实现有损重建。然而，上述定理确实可以保证所提出的解码操作（即将码字与二维栅格点拼接，然后使用感知器处理每一行）是合理的，因为在最坏的情况下存在一个基于折叠的神经网络，使用手工制作的边权值可以重建任意的点云。在现实中，一个良好的解码器的参数化和适当的训练可以获得更好的性能。

# Ch04 实验结果

## 4.1. 训练过程的可视化

解码器如何将2D栅格折叠到3D点云的表面并非显而易见。因此，我们加入了一个训练过程的描述，以展示一个由初始随机折叠得到的随机二维流形如何逐渐变成一个有意义的点云。该自动编码器是一个使用ShapeNet部分数据集[58]独立地训练的FoldingNet，这个ShapeNet部分数据集仅包含ShapeNet数据集中的16个类别。我们使用ADAM训练FoldingNet，初始学习率为$0.0001$，批大小1，动量0.9，动量2为$0.999$，权值衰减$1e−6$，进行$4×10^6$次迭代（即330个周期）。表2报告了多个模型经过不同训练迭代次数后重建的点云。从训练过程中，我们可以看到一个初始的随机二维流形可以通过各种方式被扭曲/切割/压缩/拉伸/附着，从而形成点云曲面。

## 4.2. 点云插值

证明码字提取了输入的自然表示的一种常见方法是，看看自动编码器是否能够在数据集中的两个输入之间实现有意义的新插值。在表3中，我们展示了类间和类内的插值。请注意，我们对此任务的所有形状类别都使用了一个自动编码器。

![image-20231201113021420](/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%B8%89%E7%BB%B4%E5%A4%84%E7%90%86/%E7%82%B9%E4%BA%91/%E7%82%B9%E4%BA%91%E7%89%B9%E5%BE%81/FoldingNet/images/FoldingNet%20Point%20Cloud%20Auto-encoder%20via%20Deep%20Grid%20Deformation/image-20231201113021420.png)

表3：点云插值的描述。前三行：类内插值；后三行：类间插值。

## 4.3. 点云聚类的描述

我们还提供了一个三维点云聚类的描述，该聚类使用FoldingNet获得的码字来实现。我们使用ShapeNet数据集来训练自动编码器，并且获得码字用于ModelNet10数据集。详见[第4.4节]()。然后，我们使用T-SNE [34]在$\mathbb{R}^2$来获得高维码字的嵌入。T-SNE中的参数“困惑度”设置为50。我们在图2中显示了嵌入的结果。从图中我们看到，大多数类很容易分离，除了$\{梳妆台（紫色）v.s. 床头柜（粉红色）\}$和$\{桌子（红色）v.s. 餐桌（黄色）\}$。我们直观检查了这两对类，发现有许多对数据即使是人类也不容易区分。在表4中，我们列出了在对ModelNet10数据集进行分类时最常见的错误。

![image-20231201113923490](/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%B8%89%E7%BB%B4%E5%A4%84%E7%90%86/%E7%82%B9%E4%BA%91/%E7%82%B9%E4%BA%91%E7%89%B9%E5%BE%81/FoldingNet/images/FoldingNet%20Point%20Cloud%20Auto-encoder%20via%20Deep%20Grid%20Deformation/image-20231201113923490.png)

图2：从FoldingNet自动编码器中获得的码字用于T-SNE聚类结果可视化

![image-20231201114033399](/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%B8%89%E7%BB%B4%E5%A4%84%E7%90%86/%E7%82%B9%E4%BA%91/%E7%82%B9%E4%BA%91%E7%89%B9%E5%BE%81/FoldingNet/images/FoldingNet%20Point%20Cloud%20Auto-encoder%20via%20Deep%20Grid%20Deformation/image-20231201114033399.png)

表4：在ModelNet10数据集的分类错误数目排名的前四个。它们的图片详见[补充材料第11节]()

## 4.4. 转移分类精度

在本节中，我们将展示FoldingNet在三维点云表示学习和特征提取中的效率。特别是，我们遵循[1,56]的过程，使用从自动编码器获得的码字（潜在表示）在ModelNet数据集[57]上训练一个线性SVM分类器，同时基于ShapeNet数据集[7]训练自动编码器。ModelNet数据集的训练/测试区分与[41,56]相同。ShapeNet数据集的点云格式是通过从数据集中的网格模型上的三角形上随机采样点获得的。它包含了来自$55$种人造物体的$57447$种模型。ModelNet数据集与[41]中使用的相同，MN40/MN10数据集分别包含9843/3991模型用于训练和2468/909模型用于测试。所选数据集中的每个点云包含2048个点，点云的$(x,y,z)$坐标如[41]一样归一化为一个单位球体。

从FoldingNet自动编码器获得的码字长度为$512$，与[1]中相同，小于[57]中的$7168$。在训练自动编码器时，我们使用了ADAM，初始学习率为$0.0001$，批处理大小为1。我们在ShapeNet数据集上训练了自动编码器进行$1.6×10^7$次迭代（即278个周期）。与[1,41]类似，在训练自动编码器时，我们对每个点云进行了随机旋转。与[1,41]中的随机旋转不同，我们应用了右旋系统中24个轴对齐旋转中的一个旋转。当使用从自动编码器获得的码字训练线性SVM时，我们不使用随机旋转，详见表5。[8,19,26,45]的结果是根据[1,56]的方式报告。由于自动编码器的训练和SVM的训练是基于不同的数据集，实验显示了FoldingNet的转移鲁棒性。我们还提供了一张图（见图3）来显示在训练过程中如何减少重建损失和增加线性SVM的分类精度。从表5中可以看出，FoldingNet在MN40数据集上的性能优于所有其他方法；在MN10数据集上[1]中提出的自动编码器的性能稍好一些。但是，[1]中使用的ModelNet10数据集的点云格式并不公开，所以我们的点云采样协议可能与[1]中的不同。因此，[1]在MN10数据集上是否比我们的更好还不确定。

![image-20231201141811182](/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%B8%89%E7%BB%B4%E5%A4%84%E7%90%86/%E7%82%B9%E4%BA%91/%E7%82%B9%E4%BA%91%E7%89%B9%E5%BE%81/FoldingNet/images/FoldingNet%20Point%20Cloud%20Auto-encoder%20via%20Deep%20Grid%20Deformation/image-20231201141811182.png)

图3：线性SVM分类精度 v.s. ModelNet40数据集上重建损失。使用ShapeNet数据集上的数据训练自动编码器。

![image-20231201141924830](/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%B8%89%E7%BB%B4%E5%A4%84%E7%90%86/%E7%82%B9%E4%BA%91/%E7%82%B9%E4%BA%91%E7%89%B9%E5%BE%81/FoldingNet/images/FoldingNet%20Point%20Cloud%20Auto-encoder%20via%20Deep%20Grid%20Deformation/image-20231201141924830.png)

表5：比较FoldingNet与其他非监督方法的分类精度。所有的方法都在一个从非监督训练中获得的高维表示上训练一个线性SVM。

## 4.5. 半监督学习：当标准数据不足时会发生什么？

研究无监督分类问题的主要动机之一是，标记数据的数量通常比未标记数据的数量要小得多。在[第4.4节]()中，实验非常接近这个设置：ShapeNet数据集中的数据数量很大，超过$5.74×10^4$，而标记的ModelNet数据集中的数据数量很小，约为$1.23×10^4$。由于获取人工标记的数据通常是困难的，我们想测试当标记数据的数量较小时，FoldingNet的性能是如何下降的。我们仍然使用ShapeNet数据集来训练FoldingNet自动编码器。然后，我们只使用ModelNet数据集中整体训练数据的$a\%$来训练线性SVM，其中$a$可以是$1、2、5、7.5、10、15和20$。线性SVM的测试数据使用的是ModelNet数据集的测试数据分区中的所有数据。如果由自动编码器得到的码字已经是线性可分的，那么训练线性SVM所需要的标注数据应该是很小的。为了演示这一直观的陈述，我们在图4中报告了实验结果。我们可以看到，即使只有1%的标记训练数据可用（98个标记训练数据，即每类约1∼3个标记数据），测试准确率仍然超过55%。当20%的训练数据可用时，测试分类准确率已经接近85%，高于表5中列出的大多数方法。

![image-20231201142110690](/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%B8%89%E7%BB%B4%E5%A4%84%E7%90%86/%E7%82%B9%E4%BA%91/%E7%82%B9%E4%BA%91%E7%89%B9%E5%BE%81/FoldingNet/images/FoldingNet%20Point%20Cloud%20Auto-encoder%20via%20Deep%20Grid%20Deformation/image-20231201142110690.png)

图4：线性SVM分类精度 v.s. ModelNet40数据集中有效的有标注训练数据集的百分比

## 4.6. 基于折叠的编码器的效率

在本节中，我们展示了基于折叠的解码器在提取特征方面优于[1]中提出的全连接解码器。我们使用ModelNet40数据集来训练两个深度自动编码器。第一个自动编码器使用基于[第2.2节]()相同结构的解码器，第二个自动编码器使用[1]中提出的全连接的三层感知器。对于全连接解码器，三层的输入数和输出数分别为$\{512、1024\}$、$\{1024、2048\}$、$\{2048、2048×3\}$，与[1]相同。输出是$2048×3$矩阵，其中包含了输出点云的三维点。这两个自动编码器的编码器都是第2.1节中提到的基于图的编码器。当训练自动编码器时，我们在ModelNet40训练数据集上使用初始学习率为$0.0001$的ADAM，批处理大小为1，进行$4×10^6$次迭代（即406个周期）。

经过训练后，我们使用编码器处理ModelNet40数据集中的所有数据，以获得每个点云的一个码字。然后，类似于[第4.4节]()，我们使用这些码字训练一个线性SVM，并报告分类精度，看看这些码字在编码后是否已经线性可分，详见图5。在训练过程中，重建损失（以倒角距离测量）不断减小，这意味着重建的点云与输入点云越来越相似。同时，在码字上训练的线性SVM的分类精度不断提高，这意味着码字表示得更加线性可分离。

![image-20231201142303065](/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%B8%89%E7%BB%B4%E5%A4%84%E7%90%86/%E7%82%B9%E4%BA%91/%E7%82%B9%E4%BA%91%E7%89%B9%E5%BE%81/FoldingNet/images/FoldingNet%20Point%20Cloud%20Auto-encoder%20via%20Deep%20Grid%20Deformation/image-20231201142303065.png)

图5：比较[^1]中的全链接解码器和ModelNet40上的折叠解码器

从图中可以看出，折叠解码器几乎总是具有较高的精度和较低的重建损失。与依赖于三维空间中重建的三维点的非自然“一维顺序”的全连接解码器相比，所提出的解码器依赖于与三维空间内的点云对应的固有的二维流形的折叠。正如我们前面提到的，这种折叠操作比全连接解码器更自然。此外，全连接解码器中的参数数目为$1.52×10^7$，而我们的折叠解码器中的参数数目为$1.05×1066$，约为全连接解码器的$7\%$。

人们可能会想知道，平面上均匀随机采样的二维点在重建点云时是否比二维栅格点表现得更好。从我们的实验来看，二维栅格点确实比随机点提供了更少的重建损失（补充部分8中的表6）。请注意，我们的基于图的最大池编码器可以看作是最大池化神经网络PointNet[41]的一个泛化版本。主要的区别是，编码器中的池化操作是在本地邻域中完成的，而不是在全局环境中完成的（见[第2.1节]()）。在[补充部分10]()中，就点坐标的随机扰动的稳健性而言，我们证明了基于图的编码器架构相比[第2.1.节]()中提及的没有图池化层的编码器要好。

# Ch05 致谢

这项工作得到了MERL的支持。作者要感谢匿名评论家李腾洋、张子明、余志定、陈世恒、田口裕一、迈克·琼斯和艾伦·沙利文的有益评论和建议。

# Ch06 补充材料：定理3.1的证明

使用$\mathbf{L}\in\mathbb{R}^{n\times12}$表示输入矩阵，$\theta$表示由编码器得到的码字，$\mathbf{P}\in\mathbb{R}^{n\times n}$表示转换矩阵。现在我们来证明当输入是$\mathbf{PL}$时，码字依然是$\theta$。

编码器的第一部分是每个点的函数，如：3层感知器应用于输入矩阵$\mathbf{L}$的每一行，若函数是$f_1$，显而易见$f_1(\mathbf{PL})=\mathbf{P}f_1(\mathbf{L})$。第二部分计算等式(2)，则证明如下：
$$
\begin{equation}
\mathbf{PY}=\mathbf{A}_{\max}(\mathbf{PX})\mathbf{K}
\end{equation}
$$
因为$\mathbf{Y}=\mathbf{A}_{\max}(\mathbf{X})\mathbf{K}$，因此我们仅需要证明：
$$
\begin{equation}
\mathbf{A}_{\max}(\mathbf{PX})=\mathbf{PA}_{\max}(\mathbf{X})
\end{equation}
$$
假设置换矩阵$\mathbf{P}$使得$\mathbf{PX}$的第$i$行等于$\mathbf{x}_{\pi(i)}$，其中$\pi(\cdot)$是行序列集合$\{1,2,\ldots,n\}$上的置换函数，则从等式(3)中可得矩阵$\mathbf{A}_{\max}(\mathbf{PX})$的第$(i,j)$项为：
$$
\begin{equation}
(\mathbf{A}_{\max}(\mathbf{PX}))_{ij}=\text{ReLU}(\max_{k\in\mathcal{N}(\pi(i))}x_{kj})
\end{equation}
$$
与此同时，$\mathbf{A}_{\max}(\mathbf{PX})$的第$(\pi(i),j)$项为：
$$
\begin{equation}
(\mathbf{A}_{\max}(\mathbf{PX}))_{\pi(i)j}=\text{ReLU}(\max_{k\in\mathcal{N}(\pi(i))}x_{kj})
\end{equation}
$$
因为等式(6)与等式(7)的右手边是相同的，我们知道矩阵$\mathbf{A}_{\max}(\mathbf{PX})$可以通过将矩阵$\mathbf{A}_{\max}(\mathbf{X})$中的第$i$行置换到第$\pi(i)$行得到，即：$\mathbf{A}_{\max}(\mathbf{PX})=\mathbf{P}\mathbf{A}_{\max}(\mathbf{X})$。因此，我们证明了编码器的第二部分，输入中行的置换等价于输出中行的置换，即：等式(4)成立。

因此，如果我们置换编码器的输入，那么图网络层的输出也被置换。然后，我们应用全局最大池化到图网络层的输出中。很明显，如果全局最大池化层的输入（或图网络层的输出）中行发生置换，那么网络输出的结果将保持不变。从而证明了定理3.1的结论。

# Ch07 补充材料：定理3.2的证明

我们通过显式地构造一个满足所述性质的2层感知器和一个码字向量$θ$，证明了基于存在性的定理3.2。

该码字被简单地选择为点云矩阵$\mathbf{S}$的向量化形式，特别是，对于一个矩阵$\mathbf{S}\in\mathbb{R}^{m\times3}$，如果$\mathbf{S}=[s_{jk}],j=1,2,\ldots,m;k=1,2,3$，码字向量$\theta=[s_{11},s_{12},s_{13},s_{21},s_{22},s_{23},\ldots,s_{m1},s_{m2},s_{m3}]$，则拼接后的第$i$行是$\mathbf{v}_i=[x_i,y_i,s_{11},s_{12},s_{13},s_{21},s_{22},s_{23},\ldots,s_{m1},s_{m2},s_{m3}]$，其中$[x_i,y_i]$是第$i$个2D栅格点的坐标。假设2D栅格点的间距为$2\delta$，即：2D栅格点中任意两点的距离不小于$2\delta$。进一步假设这$m$个栅格点全都可以写作$[x_i,y_i]=[(2\beta_i+1)\delta,(2\gamma_i+1)\delta]$，其中$\beta_i$和$\gamma_i$是两个整数，它们的绝对值小于一个正常数$M$。一个$4\times4$集合的例子如下：
$$
\begin{equation}
\begin{split}
\{
[-3\delta,-3\delta],[-3\delta,-1\delta],[-3\delta,1\delta],[-3\delta,3\delta],\\
[-1\delta,-3\delta],[-1\delta,-1\delta],[-1\delta,1\delta],[-1\delta,3\delta],\\
[+1\delta,-3\delta],[+1\delta,-1\delta],[+1\delta,1\delta],[+1\delta,3\delta],\\
[+3\delta,-3\delta],[+3\delta,-1\delta],[+3\delta,1\delta],[+3\delta,3\delta]
\}
\end{split}
\end{equation}
$$
在本例中，$M=4$，还假设输出点云位于以原点为中心的长度为2的三维的包围盒内，即$|s_{ij}|\leq1$。

现在，我们构造一个两层感知机$f$，输入为行$\mathbf{v}_i$，输出为$f(\mathbf{v}_i)=[s_{i1},s_{i2},s_{i3}],i=1,2,\ldots,m$。输入层中的输入向量$\mathbf{v}_i$有$3m+2$个标量。隐藏层拥有$3m$个神经元。输出层输出三个标量$[s_{i1},s_{i2},s_{i3}]$。隐藏层中$3m$个神经元分为$m$个组，每组$3$个神经元。第$j$组中第$k$个神经元仅连接三个输入$x_i,y_i,[s_{j,k}]$，并计算这三个输入的线性组合：
$$
\begin{equation}
\begin{split}
\alpha_{j1}&=u^2x_j,\\
\alpha_{j2}&=uy_j,\\
\alpha_{j3}&=1
\end{split}
\end{equation}
$$
和偏差：
$$
\begin{equation}
b=-u^2x^2_j-uy^2_j
\end{equation}
$$
其中，$u$是后期指定的正常数。假定线性组合输出是$y_{j,k}$。线性组合紧接一个非线性激活函数：
$$
\begin{equation}
z_{j,k}=
\begin{cases}
y_{j,k},&\text{如果}|y_{j,k}|\le c,\\
0,&\text{如果}|y_{j,k}|\geq c,
\end{cases}
\end{equation}
$$
其中，$c$是后期指定的正常数。激活函数的输出被线性组合以产生最终的输出。在输出层有三个神经元，第$k$个神经元$(k=1,2,3)$计算公式：
$$
\begin{equation}
w_k=\sum_{j=1}^m z_{j,k}
\end{equation}
$$
我们假设参数$(\delta,u,c,M)$满足：
$$
\begin{align}
u>0,c>0,\delta>0,M>0,\\
u\delta^2>c+1,\\
u>8M^2+4M+1,\\
c>1.
\end{align}
$$
现在我们证明了对于这个感知器，当感知器的输入为$\mathbf{v}_i$时，最终的输出$[w_1，w_2，w_3]$确实是$[s_{i1}，s_{i2}，s_{i3}]$。对于第$i$个输入$\mathbf{v}_i=[x_i,y_i,s_{11},s_{12},s_{13},s_{21},s_{22},s_{23}，\ldots,s_{m1},s_{m2},s_{m3}]$，隐藏层第$j$组的第$k$个神经元计算以下线性组合：
$$
\begin{equation}
\begin{split}
y_{j,k}
&=\alpha_{j1}x_i+\alpha_{j2}y_i+\alpha_{j3}s_{j,k}+b\\
&=u^2x_jx_i+uy_jy_i+s_{j,k}-u^2x^2_j-uy^2_j\\
&=u^2x_j(x_i-x_j)+uy_j(y_i-y_j)+s_{j,k}
\end{split}
\end{equation}
$$
请注意，我们已经假定$[x_i,y_i]=[(2\beta_i+1)\delta,(2\gamma_i+1)\delta],\forall i$，因此可得：
$$
\begin{equation}
\begin{split}
y_{j,k}
&=u^2x_j(x_i-x_j)+uy_j(y_i-y_j)+s_{j,k}\\
&=2u^2\delta^2(2\beta_j+1)(\beta_i-\beta_j)+2u\delta^2(2\gamma_j+1)(\gamma_i-\gamma_j)+s_{j,k}\\
&=u^2\delta^2m_1+u\delta^2m_2+s_{j,k}
\end{split}
\end{equation}
$$
其中，两个整数常量：$m_1=2(2\beta_j+1)(\beta_i-\beta_j),m_2=2(2\gamma_j+1)(\gamma_i-\gamma_j)$，当且仅当$x_i=x_j$时$m_1=0$，$y_i=y_j$时$m_2=0$。因为$\beta_i,\beta_j,\gamma_i,\gamma_j$的绝对值都比$M$小，可得：
$$
\begin{align}
|m_1|\leq2|2\beta_j+1|\cdot|\beta_i-\beta_j|<2(2M+1)\cdot2M=8M^2+4M\\
|m_2|\leq2|2\gamma_j+1|\cdot|\gamma_i-\gamma_j|<2(2M+1)\cdot2M=8M^2+4M
\end{align}
$$
现在，考虑三种可能的案例：

- $|m_1|\geq1$：

$$
\begin{equation}
\begin{split}
|y_{j,k}|
&=|u^2\delta^2m_1+u\delta^2m_2+s_{j,k}|\\
&>u^2\delta^2|m_1|=u\delta^2|m_2|-|s_{j,k}|\\
&>u^2\delta^2-u\delta^2(8M^2+4M)-1\\
&=u\delta^2[u-(8M^2+4M)]-1\\
&>(c+1)\cdot1-1=c
\end{split}
\end{equation}
$$

最后一行依据假设等式(14)得到。

- $m_1=0,|m_2|\geq1$：

$$
\begin{equation}
\begin{split}
|y_{j,k}|
&=|u\delta^2m_2+s_{j,k}|\\
&\geq u\delta^2|m_2|-|s_{j,k}|\\
&\geq u\delta^2\\
&\geq c+1>c
\end{split}
\end{equation}
$$

最后一行依据假设等式(15)得到。

- $m_1=m_2=0$

$$
\begin{equation}
|y_{j,k}|=|s_{j,k}|\leq1<c
\end{equation}
$$

最后一步依据假设等式(16)得到。

请注意，前面两个等式等价于$i\neq j$，最后一个等式等价于$i=j$。因此，由等式(11)得到：
$$
\begin{equation}
z_{j,k}=
\begin{cases}
s_{j,k}, &\text{如果}j=i\\
0,&\text{如果}j\neq i
\end{cases}
\end{equation}
$$
因此，由等式(12)得到：
$$
\begin{equation}
w_k=\sum_{j=1}^m z_{j,k}=s_{i,k},\quad k=1,2,3
\end{equation}
$$
这意味着输入是$\mathbf{v}_i$，输出就是$[s_{i,1},s_{i,2},s_{i,3}]$，证明结束。

# Ch08 补充材料：解码器变形

目前的解码器设计有两个连续的折叠操作，应用于一个二维栅格上。因此，人们可能会想，如果我们使用(1)更多的折叠操作或(2)在不同维度的规则栅格上使用相同数量的折叠操作，FoldingNet的性能是否能得到提高。在本节中，我们将报告这些不同设置的结果。实验设置与[第4.6节]()相同，实验结果如表6所示。从第1行和第2行可以看出，增加折叠操作的次数并不会显著提高性能。比较第1行和第3行，我们可以看到二维栅格在分类和重建方面都优于一维网格。从第1行和第4行可以看到3D栅格只带来微小的改进。正如我们在引言中讨论的，这是因为ShapeNet数据集和ModelNet数据集内的数据的内在维数是2，因为它们是从对象表面采样的。如果点云本质上是体积的，我们认为在解码器中使用三维栅格更合适。此外，我们还尝试在平面上通过均匀随机采样的方法生成固定栅格。然而，它还导致了更差的结果。我们认为这是随机采样引入的局部密度变化引起的。

![image-20231201165355732](/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%B8%89%E7%BB%B4%E5%A4%84%E7%90%86/%E7%82%B9%E4%BA%91/%E7%82%B9%E4%BA%91%E7%89%B9%E5%BE%81/FoldingNet/images/FoldingNet%20Point%20Cloud%20Auto-encoder%20via%20Deep%20Grid%20Deformation/image-20231201165355732.png)

表6：不同FoldingNet解码器的比较。“Uniform”：栅格是均匀地随机采样；“Regular”：栅格基于固定距离规则采样。

# Ch09 补充材料：通过解卷积实现折叠

定义1中的折叠操作本质上是一个从二维栅格到三维曲面的逐点的二维到三维的函数。一个很自然的问题是，在相邻栅格点上的函数中引入显式的相关性是否有助于提高性能。我们注意到，有一个密切相关的工作，基于图像使用边信息重建三维点集[17]。[17]中的点重建网络利用反卷积来融合来自于图像所施加在规则栅格结构上的信息，这与本文思想相似。在这里，我们比较了一个反卷积网络与折叠网络的重建性能，详见表7。反卷积网络（C×H×W）的特征大小为$512\times1\times1$→$256\times3\times3$→$128\times5\times5$→$64\times15\times15$→$3\times45\times45$，核大小为$3,3,5,5$。我们推测反卷积超越了逐点操作，从而对重建曲面的光滑性施加了更强的约束。因此，它的重建效果更差（尽管具有相当的分类精度）。而在折叠网中使用的逐点MLP的栅格只施加了一个隐式约束，从而导致了更好的重构。

![image-20231201170454870](/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%B8%89%E7%BB%B4%E5%A4%84%E7%90%86/%E7%82%B9%E4%BA%91/%E7%82%B9%E4%BA%91%E7%89%B9%E5%BE%81/FoldingNet/images/FoldingNet%20Point%20Cloud%20Auto-encoder%20via%20Deep%20Grid%20Deformation/image-20231201170454870.png)

表7：比较两种不同实现的折叠操作。

# Ch10 补充材料：基于图的编码器的稳健性

在这里，我们使用一个实验来表明，当数据受到随机噪声的影响时，图池化层对于保持FoldingNet的良好性能是有用的。下面的实验比较了FoldingNet和深度自动编码器，该自动编码器与基于折叠的解码器具有相同的架构，但是不同的编码器架构，在该自动编码器中基于图的最大池化层被删除。实验的设置与[第4.6节]()相同，只是ModelNet40数据集中每个点云中的$5\%$的点被随机移动到其他位置（但仍在原始点云的边界框内）。我们使用这些噪声数据来查看基于图的编码器和没有基于图的最大池化层的编码器的性能是如何降低的。结果报告如图6所示。我们可以看到，当噪声被注入到数据集中时，移除了图的最大池化层的模型性能退化大约$2\%$，而FoldingNet的分类精度变化不大（与[第4.6节]()中的图5相比）。由此可以看出，基于图的编码器可以使得FoldingNet更加稳健。

![image-20231201171250561](/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%B8%89%E7%BB%B4%E5%A4%84%E7%90%86/%E7%82%B9%E4%BA%91/%E7%82%B9%E4%BA%91%E7%89%B9%E5%BE%81/FoldingNet/images/FoldingNet%20Point%20Cloud%20Auto-encoder%20via%20Deep%20Grid%20Deformation/image-20231201171250561.png)

图6：比较第2.1节中基于图的编码器和移除了基于图的最大池化层的编码器。未基于图的编码器与[^41]中提出的相似，只是[^41]中目标是有监督学习。

# Ch11 补充材料：ModelNet10上线性SVM实验的更多细节

[第4.4节]()对MN10数据集的分类准确率为$94.4\%$。我们在[第4.5节]()中指出，许多被错误分类的数据对对于人类也很难区分。在表中，我们列出了所有不正确分类的模型及其点云表示。像“table→desk”这样的短语是指点云带有“table”的标签，但它被线性SVM错误地归类为“desk”。

![image-20231201173234332](/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%B8%89%E7%BB%B4%E5%A4%84%E7%90%86/%E7%82%B9%E4%BA%91/%E7%82%B9%E4%BA%91%E7%89%B9%E5%BE%81/FoldingNet/images/FoldingNet%20Point%20Cloud%20Auto-encoder%20via%20Deep%20Grid%20Deformation/image-20231201173234332.png)
