---
title: FoldingNet：通过深度栅格变形技术实现的点云自动编码器
excerpt: 形状补全，是许多视觉和机器人应用的核心问题。目标是从部分观测中估计对象的完整几何形状。在本文中，我们提出了点补全网络（Point Completion Network, PCN），一种新颖的基于学习的形状补全方法。与现有的形状补全方法不同，PCN直接对原始点云进行操作，没有任何关于底层形状的结构假设（如：对称性）或者标注（如：语义类别）。它的特点是一个解码器的设计，能够生成细粒度的补全，同时维护少量的参数。我们的实验表明，PCN在基于不同水平的不完整数据和噪声的输入（包括来自KITTI数据集中使用激光雷达扫描得到的汽车数据）下都在现实结构的缺失区域中补全了稠密的、完整的点云。
categories:
  - 点云特征
tags:
  - 点云特征
  - 折叠网络
  - FoldingNet
  - ShapeNet
  - ModelNet
date: 2023-11-28
updated: 2023-11-28
toc: true
typora-root-url: D:\Projects\Github\zhuyuanxiang\hexo_pages\hexo-starter\source\_posts\
---

# FoldingNet：通过深度栅格变形技术实现的点云自动编码器

Yang Y, Feng C, Shen Y, et al.  Foldingnet: Point cloud auto-encoder via deep grid  deformation[C]//Proceedings of the IEEE conference on computer vision  and pattern recognition. 2018: 206-215.

[原始论文](https://arxiv.org/pdf/1712.07262v2.pdf)

[中文翻译](https://zhuyuanxiang.github.io/pdfs/机器学习/计算机视觉/三维处理/点云/FoldingNet/FoldingNet：通过深度栅格变形技术实现的点云自动编码器.pdf)

[原始代码_PyTorch](https://github.com/AnTao97/UnsupervisedPointCloudReconstruction)

[论文作者实验室主页]([Software & Data Downloads | Mitsubishi Electric Research Laboratories (merl.com)](https://www.merl.com/research/license#FoldingNet))

ToDo:网格→栅格；重构→重建；折叠网→FoldingNet；

# 摘要

最近的深度网络，直接处理点集中的点，例如：PointNet，已经成为有监督的点云学习任务（如：分类和分割）中最先进的方法。在本文中，我们提出了一种全新的基于深度学习的端到端的自动编码器来解决点云上的无监督学习问题。在编码器方面，强制执行基于图的增强，以促进点网之上的局部结构。然后，一种新型的基于折叠的解码器将规范的二维栅格变形到点云的潜在三维对象表面上，即使对于具有精细结构的物体，也能获得较低的重建误差。该解码器只使用全连接神经网络解码器的约7%的参数，然而获得了更具识别力的表示，实现了比基准（线性SVM）更高的分类精度。此外，所提出的解码器结构在理论上是一种通用的，能够从二维栅格重建任意点云的架构。

# Ch01 简介

三维点云的处理和理解通常被认为比二维图像更具挑战性，这主要是因为点云样本具有不规则的结构，而二维图像样本（像素）依赖于图像平面上具有规则间距的二维栅格。点云几何通常是由一组稀疏的三维点表示。这种数据格式使得传统的深度学习框架难以应用。例如，对于每个样本，传统的卷积神经网络（CNN）要求其相邻的样本出现在一些固定的空间方向和距离上，以方便卷积。不幸的是，点云样本通常不满足这样的约束条件。缓解这个问题的一种方法是模拟图像的表示方式对点云进行体素化，然后对体素进行操作。体素化的缺点是，要么牺牲表示精度，要么接受巨大的冗余。选择的结果，要么性能受损，要么处理的复杂度快速增加，这都可能会在后续的操作中造成不必要的成本。相关技术的回顾参见（Sec1.1.）。

在本文中，我们关注的是新兴领域的无监督学习的点云。我们提出了一种自动编码器（Auto-Encoder，AE），它被称为折叠网络（FoldingNet）。从自动编码器中的瓶颈层得到的输出称为码字（codeword），可以用作输入点云的高维嵌入。我们将展示一个二维的栅格结构，其不仅是一个影像的采样结构，实际上还可以通过提出的折叠（folding）操作来构建一个点云。基于我们感兴趣的三维点云观察得出了三维点云重建的结论，这些三维点云是从物体表面获得的：要么是从CAD/计算机图形中的边界的离散化表示得到，要么是从像激光雷达这样的视线传感器采样得到。直观地说，任何三维物体表面都可以通过某些操作：切割、压缩和拉伸等转换为二维平面。反过程是通过某些折叠操作将这些二维点样本粘合回物体表面，这些折叠操作被初始化为二维栅格样本。如表1所示，为了重建一个点云，需要连接起来的、连续的折叠操作来再现表面结构。这些点被着色，以显示初始的二维栅格样本与重建的三维点样本之间的对应关系。利用基于折叠的方法，通过在解码器中直接引入这种隐式二维栅格约束，可以很好地解决点云不规则结构的挑战，避免了其他工作[56]中三维体素化的计算成本。稍后将证明，如果有适当的码字，折叠操作可以构建任意曲面。请注意，当数据来自体素格式而不是二维曲面时，三维栅格可能会表现得更好。

![image-20231128170958341](/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%B8%89%E7%BB%B4%E5%A4%84%E7%90%86/%E7%82%B9%E4%BA%91/%E7%82%B9%E4%BA%91%E7%89%B9%E5%BE%81/FoldingNet/images/FoldingNet%20Point%20Cloud%20Auto-encoder%20via%20Deep%20Grid%20Deformation/image-20231128170958341.png)

表1：两步折叠解码的说明。第一列：包含了来自ShapeNet数据集[57]的原始点云示例。第二列：说明了在解码过程中要折叠的二维栅格点。第三列：包含了一次折叠操作后的输出。第四列：包含了两次折叠操作后的输出。这个输出也是重建的点云。我们使用一个颜色梯度来说明第二列中的二维栅格与最后两列中折叠操作后重建的点云之间的对应关系。使用颜色得到最佳观察。

尽管折叠操作在重构点云方面具有很强的表达力，但其本质很简单：它首先用从编码器获得的码字来增强二维栅格点，然后通过一个3层感知器进行处理。所提出的解码器是两个折叠操作的连接。这种设计使所提出的解码器在参数尺寸上比最近在[1]中提出的全连接解码器要小得多。在(Sec4.6.)中，我们展示了基于折叠的解码器的参数数量约为[1]中全连接解码器的7%。虽然提出的解码器结构简单，但是我们依然在定理3.2中从理论上证明了这种基于折叠的结构的普适性，因为仅使用2层感知器的折叠操作已经可以生成任意的点云结构。因此，我们的FoldingNet自动编码器利用两个连续的折叠操作可以产生复杂的结构就不足为奇了。

为了展示折叠网自动编码器在无监督表示学习中的效率，我们遵循了[1]中的实验设置，并测试了从ShapeNet数据集[7]到ModelNet数据集[57]的按类别的转换精度。利用ShapeNet数据集训练折叠网自动编码器，并通过从ModelNet数据集中提取码字进行测试。然后，我们训练一个线性SVM分类器来测试所提取的码字的识别有效性。在具有40个形状类别的ModelNet数据集上，转换后分类准确率为88.4%。这种分类化精度甚至接近于最先进的监督训练结果[41]。为了获得最佳的分类性能和最小的重构损失，我们使用了一种不同于[41]的基于图形的编码器结构。这个基于图形的编码器是基于局部特征池操作的思想，能够沿着图的结构检索和传播局部结构信息。

为了直观地解释我们的网络设计：我们想要使二维栅格基于一个“虚拟力”来变形/切割/拉伸到三维物体表面，这种变形力应该受到点阵邻域产生的互连的影响或调节。由于解码器中的中间折叠步骤和训练过程可以用重建点来说明，因此可以通过可视化地折叠力来观察它的逐渐变化。

现在，我们总结一下我们在这项工作中的贡献：

- 我们训练了一个直接使用无序点云的端到端深度自动编码器。
- 我们提出了一种新的折叠解码操作，并从理论上证明了它在点云重建中是通用的，同时将重建点的顺序作为唯一的副产品。
- 我们在主要数据集上的实验表明，折叠将比其他非监督方法获得更高的分类精度。

## 1.1. 相关工作

学习在点云上的应用包括形状补全和识别[57]、无人驾驶汽车[36]、三维目标检测、识别和分类[9,33,40,41,48,49,53]、轮廓检测[21]、布局推理[18]、场景标记[31]、类别发现[60]、点云分类、稠密标记和分割[3,10,13,22,25,27,37,41,54,55,58]。

大多数为三维点云设计的深度神经网络都是基于将三维空间划分为规则体素并将二维CNN扩展到体素的想法，如[4,11,37]，包括三维生成对抗网络[56]的工作。基于体素的网络的主要问题是神经网络的规模随着空间分辨率的增大而快速增长。其他一些为三维点云设计的深度神经网络则是：基于八叉树的[44]和基于KD树的[29]。最近，有研究表明，基于纯三维点表示的神经网络[1,41-43]对点云的工作相当有效。基于点的神经网络可以减少将点云转换为其他数据格式（如八叉树和体素）的开销，同时避免了转换造成的信息损失。

我们所知道的关于直接处理点云的端到端深度自动编码器的唯一工作是[1]。在[1]中设计的自动编码器是为了提取生成网络的特征。为了进行编码，它使用字典顺序对三维点进行排序，并对点序列应用一维CNN。为了解码，它应用了一个三层全连接的网络。在从ShapeNet数据集到ModelNet数据集[1]转移的分类精度方面，这个简单的结构优于所有现有的无监督工作。我们的方法具有一个基于图的编码器和一个基于折叠的解码器，在ModelNet40数据集[1]上转移的分类精度方面优于该方法[^1]。此外，与[1]相比，我们设计的自动编码器更容易解释：编码器学习局部形状信息并且与近邻图上的最大池化信息合并，而解码器使用获得的信息学习一个“力”两次，并将该力用于折叠二维栅格从而扭曲栅格成点云的形状。另一个密切相关的工作是从2D图像中重建点云[^17]。虽然[^17]中解卷积网络需要一个2D图像作为边缘信息，我们发现我们的折叠操作的另一种实现是有用的。我们将FoldingNet与基于反卷积的折叠网络进行了比较，结果表明FoldingNet在重建误差方面的表现略好（见补充部分9）。

纯粹的基于点的神经网络很难提取出点周围的局部邻域结构，即相邻点的特征，而不是单个点的特征。在[1,42]中有些研究已经进行了一些尝试。在本项工作中，我们利用一个基于图的框架来利用局部邻域特征。对图结构数据的深度学习并不是一个全新的想法，有大量的工作讨论了将深度学习应用于不规则数据。虽然使用图作为点云深度学习的处理框架是一个自然的想法，但只有几个开创性的工作在这个方向上做了尝试。这些工作试图将卷积操作从二维图像推广到图形中。然而，由于很难在图上定义卷积操作，我们使用了一个简单的基于图的神经网络层，这与以前的工作不同：我们构造了k-最近邻图（K-Nearest Neighbor Graph, KNNG），并在每个节点的邻域重复进行最大池操作，这是对[41]中提出的全局最大池操作的泛化操作，即最大池只应用于每个局部邻域来生成局部数据签名。与上述基于图的卷积网络相比，我们的设计更简单，计算效率更高。K-NNGs也被用于其他没有深度学习框架的点云的应用，如：表面检测、三维对象识别、三维对象分割与压缩[20,50,51]。

从二维栅格重建曲面的折叠操作本质上建立了从二维规则域到三维点云的映射。一个疑问油然而生：我们是否可以用兼容的网格来参数化三维点，这些网格不一定是规则的栅格，比如交叉参数化[30]。从表2来看，FoldingNet似乎可以学习在二维栅格上生成“切割”，并且生成的曲面与二维栅格并非拓扑等价，从而使二维栅格的表示在某种程度上是通用的。尽管如此，当原始表面太复杂时，重建的点仍然可能存在逐类别的扭曲。例如，在表2中，我们看到了重建平面上缺失的小翼和重建椅背上缺失的孔。为了恢复这些更精细的细节，可能需要更多的输入点样本和更复杂的编码器/解码器网络。另一种学习表面嵌入的方法是学习[16]中的度量对齐层，这可能在训练过程中需要对计算进行密集的内部优化。

![image-20231130165006521](/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%B8%89%E7%BB%B4%E5%A4%84%E7%90%86/%E7%82%B9%E4%BA%91/%E7%82%B9%E4%BA%91%E7%89%B9%E5%BE%81/FoldingNet/images/FoldingNet%20Point%20Cloud%20Auto-encoder%20via%20Deep%20Grid%20Deformation/image-20231130165006521.png)

表2：训练过程的描述。随机2D流形逐渐地变换到点云表面。

## 1.2. 前置条件和符号

我们经常用$S$表示点集。用小写加粗字母来表示向量，如$\mathbf{x}$；用大写加粗字母表示矩阵，如$\mathbf{A}$。码字总是用$\mathbf{\theta}$表示。如果一个矩阵有$m$行和$n$列，我们称它为`m-by-n`或$m\times n$。

# Ch02 点云上的FoldingNet自动编码器

现在我们提出了FoldingNet深度自动编码器。自动编码器的结构如图1所示。编码器的输入是一个n乘3的矩阵。矩阵的每一行都由三维坐标$(x,y,z)$组成。输出是一个m乘3的矩阵，表示重建的点的位置。重建点的个数m不一定与输入点的个数n相同。假设输入点集为$S$，重建点集为$\hat{S}$。然后，使用定义为（扩展的）倒角距离的层来计算$\hat{S}$的重建误差：
$$
\begin{equation}
d_{CH}(S,\hat{S})=
\max\{
\frac1{|S|}\sum_{\mathbf{x}\in S}\min_{\hat{\mathbf{x}}\in\hat{S}}\|\mathbf{x}-\hat{\mathbf{x}}\|_2,
\frac1{|S|}\sum_{\hat{\mathbf{x}}\in\hat{S}}\min_{\mathbf{x}\in S}\|\hat{\mathbf{x}}-\mathbf{x}\|_2
\}
\end{equation}
$$
其中，$\min_{\hat{\mathbf{x}}\in\hat{S}}\|\mathbf{x}-\hat{\mathbf{x}}\|_2$强制原始点云中的任何三维点$\mathbf{x}$在重建的点云中都有一个匹配的三维点$\hat{\mathbf{x}}$，而$\min_{\mathbf{x}\in S}\|\hat{\mathbf{x}}-\mathbf{x}$强制了相反的匹配。$\max()$运算强制执行从$S$到$\hat{S}$的正向距离和反向距离必须同时较小。编码器计算每个输入点云的表示（码字），解码器使用这个码字重构点云。在我们的实验中，根据[1]，将码字长度设置为512。

![image-20231130172538536](/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E4%B8%89%E7%BB%B4%E5%A4%84%E7%90%86/%E7%82%B9%E4%BA%91/%E7%82%B9%E4%BA%91%E7%89%B9%E5%BE%81/FoldingNet/images/FoldingNet%20Point%20Cloud%20Auto-encoder%20via%20Deep%20Grid%20Deformation/image-20231130172538536.png)

图1：FoldingNet 架构。图网络层是基于图的最大池化层，详见[Sec2.1.]()的等式(2)。第1个折叠与第2个折叠都是通过将码字拼接到特征向量上，然后再后接一个三层感知器来实现的。每个感知器独立地应用于单个点的特征向量上，就如[^41]中将感知器应用到$m\times n$矩阵的行上。

## 2.1. 基于图的编码器架构

基于图的编码器遵循了[46]中类似的设计，在[^46]中侧重于使用点云邻域图进行监督学习。编码器是一个多层感知器（MLP）和基于图的最大池化层的拼接。图是由输入点集中节点的三维坐标构造出来的K-NNG。在实验中，我们选择了$K = 16$。首先，对于每一个单点$v$，我们计算其大小为3乘3的局部协方差矩阵，并将其向量化为1乘9。$v$的局部协方差是利用K-NNG中节点$v$（包含$v$）的一跳邻居的点的三维坐标来计算的。我们将大小为$n\times3$的点坐标矩阵和所有大小为$n\times9$的点的局部协方差矩阵拼接成一个大小为$n\times12$的矩阵，并将它们输入到一个3层感知器。感知器并行地应用到大小 为$n\times12$的输入矩阵的每一行。它可以看作是每个三维点上的单点函数。感知器的输出被输入到两个连续的图网络层，其中的每一层都对每个节点的邻域执行最大池化。更具体地说，假设K-NN图具有邻接矩阵$\mathbf{A}$，并且图网络层的输入矩阵为$\mathbf{X}$，则输出矩阵为：
$$
\begin{equation}
\mathbf{Y}=\mathbf{A}_{\max}(\mathbf{X})\mathbf{K}
\end{equation}
$$
其中，$\mathbf{K}$是特征映射矩阵，矩阵$\mathbf{A}_{\max}(\mathbf{X})$的第$(i,j)$项：
$$
\begin{equation}
(\mathbf{A}_{\max}(\mathbf{X}))_{ij}=\mathbf{ReLU}(\max_{k\in\mathcal{N}(i)}x_{kj})
\end{equation}
$$
等式(3)中局部最大池化操作$\max_{k\in\mathcal{N}(i)}x_{kj1}$在本质上是基于图结构的计算一个局部签名。此签名可以表示局部领域的（聚合的）拓扑信息。通过对基于图的最大池化层的拼接，网络将拓扑信息传播到更大的区域。

## 2.2. 基于折叠的解码器结构

该解码器使用两个连续的三层感知器将一个固定的二维栅格扭曲成输入点云的形状。输入码字是从基于图的编码器中获得的。在我们将码字输入解码器之前，我们将它复制$m$次，并将$m\times512$矩阵与一个$m\times2$矩阵拼接起来，该矩阵包含一个以原点为中心的正方形上的$m$个栅格点。拼接的结果是一个大小为$m\times514$的矩阵。该矩阵由一个$3$层感知器逐行处理，输出为一个大小为$m\times3$的矩阵。在那之后，我们再次将复制的码字连接到$m\times3$输出中，并将其输入一个3层感知器。这个输出是重建的点云。参数$n$是根据输入点云的大小来设置的，如我们的实验中的$n = 2048$，它与[1]相同。我们在一个平方中选择$m$个栅格点，所以选择$m=2025$，这是最接近$2048$的平方数。

定义1。我们将复制的码字拼接到低维的栅格点，然后紧接一个逐点MLP称为折叠操作。

折叠操作本质上形成了一个通用的2D到3D的映射。为了直观地理解其本质，用矩阵$U$表示输入的二维栅格点。$U$的每一行都是一个二维栅格点，用$\mathbf{u}_i$表示$U$的第$i$行，用$θ$表示编码器输出的码字。然后，在拼接后，输入到MLP的矩阵的第i行为$[\mathbf{u}_i,θ]$。由于MLP并行应用于输入矩阵的每一行，因此输出矩阵的第$i$行可以写成$f（[\mathbf{u}_i，θ]）$，其中$f$表示由MLP执行的函数。该函数可以看作是一个具有码字$θ$的参数化高维函数，参数$\theta$用于指导函数（折叠操作）的结构。由于MLP很擅长逼近非线性函数，它们可以在二维栅格上执行复杂的折叠操作。高维码字本质上存储了进行折叠所需的力，这使得折叠操作更加多样化。

所提出的解码器有两个连续的折叠操作。第一个是将二维栅格折叠到三维空间，第二个是在三维空间内折叠。我们在表1中显示了这两个折叠操作之后的输出。从表1中的C列和D列可以看出，每个折叠操作都相对简单，这两种折叠操作的组合可以产生相当复杂的表面形状。虽然第一次折叠似乎比第二次折叠更简单，但它们组合在一起导致最终输出的实质性变化。如果需要更精细的表面形状，则可以应用更多的连续折叠操作。解码器的更多变化，包括栅格尺寸的变化和折叠操作的数量，可以在补充部分8中找到。

