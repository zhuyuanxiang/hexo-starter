# PointNet：基于点的集合的深度学习解决三维分类和分割问题

[PointNet Deep Learning on Point Sets for 3D Classification and Segmentation.arXiv.pdf](https://arxiv.org/abs/1612.00593)

Qi C R, Su H, Mo K, et al. Pointnet: Deep learning on point sets for 3d classification and segmentation[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 652-660.

[项目地址](http://stanford.edu/~rqi/pointnet/)

[GitHub Tensorflow 实现](https://github.com/charlesq34/pointnet)

[GitHub PyTorch 实现](https://github.com/fxia22/pointnet.pytorch)

[GitHub PyTorch 中文化](https://github.com/zhuyuanxiang/pointnet.pytorch/tree/cn-pytorch1.8.0)

翻译的原文地址

# 摘要

点云是几何数据结构的一种重要类型。由于其不规则的格式，大多数研究人员将此类数据转换为规则的3D体素栅格或者图像集合。然而，这样的操作导致数据渲染时需要面对大量的多余数据，及衍生的其他问题。为此，我们在本文中设计了一种新颖的直接使用点云数据的神经网络，并且很好地考虑了输入数据中点排列的不变性。网络名称是：PointNet，提供了从对象分类、部件分割到场景语义解析各种应用的统一架构。PointNet 简单、高效、质量好，实践证明：网络效果超越当前最好成绩。我们还通过理论分析理解了：网络学到了什么，以及网络面对数据干扰和数据丢失依然稳健的原因。

# Sec01 介绍

在本文中，我们探索了能够推理三维几何数据（如：点云或者网格）的深度学习架构。典型的卷积架构需要高度规则的输入数据格式（如：图像栅格或者3D体素），以便执行权重共享和其他核优化操作。因为点云和网格不是规则的数据，大多数研究人员通常将此类数据转换为规则的3D体素栅格或者图像的集合（如：视图），然后将转换后的数据送入深度网络结构。然而，这种数据表示的转换使得渲染时需要面对不必要的大规模的数据，而且会在量化时引入人工伪影，这个会遮掩数据的自然不变性。

因此，我们将重点放在基于简单点云的3D几何图形的输入表示上，并且将由此产生的深度网络命名为*PointNet*。点云是简单且统一的结构，可以避免网格数据中组合的不规则性和复杂性，因此更容易学习。然而，PointNet仍然需要尊重一个事实，即点云只是一组点的集合，因此其具有成员排列的不变性，在网络计算中需要一定的对称性，还需要考虑刚性运动的不变性。

![image-20211213163752101](images/机器学习/计算机视觉/三维处理/点云/点云特征/PointNet/image-20211213163752101.png)

图1：PointNet的应用。我们提出一个新颖的深度网络架构，它可以直接使用原始的点云数据（点的集合）而不需要体素化或者渲染。这个统一的架构既可以学习全局点特征，还可以学习局部点特征，并且提供一个简单的、有效的并且高效的方法，用于处理许多3D识别任务。

我们的PointNet是一个统一的架构（详见图1），输入是点云，输出既可以是整个输入的类标签，还可以是输入的每个点其对应的点分割标签或点部件标签。这个网络的基本结构非常简单，因为在初始阶段每个点都是独立地并且采用相同的方法进行处理。在基本设置中，每个点仅由其三个坐标$(x,y,z)$进行表示，还可以通过计算法线和其他局部或者全局特征来增加维度。

我们方法的关键是使用单对称函数：最大池化（Max Pooling）。网络有效地学习了一组优化函数/准则，这组函数/准则选择了点云中感兴趣的或者有信息的点，并且编码了这种选择。网络的最后一层（全连接层）将这些学习到的最优值进行处理，或者将它们聚集到整个形状的全局描述符中（形状分类），或者将它们用于每个点的标签预测（形状分割）。

因为每个点的变换都是独立的，所以输入格式很容易应用到刚性变换或者仿射变换。因此，通过添加一个依赖数据的空间变换网络，可以先规范化数据，再经PointNet处理，从而进一步改善预测的结果。

本文描述了我们提出的方法的理解与分析及实验评估，证明了此网络可以逼近任意的连续的集合函数。更有意思的是，我们的网络竟然是通过一组稀疏的关键点实现了对输入点云的学习和总结，这些关键点大致跟可视化对象的框架具有对应关系。理论分析提供了一种理解，在对抗数据扰动（输入点）以及数据破坏（点插入/异常值或者点删除/数据缺失）上，PointNet为什么具有高度的稳健性。

在形状分类、部件分割及场景分割一系列基准数据集上，我们将PointNet和基于其他表示（多视图和体素）的最先进方法进行了对比。基于统一架构上，相比基准性能或者更先进的方法，PointNet不仅速度更快，而且性能更好。

我们工作的主要贡献如下：

- 设计了一个新颖的、适合处理3D中无序点集的深度网络架构；
- 展示了怎样训练这类网络去执行3D形状分类、形状部件分割和场景语义解析任务；
- 提供了该方法在稳定性和效率方面的全面的理论分析和实例验证；
- 阐述了在网络中由选定的神经元计算3D特征，并对其性能进行直观地解释

# Sec02 相关工作

## 2.1 点云特征

现存的大多数针对特定任务的点云特征都是人工生成的。点特征通常为点的某些统计特征编码，并且通过设计使其具有某些变换的不变性。这些特征可以分类为内在特征[^2][^24][^3]或者外在特征[^20][^19][^14][^10][^5]，还可以分类为局部特征或者全局特征。找到特定任务的最佳特征组合并非易事。

## 2.2 3D数据的深度学习

3D数据具有多种流行的表示形式，也导致了不同的学习方式：

- 体素（Volumetric）CNN：[^28][^17][^18]是在3D卷积神经网络上应用体素形状的先驱。然而，因为数据的稀疏性和3D卷积的计算代价，使得体素表示受限于其分辨率。FPNN[^13]和Vote3D[^26]提出了处理稀疏问题的特殊方法，但是它们的操作仍然在稀疏的体积上，这对处理非常大的点云仍然是个挑战。
- 多视图（Multiview）CNN：[^23][^18]试图将3D点云或者形状渲染成2D图像，然后应用2D卷积网络对其分类。利用精心设计的图像CNN，这一系列方法的性能在形状分类和检索任务中获得了显著提升[^21]。然而，将这些方法扩展到场景理解或者其他3D任务（如：点分类和形状修复）中是不容易的。
- 谱（Spectral）CNN：一些最新的工作[^4][^16]在网格上使用谱CNN。然而，目前这些方法仅限于流形网格上（如：生物对象），并且没有扩展到非等距形状（如：家具）上的方法。
- 基于特征的（Feature-Based）CNN：[^6][^8]首先通过抽取经典的形状特征将3D数据转换为一个向量，并且使用全连接网络来分类这个形状。我们认为这些方法受到抽取的特征的表示能力的限制。

## 2.3 无序集合上的深度学习

从数据结构的角度来看，点云是一组无序的向量集合。虽然深度学习的大部分工作侧重于规则的输入表示，如：序列（语音处理和语言处理）、图像和体积（视频或者3D数据），但是很少有工作基于点集合的深度学习。

最近的一项工作是来自于Oriol Vinyals 等人[^25]对这个问题的探索。他们使用一个具有注意力机制的“边读取-边处理-边写入”的网络去处理无序的输入集合，并且展示了其网络具备的数字排序能力。然而，因为他们的工作侧重于通用的集合和NLP的应用，因此缺乏对集合中存在的几何形状的处理能力。

# Sec03 问题陈述

我们设计了一个深度学习框架，可以直接使用无序的点集作为输入。点云可以表示为一组3D点的集合$\{P_i|i=1,\cdots,n\}$，其中每个点$P_i$是一个向量，由其$(x,y,x)$坐标加上额外的特征通道（如：颜色、法向等）组成。为了简单明了，除非另有说明，我们仅使用$(x,y,z)$作为点的通道。

对于对象分类任务，输入的点云既可以直接从形状中抽样，还可以是预分割的场景点云。我们提出的深度网络对于全部$k$个候选类别输出$k$个分数。对于语义分割，输入可以是部件区域分割的单个对象，或者是对象区域分割的3D场景的子体。我们的模型对于$n$个点中的每个点、$m$个语义子类中的每个子类将输出$n\times m$个分数。

# Sec04 基于点集的深度学习

受到$\mathbb{R}^n$中点集性质(4.1)的启发我们构造了网络架构(4.2)

## 4.1 $\mathbb{R}^n$中点集性质

我们的输出是欧拉空间中的点的子集，它有三个主要性质：

- 无序（Unordered）。与图像中的像素数组或者体素栅格中的体素数组不同，点云是一组没有特定顺序的点。换句话说，使用$N$个3D点集的网络需要在数据流入顺序上对输入集合保持$N!$排列的不变性。
- 点的交互关系（Interaction Among Points）。点来自于具有距离测度的空间。这意味着这些点不是孤立的，并且其邻近点来自于一个有意义的子集。因此，这个模型需要具备从邻近点中捕捉局部结构，以及局部结构之间的组合交互关系。
- 变换的不变性（Invariance Under Transformations）。作为一个几何对象，点集学习到的表示对于一定的变换是不变的。例如：旋转和平移所有的点不应该改变全局点云的类别，也不应该改变的分割结果。

## 4.2 PointNet结构

![PointNet架构](images/机器学习/计算机视觉/三维处理/点云/点云特征/PointNet/image-20211214092212065.png)

图2：PointNet架构。分类网络的输入为$n$个点，应用输入转换和特征转换，然后通过最大池化层聚集点特征。输出是$k$个类别的分类得分。分割网络是分类网络的扩展。网络拼接全局特征和局部特征，输出每个点的得分。“MLP”表示多层感知机，括号内的数字代表每层的大小。批归一化被应用在所有层的ReLU激活函数后。Dropout层被用在分类网络的最后一个MLP层之后

完整的网络架构参见图2，其中分类网络和分割网络共享了很大一部分结构。请通过图2的标题了解数据管道。

网络拥有三个关键模块：

- 最大池化层：其作为一个对称函数，用于聚合来自所有点的信息
- 信息混合结构：包括局部信息和全局信息
- 两个联合的对齐网络：用于对输入点及点的特征进行对齐。

### 4.2.1 用于无序输入的对称函数

存在三种策略可以使模型不受输入的排列顺序的影响：

- 排序：将输入按规范顺序进行排序；
- RNN：将输入作为RNN的训练序列，但是通过各种排列来实现训练数据集的增强
- 对称函数：使用一个简单的对称函数来聚合来自每个点的信息
	- 对称函数使用$n$个向量作为输入，输出一个新向量（不受输入顺序影响）。例如：`+`与`*`是对称的二元函数。

虽然**排序**看起来像一个简单的解决方案，但事实上在一般场景下高维空间中关于点的扰动不存在平稳的序，这个事实很容易通过反证法来证明。如果这样一个排序的策略存在，那么它能定义一个双向映射在高维空间和1维实数直线。不难看出，满足点的扰动在序上是平稳的等价于该映射在维度减少时仍然保持空间的邻近性，这在通常情况下是无法实现的。因此，排序不能完全解决序的问题，并且由于存在序的问题，网络很难从输入到输出中学习到一致的映射。实验结果（图5）可以发现直接在排序后的点集上应用MLP的表现不佳，尽管比直接处理未排序的输入略好。

使用**RNN**的思想就是认为点集是一个序列信号，希望通过使用随机排列的序列来训练RNN，使得RNN对输入的顺序保持不变。然而，在“顺序问题（Order Matters）”[^25]中，作者已经证明了顺序的重要性，无法忽略。虽然RNN对于长度较短（几十）的序列在输入顺序上具有较好的鲁棒性，但是这种特性无法同比例的缩放到输入元素为几千的序列上，而这个尺寸在点云集合中是很常见的。实践（图5）已经证明基于RNN的方法获得的性能无法与我们的方法相提并论。

![image-20211214104507177](images/机器学习/计算机视觉/三维处理/点云/点云特征/PointNet/image-20211214104507177.png)

图5：获得顺序不变的三种方法。多层感知机（Multi-layer Perceptron，MLP）应用在包括5个隐藏层（神经元的尺寸分别为：64，64，64，128，1024）的点上，所有的点共享一个MLP。MLP在靠近输出的两个层的尺寸分别为512，256。

我们的思想是在集合上通过在变换后的元素上应用一个对称函数逼近一个定义在点集上的通用函数：
$$
f(\{x_1,\cdots,x_n\})\approx g(h(x_1),\cdots,h(x_n))
$$
其中，$f:2^{\mathbb{R}^N}\to\mathbb{R},h:\mathbb{R}^N\to\mathbb{R}^K$，$g:\underbrace{\mathbb{R}^K\times\cdots\times\mathbb{R}^K}_n\to\mathbb{R}$ 是一个对称函数。

基于经验，我们设计了非常简单的基本模型：通过多层感知机网络逼近$h$，通过一个单变量函数和一个最大池化函数组合成$g$。这个模型通过实验证明有效。通过对$h$的收集，我们可以学习一系列$f$的参数去捕捉集合的不同的性质。

虽然我们的关键模型看起来很简单，但是它有许多有趣的性质（5.3），并且在许多不同的应用中能够获得很强的性能（5.1）。由于我们的模型非常简单，因此还能提供理论的分析（4.3）。

### 4.2.2 局部信息和全局信息聚集

上节的输出构成了一个向量$[f_1,\cdots,f_K]$，这是一个输入集合的全局签名。我们可以很容易地为分类问题在形状全局特征上训练一个SVM或者多层感知机分类器。然而，点分割需要一个局部知识和全局知识的混合，因此我们通过一个简单但是高效的办法得到这个混合。

解决方案是分割网络（图2）。在计算得到全局点云特征向量后，将全局特征与每个点特征拼接起来，再将拼接结果反馈为每个点的特征。然后，我们基于组合的点特征抽取新的点特征，这次得到的新的点特征同时拥有了局部信息和全局信息。

网络通过这种依赖于局部几何和全局语义的修改能够预测每个点的值。例如：精确地预测每个点的法向（参见补充材料），验证了网络能够从点的局部近邻中汇总信息。在实验阶段，我们还展示了模型在形状部件分割和场景分割中获得的SOTA性能。

### 4.2.3 联合对齐网络

不管点云经历了何种几何变换（例如：刚性变换），点云的语义标签都必须保持不变。因此，我们希望通过点集学习的表示对于这些变换也是不变的。

一个自然的解决方案是在特征提取之前对齐所有的输入集合到一个规范空间中（规一化）。Jaderberg等人[^9]引入了空间变换器的思想，通过采样和插值对齐2D图像，并在GPU上实现一个特别的定制层来达成。

相比[^9]的方法，我们的点云输入形式使得目标达成更加简单。我们不需要创造任何新的层，也不会在图像案例中引入失真。我们通过一个小型网络（图2中T-net）预测了一个仿射变换矩阵，并将该变换直接应用到输入点的坐标上。小型网络与大型网络有相似之处，也是由点的独立特征提取层、最大池化层和全连接层几个基本模块构成。关于T-net的更多细节参见附录。

这个思想也可以被进一步扩展到特征空间的对齐。我们可以在点特征中插入其他对齐网络，并且从不同的输入点云中预测一个特征变换矩阵去对齐特征。然而，相比空间变换矩阵，在特征空间中的变换矩阵拥有更高的维度，使得优化的难度更高。因此，我们增加了一个正则化项到我们的softmax训练损失中。我们强制特征变换矩阵逼近一个正交矩阵：
$$
L_{reg}=\|I-AA^T\|_F^2
$$
其中，$A$是通过小型网络预测的特征对齐矩阵。需要一个正交变换是因为它不会丢失输入的信息。我们发现通过增加正则化项，优化变得更加平稳，并且模型得到更好的性能。

## 4.3 理论分析

### 4.3.1 万能逼近

首先，我们的神经网络展示了对连续集合函数的万能逼近能力。直观地说，通过集合函数的连续性，对于输入点集，一个小的扰动不应该大幅度改变函数的值，例如：分类或者分割的得分。

形式上，假设$\mathcal{X}=\{S:S\subseteq[0,1]^m\text{and}|S|=n\}$，$f:\mathcal{X}\to\mathbb{R}$是在$\mathcal{X}$上的一个关于Hausdorff距离$d_H(\cdot,\cdot)$的连续集合函数，即：对$\forall\epsilon>0$总$\exists\delta>0$，如果$d_H(S,S')<\delta,S\in\mathcal{X},S'\in\mathcal{X}$，则$|f(S)-f(S')|<\epsilon$。我们的理论表明基于最大池化层给定足够神经元的条件下，$f(\cdot)$可以通过我们的网络被任意逼近，即$K$在等式(1)中充分大。

#### 定理1

假设$f:\mathcal{X}\to\mathbb{R}$是一个关于Hausdorff距离$d_H(\cdot,\cdot)$的连续集合函数。$\forall\epsilon>0$，存在一个连续函数$h$和一个对称函数$g(x_1,\cdots,x_n)=\gamma\circ MAX$，因此在满足任意$S\in\mathcal{X}$的条件下：
$$
|f(S)-\gamma(\underset{x_i\in S}{MAX}\{h(x_i\})|<\epsilon
$$
其中，$x_1,\cdots,x_n$是$S$中的所有数据任意排序的列表，$\gamma$是一个连续函数，$MAX$是向量的$\max$运算符，即：将$n$个向量作为输入，返回由每个元素中最大值组成的新向量。

这个定理的证明可以参考附录。关键思想是：在最坏的情况下，网络可以通过将空间划分为大小相等的体素，从而学会将点云转换为体积的表示。然而，网络在实践中学会了一个更加聪明的策略来探测空间，就如我们在点函数可视化中看到的那样。

### 4.3.2 维度瓶颈和平稳性

理论上和实验中，网络的表达能力都受到最大池化层维度的影响，即公式(1)中的$K$。这里，我们通过分析提示了与模型的平稳性相关的属性。

我们定义了$\text{u}=\underset{x_i\in S}{MAX}\{h(x_i)\}$为$f$的子网络，这个子网络将$[0,1]^m$中的点集映射为$K$维向量。后续的理论告诉我们，输入集中小的扰动或者多出的噪声点不会改变我们网络的输出结果。

#### 定理2

假设$\text{u}:\mathcal{X}\to\mathbb{R}^K$，则$\text{u}=\underset{x_i\in S}{MAX}$且$f=\gamma\circ\text{u}$，得
$$
\begin{align*}
    (a)& \forall S,\exists C_S,\mathcal{N}_S\subseteq\mathcal{X},如果C_S\subseteq T\subseteq\mathcal{N}_S则f(T)=f(S)\\
    (b)& |C_S|\leq K
\end{align*}
$$
我们解释了定理的含义：

- $(a)$表明：如果保留$\mathcal{C}_S$中所有的点，则$f(S)$将保持不变直到遇到输入错误，或者$f(S)$将保持不变直到$\mathcal{N}_S$中出现多余的噪声。
- $(b)$表明：$\mathcal{C}_S$中包含的点的数目是有界的，值由公式(1)中的$K$决定。换句话说，$f(S)$事实上是由有限的子集$\mathcal{C}_S\subseteq S$确定，或者其数目小于或者等于$K$个元素。因此，我们称$\mathcal{C}_S$为$S$的临界点集，$K$为$f$的维度瓶颈。

结合$h$的连续性，这个宣解释了面对点的扰动、点的丢失和额外噪声点时模型的稳健性。获得的这个稳健性类似于机器学习中的稀疏性准则。直观上，通过一组稀疏的关键点集合，我们的网络学习去总结形状。在实验阶段，我们看到关键点构成了对象的骨架。

# Sec05 实验

实验被分为四个部分：

1. PointNet应用于多个3D识别任务中（5.1）
2. 实验的细节去验证我们的网络（5.2）
3. 可视化网络的学习结果（5.3）
4. 分析时间和空间复杂度（5.4）

## 5.1 应用

在本节中，我们展示了网络是怎样被训练去执行3D对象分类、对象部分分割和语义场景分割。即使我们工作在一个全新的数据表示上（点集），我们在许多任务上还能够获得相比基准点类似的或者更好的性能。

### 5.1.1 3D对象分类

我们网络学习可以用于对象分类的全局点云特征。我们在ModelNet40[^28]形状分类基准上评估了我们的模型。数据集中包括来自于40个人造物体类别的12311个计算机辅助设计模型，被分为9843个用于训练，2468个用于测试。我们是首先直接应用原始的点云数据，而先前的方法侧重于体素和多视图图像表示。

我们在网格表面根据表面区域对1024个进行均匀抽样，并将其归一化到单位球内。在训练阶段，我们沿着向上的方向轴随机旋转对象和通过一个零均值标准方差为0.02的高斯噪声来抖动每个点的位置，从而在运行中增强点云数据集。

|                  | 输入格式 | 视图数目 | 类别的平均精度 | 总体精度 |
| ---------------- | -------- | -------- | -------------- | -------- |
| SPH[^11]         | 网格     | -        | 68.2           | -        |
| 3DShapeNets[^28] | 体素     | 1        | 77.3           | 84.7     |
| VoxNet[^17]      | 体素     | 12       | 83.0           | 85.9     |
| Subvolume[^18]   | 体素     | 20       | 86.0           | 89.2     |
| LFD[^28]         | 图像     | 10       | 75.5           | -        |
| MVCNN[^23]       | 图像     | 80       | 90.1           | -        |
| 我们的基线       | 点       | -        | 72.6           | 77.4     |
| PointNet         | 点       | 1        | 86.2           | 89.2     |

表1：ModelNet40上的分类结果。我们的PointNet在所有基于3D输入的深度网络中获得SOTA。

在表1中，我们将自己的模型与先前的工作进行了比较，还加入了使用点云中抽取的传统特征（点密度、D2、形状等）的MLP。我们的模型在基于3D输入（体素和点云）的方法中获得了最先进的性能。使用全连接层和最大池化层，我们的网络在推理速度上获得了很大的优势，并且还可以很容易地在CPU中并行化。我们的方法与基于多视图的方法（MVCNN[^23]）之间仍然存在很小的差距，我们认为这个差距产生于精细的几何细节的损失，这个细节可以在渲染图像时捕捉到。

### 5.1.2 3D对象部件分割

部件分割是一项具有挑战性的细粒度3D识别任务，给定一个3D扫描或者网格模型，任务是分配部件分类标签（如：椅腿、杯柄）到每个点或面上。

我们在ShapeNet部件数据集[^29]上进行了评估，这个数据集包含16个分类16881个形状，总共50个部件标注。许多对象分类拥有2到5个部件标签。基准标注是在形状上对样本点加注标签。

我们将部件分割作为每个点的分类问题进行规范化。评估的度量标准是点上的mIoU。对于每个分类$C$的每个形状$S$，计算形状的mIoU；对于每个分类$C$的每个部件类型，计算基准与预测之间的IoU；如果基准与预测点的并集为空，则部件IoU记为1.然后，我们将分类$C$中所有的部件类型求平均IoU从而获得形状的mIoU。为了计算类别的mIoU，我们将这个类别中所有形状取mIoU的均值。

在本节中，我们的分割版本PointNet（图2中修改版本，分割网络）与两种传统方法[^27]和[^29]，以及我们的3D CNN基线进行了比较，这两种传统方法都使用了逐点的几何特征和形状之间的对应关系。3D CNN的网络架构与修改细节参见附录。

|          | 均值 | 飞机 | 背包 | 帽子 | 汽车 | 椅子 | 听筒 | 吉他 | 刀具 | 灯具 | 手提电脑 | 摩托车 | 马克杯 | 手枪 | 火箭 | 滑板 | 桌子 |
| -------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | -------- | ------ | ------ | ---- | ---- | ---- | ---- |
| 形状数   |      | 2690 | 76   | 55   | 898  | 3758 | 69   | 787  | 392  | 1547 | 451      | 202    | 184    | 283  | 66   | 152  | 5271 |
| Wu[^27]  | -    | 63.2 | -    | -    | -    | 73.5 | -    | -    | -    | 74.4 | -        | -      | -      | -    | -    | -    | 74.8 |
| Yi[^29]  | 81.4 | 81.0 | 78.4 | 77.7 | 75.7 | 87.6 | 61.9 | 92.0 | 85.4 | 82.5|95.7 | 70.6     | 91.9   | 85.9   | 53.1 | 69.8 | 75.3 |
| 3DCNN    | 79.4 | 75.1 | 72.8 | 73.3 | 70.0 | 87.2 | 63.5 | 88.4 | 79.6 | 74.4 | 93.9 | 58.7 | 91.8 | 76.4 | 51.2 | 65.3 | 77.4 |
| PointNet | 83.7 | 83.4 | 78.7 | 82.5 | 74.9 | 89.6 | 73.0 | 91.5 | 85.9 | 80.8 | 95.3 | 65.2 | 93.0 | 81.2 | 57.9 | 72.8 | 80.6 |

表2：ShapeNet部件数据集的分割结果。度量是mIoU(%)。我们与两种传统方法[^27][^29]以及我们提出的全卷积网络基线进行了比较，结果是PointNet在mIoU中获得SOTA。

在表2中，我们报告了每个类别的IoU及其均值IoU。我们观察到PointNet在均值上相比基线方法有$2.3\%$改善，并且在大多数类别上都优于基线方法。

![image-20211215102051923](images/机器学习/计算机视觉/三维处理/点云/点云特征/PointNet/image-20211215102051923.png)

图3：部件分割的定性结果。我们在所有16个对象分类上可视化了CAD部件分割结果，展示了模拟的Kinect扫描的部分形状数据（左边）和ShapeNet CAD模型的完整形状数据（右边）

我们还对模拟的Kinect扫描上进行了实验，以测试这些方法的稳健性。对于ShapeNet部件数据集中每个CAD模型，我们使用Blensor Kinect 模拟器[^7]从六个随机视角去生成不完整的点云。我们使用相同的网络架构和训练设置，在完整的形状数据和部分的扫描数据上训练PointNet。结果表明，我们只损失了$5.3\%$的均值IoU。在图3中，我们展示了在完整的形状数据和部分的扫描数据上的定性结果。可以看出部分的扫描数据极具挑战性，但是我们的预测结果依然是合理的。

### 5.1.3 场景中的语义分割

我们的网络在部件分割上的应用可以很容易地扩展到语义场景分割上，其中点的标签由对象部件标签转换为语义对象分类。

我们在Standford 3D 语义解析数据集[^1]上进行了实验。数据集包含在6个区域271间房屋中利用Matterport扫描仪得到的3D扫描数据。扫描中的每个点都被标记为13个类别（椅子、桌子、地板、墙等，还包括杂七杂八的东西）确定的语义标签中的一个。

为了准备训练数据，我们首先从房屋中分离出点，然后按照区域（$1米\times1米$）将房屋采样成块。我们训练PointNet的分割模型去预测每个块中的每个点。每个点用9个维度（XYZ、RGB和房间从0到1归一化的位置）的向量表示。在训练阶段，我们在运行过程中随机在每个块中抽取4096个点。在测试阶段，我们将测试所有的点。我们遵循[^1]中协议，对训练和测试使用K折交叉验证策略。

|            | IoU均值 | 总的精确度 |
| ---------- | ------- | ---------- |
| 我们的基线 | 20.12   | 53.19      |
| PointNet   | 47.71   | 78.62      |

表3：场景语义分割的结果。度量是13个类别上的IoU均值（结构和家具元素以及杂七杂八的东西），并且基于点上计算分类的结果。

![image-20211215142445606](images/机器学习/计算机视觉/三维处理/点云/点云特征/PointNet/image-20211215142445606.png)

图4：语义分割的定性结果。上面一行是有颜色的输入点云，下面一行是在点上输出的语义分割结果，结果与输入展示在相同的相机视角下。

我们的方法基于手工制作的点特征与基线进行了比较。基线抽取了同样的9维局部特征和三个附加特征：局部点密度、局部曲率和法向。我们使用标准的MLP作为分类器。结果如表3，其中PointNet方法显著地好过基线方法。在图4中，我们还定性地展示了分割的结果。我们的网络能够输出平滑的预测，并且对于缺失点和遮蔽都是稳健的。

基于来自于我们的网络的语义分割输出，我们基于用于

|                | 桌子  | 椅子  | 沙发 | 板子  | 均值  |
| -------------- | ----- | ----- | ---- | ----- | ----- |
| 实例数         | 455   | 1363  | 55   | 137   |       |
| Armeni等人[^1] | 46.02 | 16.15 | 6.78 | 3.91  | 18.22 |
| 我们的         | 46.67 | 33.80 | 4.76 | 11.72 | 24.24 |

对象建议的连接组件构建了3D对象检测系统（详见附录）。我们在表4中比较了先前的SOTA方法。先前的方法基于滑动形状方法（使用CRF进行后处理）使用SVM在体素栅格的局部几何特征和全局房间上下文特征进行训练。我们的方法远好过家具分类报告的结果。

## 5.2 架构设计分析

在本节中，我们通过控制实验验证了我们的设计选择。我们也展示了我们的网络的超参数的效果。

### 5.2.1 与其他序不变方法的比较

如（4.2）中提及的，处理无序集合输入问题至少有三种选择。我们使用ModelNet40形状分类问题作为一个试验床用于比较这三种选择，后面的两个控制实验也会使用这个任务。

我们比较的基线（图5所示）包括基于无序的点和有序的点的多层感知机（$n\times3$数组），将输入点看作一个序列的RNN模型，以及基于对称函数的模型。我们试验的对称操作包括：最大池化、平均池化和基于权重求和的注意力。注意力方法与[^25]中的相同，其中的标量得分是从每个点特征中预测得到的，然后这个得分通过计算softmax跨点归一化得到的结果。然后，在归一化得分和点特征上计算得到权重和。如图5所示，最大池化操作获得了远超其他选择的最好性能，这个验证了我们的选择。

### 5.2.2 输入和特征变换的有效性

| 变换                        | 精度 |
| --------------------------- | ---- |
| 无                          | 87.1 |
| 输入（$3\times3$)           | 87.9 |
| 特征（$64\times64$）        | 86.9 |
| 特征（$64\times64$）+正则化 | 87.4 |
| 两个都要                    | 89.2 |

表5：输入特征变换的影响。度量是在ModelNet40测试集上所有分类的精度。

在表5中，我们证明了我们的输入和特征变换（用于对齐）的正面影响。有趣的是非常基础的架构已经获得了非常合理的结果。使用输入变换给出了$0.8\%$的性能提升。正则化损失对于高维变换非常必要。通过混合变换和正则化项，我们获得了更好的性能。

### 5.2.3 稳健性测试

我们展示了PointNet不仅是简单有效的，而且在不同的输入污染下的保持了稳健性。我们使用了如图5中最大池化网络相似的架构。输入点被归一化为单位球。结果在图6

![image-20211215152953672](images/机器学习/计算机视觉/三维处理/点云/点云特征/PointNet/image-20211215152953672.png)

图6：PointNet稳健性测试。度量是ModelNet40测试集上所有类别的精度。左：删除点。最远的1024个原点煌均值从最远的样本中抽样得到。中：插入。异常点在单位球中均匀散开。右：扰动。独立地对每个点增加高斯噪声也。

至于丢失点，当$50\%$的点丢失后，最远输入采样精度仅下降$2.4\%$；随机输入采样精度仅下降$3.8\%$。如果我们的网络在训练阶段见过异常点，那么对于这些异常点网络是稳健的。我们评估了两种模型：一种是基于使用$(x,y,z)$坐标的点进行的训练；另一种是基于使用$(x,y,z)$坐标和点密度进行的训练。哪怕有$%20\%$的点都是异常点，网络拥有$80\%$的精度。图6右展示了网络在扰动点上的稳健性。

## 5.3 PointNet 可视化

![image-20211218173727160](images/机器学习/计算机视觉/三维处理/点云/点云特征/PointNet/image-20211218173727160.png)

图7：临界点和形状上界。当临界点为一个给定的形状联合确定全局形状特征时，落在临战点集合和形状上界的任意点云精确地给出了相同的特征。我们通过颜色编码了所有的图展示了深度信息。

在图7中，我们对一些样本形状$S$可视化了临界点集合$\mathcal{C}_S$和上界形状$\mathcal{N}_S$（定理2中讨论过）。两个形状之间的点集合将精确地给出相似的全局形状特征$f(S)$。

我们从图7中可以清晰地看出临界点集合$\mathcal{C}_S$总结了形状的骨架，为最大池化特征给予了贡献。上界形状$\mathcal{N}_S$描述了最大的可能点云，这个可能点云给输入点云$S$相同的全局形状特征$f(S)$。$\mathcal{C}_S$和$\mathcal{N}_S$反映了PointNet的稳健性，即损失部分非临界点根本不会改变全局形状签名$f(S)$。

通过在网络上前馈一个边长为2的立方体上所有点构建$\mathcal{N}_S$，并且选择点$p$，要求这个点的点函数的值$(h_1(p),h_2(p),\cdots,h_K(p))$小于全局形状描述符。

## 5.4 时间和空间复杂度分析

|                    | 参数个数 | FLOPs/样本 |
| ------------------ | -------- | ---------- |
| PointNet（基本版） | 80万     | 1.48亿     |
| PointNet           | 350万    | 4.40亿     |
| Subvolume[^18]     | 1660万   | 36.33亿    |
| MVCNN              | 6000万   | 6.2057万亿 |

表6：用于3D数据分类的深度架构的时间和空间复杂度。PointNet（基本版）是没有输入和特征变换的分类PointNet。FLOP表示浮点运算。Subvolume和MVCNN对来自于不同旋转和视图的输入数据使用池化，相比PointNet获得了更差的性能。

表6总结了我们的分类系统PointNet的空间（网络的参数个数）和时间（每个样本的浮点操作数）。我们还在体积的表示集合和基于架构的多视图上比较了PointNet与先前的工作。

虽然 MVCNN[^23]和子体积（Subvolume，3DCNN）[^18]获得了高的性能，但是PointNet在计算代价上更加有效，基于FLOP/样本测量分别获得了141倍和8倍的提升。除此之外，PointNet相比MVCNN在网络的参数项上具有更好的空间有效性，即参数量少了17倍。而且，PointNet的尺度缩放能力更强，它的空间和时间复杂度是$O(N)$，即对于输入点的数目是线性的。然而，由于卷积消耗了主要计算时间，多视图方法的时间复杂度关于图像的分辨率按照平方增加和基于方法的体积卷积关于体积尺寸按照立方增加。

经验上说，PointNet能够在Tensorflow上使用GTX 1080 GPU，每秒处理超过一百万个点用于点云分类（1000个对象/秒）或者用于语义分割（大约2个房间/秒），这个结果在实时应用上展示了巨大的潜能。

# Sec06 结论

在本文中，我们提出了一个新颖的、直接处理点云的深度神经网络PointNet。我们的网络对于多个3D识别任务（对象分类、部件分割和语义分割）提供了一个统一的方法，而且在标准基准上相比SOTA获得了同等的或者更好的结果。我们还提供了理论分析和可视化从而更好地理解我们的网络。

# 附录

## A. 概述

本文档为论文主体提供了额外的定量结果、技术细节和更多的定性测试案例。

- 在B节中，我们扩展了稳健性测试，在不完整输入上去比较PointNet与VoxNet；
- 在C节中，我们提供了神经网络架构与训练参数的更多细节；
- 在D节中，我们描述了场景中的检测流程；
- 在E节中，我们说明了PointNet的更多应用；
- 在F节中，我们展示了更多的分析实验；
- 在G节中，我们提供了理论在PointNet上的证明；
- 在H节中，我们展示了更多的可视化结果。

## B. PointNet和VoxNet的比较（5.2）

![image-20211218174027808](images/机器学习/计算机视觉/三维处理/点云/点云特征/PointNet/image-20211218174027808.png)

图8：PointNet与VoxNet在不完整的输入数据上的对比。度量是ModelNet40测试集上所有类别精度。请注意，VoxNet使用12个视角的平均值，而PointNet仅使用点云的一个视图。证据表明PointNet在缺失点上表现得更加稳健。

我们扩展了稳健性测试，比较PointNet和VoxNet[^17]（用于体素表示的表示性架构）对于输入点云存在缺失数据时的稳健性。两个网络都基于相同的训练测试分割集上进行训练，分割集中的输入是1024个点。对于VoxNet，我们将点云体素化为$32\times32\times32$大小的覆盖栅格，并且通过扰动及围绕方向朝上的轴旋转来扩增训练数据。

在测试阶段，输入点按照一定的比例随机暂弃（Dropout）。由于VoxNet对于旋转极为敏感，因此它的预测使用一个点云的12个视角的平均得分。如图8所示，PointNet在缺失点上更加稳健，而VoxNet在面对输入点损失一半的情况时，精度从$86.3\%$下降到$46.0\%$，相差$40.3\%$，但是PointNet只有$3.7\%$的性能下降。这个事实可以通过PointNet的理论分析得到解释，即：PointNet是通过学习使用临界点的集合来汇总形状，因此它对于缺失数据非常稳健。

## C. 网络结构与训练细节（5.1）

### PointNet分类网络

在论文主体已经说明了基础架构，这里我们介绍联合对齐/变换网络和训练参数的更多细节。

第一个变换网络是微型-PointNet，它以原始点云作为输入，归纳成一个$3\times3$的矩阵。结构是由共享MLP（1D卷积）网络组成（在每个点上层的输出尺寸是64，128，1024），包括所有点的最大池化层和两个全连接层（输出的尺寸512，256）。输出矩阵初始化为单位矩阵。所有层（除最后一层外）都使用ReLU和批归一化。

第二个变换网络与第一个变换网络的架构相同，除了输出为$64\times64$的矩阵。这个矩阵也被初始化为单位矩阵。一个正则化损失（权重0.001）被加入到 softmax 分类损失中使得矩阵逼近正交。

我们使用暂弃法（比例0.7）在最后一个全连接层，其输出维度为256，下一层是类得分预测。批归一化的退化速率从0.5开始，逐步增长到0.99。我们使用Adam优化器（初始化学习率0.001，矩0.9，批大小32）。学习率每20个周期减半。使用Tensorflow和GTX1080 GPU 大约3~6个小时训练ModelNet收敛。

### PointNet分割网络

分割网络是分类网络的扩展。局部点特征（输出在第二个变换网络之后）和全局特征（输出在最大池化层之后）基于每个点拼接起来。分割网络没有使用暂弃法。训练参数与分类网络相同。

![image-20211218174257577](images/机器学习/计算机视觉/三维处理/点云/点云特征/PointNet/image-20211218174257577.png)

图9：部件分割的网络架构。T1和T2是输入点和特征的对齐/变换网络。FC是操作在每个点上的全连接层。MLP是每个点上的多层感知机。One-Hot是大小为16的独热向量，用于输入形状的指示类别。

关于形状部件分割任务，我们对论文主体中基本的分割网络架构（图2）进行了少量修改（图9）从而获得更好的性能。我们增加了独热向量去指示输入的类别，并且将之与最大池化层的输出拼接。我们还增加了一些层的神经元，增加了跳跃连接去收集不同层的局部点特征，并且拼接起来形成点特征输入到分割网络中。

尽管[^27]和[^29]分别处理每个对象分类，由于一些类别缺少训练数据（数据集中所有形状的总数显示在第一行），我们跨类别对PointNet进行训练（使用独热向量输入去指示类别）。为了使比较公平，当比较这两个模型时，我们仅仅预测了部件标签对于给定的特定对象类别。

关于语义分割任务，我们使用了论文主体中的架构（图2）。

这个模型，在ShapeNet部件数据集上训练了6~12个小，在Standford语义解析数据集上训练了大约半天。

### 3D CNN分割网络基线

![image-20211218174917819](images/机器学习/计算机视觉/三维处理/点云/点云特征/PointNet/image-20211218174917819.png)

图10：3D CNN 分割网络基线。网络是全卷积，并且预测了每个体素的部件得分。

在ShapeNet部件分割实验中，我们比较了PointNet分割网络与其他两种传统方法，以及3D体素CNN网络作为基线。在图10中，我们展示了基线3D体素CNN网络。我们泛化了著名的3D CNN 架构，如：VoxNet[^17]和3DShapeNets[^28]，为一个全卷积3D CNN 分割网络。

对于一个给定的点云，我们首先将之转换为体素表示，其占用栅格的分辨率为$32\times32\times32$。然后，共5个3D卷积操作被应用于抽取特征，其中的每一个输出通道为32，步长为1。对于每个体素其感受野为19。最终，核为$1\times1\times1$的3D卷积层附加到计算得到的特征图去预测每个体素的分割标签。所有的层（除了最后一层）都使用了ReLU和批归一化。网络是跨类别训练，然而为了比较其他给定对象类别的基线方法，我们仅仅考虑了给定对象类别中的输出得分。

## D.检测流程的细节（5.1）

基于语义分割结果和对象分割网络PointNet，我们构建了一个简单的3D对象检测系统。

我们使用具有分割得分的连接组件去获得场景中的对象建议。从场景中的一个随机点开始，我们找到它的预测标签，和BFS去搜索具有相同标签的临近点，搜索的半径为0.2米。如果搜索的结果簇包含的点超过了200（假设$1米\times1米$的区域中包含4096个点），簇的包围盒被标记为一个对象建议。对于每个建议的对象，它的检测得分被计算为该类别的平均点得分。在评估之前，对于非常小的面积/体积的建议将被裁剪。对于桌子、椅子和沙发，包围盒延伸到地板是为了防止腿与基座/表面分开。

我们观察到，在一些房间中，例如：礼堂中许多对象（如：椅子）相互挤在一起，其中相互连接的组件无法正确地分割独立的组件。因此，我们利用分类网络，并且使用滑动形状方法来缓解椅子类别的问题。我们对每个类别都训练了一个二元分类网络，并且为滑动窗口检测使用分类器。结果框通过非最大抑制进行修剪。来自连接手滑动形状的建议盒子被组合起来进行最终的评估。

![image-20211218181326673](images/机器学习/计算机视觉/三维处理/点云/点云特征/PointNet/image-20211218181326673.png)

图11：3D点云中对象检测的精度-召回曲线。我们对四个类别（桌子、椅子、沙发和面板）评估了所有六个区域。在体积上IoU的阈值是0.5。

在图11中，我们展示了对象检测的精度-召回曲线。我们训练了六个模型，其中每从此模型都在5个区域中进行训练，并且在左侧区域进行测试。在测试阶段，每个模型都在其未见过的区域中进行测试。对于所有的六个区域，测试的结果被汇总以生成PR曲线。

## E.更多应用（5.1）

### 基于点云的模型检索

PointNet为每个给定了输入点云学习了一个全局形状签名。我们期望几何形状上相似的对象有相似的全局签名。在本节中，测试了我们在形状检索应用上的推测。更具体地说，对于从ModelNet的测试分割集中选择的每个给定的查询形状，我们计算了由我们的分类PointNet给出的它的全局签名（得分预测层之前的层输出），并且在分割的训练集中检索通过最近邻搜索的相似的形状。结果展示在图12。

![image-20211219095623103](images/机器学习/计算机视觉/三维处理/点云/点云特征/PointNet/image-20211219095623103.png)

图12：从点云中检索模型。对于每个给定的点云，我们从ModelNet分割的测试集中检索了5个最相似的形状。从上到下的行中，我们展示了椅子、植物、床头柜和浴盆查询的例子。检索的结果存在的错误类别会被红框标出。

### 形状匹配

在本节中，我们展示了从PointNet中学习到的点特征可以隐性地应用于计算形状的对应关系。给定两个形状，我们通过匹配全局特征中相同维度的成对的点来计算它们的临界点集合$C_S$之间的对应关系。图13与图14展示了两个相似的椅子与桌子之间检测到的形状对应关系。

![image-20211219100751257](images/机器学习/计算机视觉/三维处理/点云/点云特征/PointNet/image-20211219100751257.png)

图13：两个椅子之间的形状对应关系。为了清晰地可视化，我们仅展示了20个随机选择的对应的成对点。

![image-20211219100912588](images/机器学习/计算机视觉/三维处理/点云/点云特征/PointNet/image-20211219100912588.png)

图14：两个桌子之间的形状对应关系。为了清晰地可视化，我们仅展示了20个随机选择的对应的成对点。

## F.更多架构分析（5.2）

### 维度瓶颈与输入点数目的影响

这里，我们展示了我们的模型关于第一个最大化层输出的尺寸以及输入点的数目对性能的改变。在图15中，我们看到当输入点增强时，性能也随之上升，然而接近1000个点时性能增长接近平稳。最大化层的尺寸扮演了重要的角色，层的尺寸从64到1024导致的性能增益为$2\sim4\%$。这个现象说明，为了分辨不同的形状，我们需要足够的点特征函数去覆盖3D空间。

![image-20211219101750154](images/机器学习/计算机视觉/三维处理/点云/点云特征/PointNet/image-20211219101750154.png)

图15：瓶颈尺寸和输入点的数目的影响。度量是ModelNet40的分割测试集上的所有分类的准确率。

值得注意的是，哪怕是64点的输入（在网格上使用最先进的点抽样获得的），我们的网络也能获得合适的性能。

### MNIST数字分类

当我们关注在3D点云学习时，一个理性的检测试验是将我们的网络应用在2D点云--像素集合上。

为了将一张MNIST图像转换成2D点集合，我们设置了像素值的阈值，并且增加了值大于128的像素（在图像中使用点的$(x,y)$坐标来表示）到集合中。我们使用的集合大小为256.如果存在多于256个像素的集合，我们随机进行子采样；如果少于则使用集合中像素进行填充（由于我们的最大化操作，所以填充哪个点到集合中不会影响最终的结果）。

|             | 输入 | 错误率(%) |
| ----------- | ---- | --------- |
| MLP[^22]    | 向量 | 1.60      |
| LeNet5[^12] | 图像 | 0.80      |
| PointNet    | 点集 | 0.78      |

如表7所示，我们比较了几种基线，包括多层感知机（将输入图像看作有序的集合）、RNN（将输入看作像素从$(0,0)$到$(27,27)$的序列）和一个基础版本的CNN。然而MNIST上最好的性能模型仍然是很好地工程化的CNN（获得了少于$0.3\%$的错误率），有趣的是通过将图像看作2D点集，我们的PointNet模型也获得了合理的性能。

### 法向估计

在PointNet的分割版本中，为了提供局部点的上下文，局部点特征和全局特征被拼接在一起。然而，我们并不清楚上下文是从这个拼接中学习得到的。在这个实验中，通过展示训练的分割网络可以预测点的法向验证了我们的设计，通过点的邻居可以确定一个局部的几何性质。

我们在有监督的方式下训练了一个修改过的分割PointNet的版本，从而回归到基准的点法向。我们仅改变了分割PointNet的最后一层去预测每个点的法向量。我们$\cos$距离的绝对值作为损失。

![image-20211219104243004](images/机器学习/计算机视觉/三维处理/点云/点云特征/PointNet/image-20211219104243004.png)

图16：PointNet法向重建结果。在本图中，我们展示了基于某些样本点云的所有点和从网络中计算得到的基准法向执行的法向重建。

图16比较了PointNet的法向预测结果（左列）和通过网格计算得到的基准法向（右列）。我们观察了一个合理的法向重建。我们的预测相比基准（在某些区域包含了翻转的法向）更加平滑和连续。

### 分割的稳健性

如（5.2）和 （附录B）中讨论的那样，PointNet受到有污染的数据或者缺失数据的影响更小，因为全局形状特征是从给定的输入点云的临界点的集合中抽取出来的。在本节中，我们还展示了分割任务的稳健性。每个点的部件标签是基于每个点的特征和学习得到的全局形状特征的混合结果进行预测的。在图17中，我们展示了给定的输入点云$S$（最左边的列）、临界点集合（中间列）和形状上界$\mathcal{N}_S$（最右边的列）的分割结果。

![image-20211219104603953](images/机器学习/计算机视觉/三维处理/点云/点云特征/PointNet/image-20211219104603953.png)

图17：分割结果的一致性。我们展示了给定的输入点云$S$（最左边的列）、临界点集合$\mathcal{C}_S$（中间列）和形状上界$\mathcal{N}_S$（最右边的列）的分割结果。我们观察到在$\mathcal{C}_S$和$\mathcal{N}_S$之间的形状系列共享了一致的分割结果。

### 对于未知形状类别的网络泛化能力

在图18中，我们可视化了不存在于ModelNet和ShapeNet的未知类别（脸、房子、小兔子和茶壶）的新的形状的临界点集合和形状上界。结果说明学习到的每个点函数是可以泛化的。然而，因为我们的大部分训练是在拥有大量平坦结构的人造对象上完成的，因此在新的类别上重建形状上界时会包含大量的平坦表现。

![image-20211219104814148](images/机器学习/计算机视觉/三维处理/点云/点云特征/PointNet/image-20211219104814148.png)

图18：对于未知对象的临界点集合和形状上界。我们可视化了茶壶、小兔子、手和人体的临界点集合和形状上界，这些形状不在ModelNet和ShapeNet的形状仓库中，通过在这些未知对象上我们检测了PointNet学习到的每个点函数的泛化性。图像通过颜色编码来反映深度信息。

## G.定理的证明（Sec0403）

### 定理1证明过程

假设$\mathcal{X}=\{S:S\subseteq[0,1]\text{and}|S|=n\}$

$f:\mathcal{X}\to\mathbb{R}$是一个基于$\mathcal{X}$关于Hausdorff距离$d_H(\cdot,\cdot)$连续函数，其满足后续的条件：
$$
\begin{align*}
\forall\epsilon>0,\\
\exists\delta>0,\\
如果d_H(S,S')<\delta,S\in\mathcal{X},S'\in\mathcal{X}\\
则|f(S)-f(S')|<\epsilon
\end{align*}
$$
我们展示了通过组合一个对称函数和一个连续函数可以任意逼近$f$。

### 定理1定义

假设$f:\mathcal{X}\to\mathbb{R}$是一个关于 Hausdorff 距离$d_H(\cdot,\cdot)$的连续集合函数。$\forall\epsilon>0$，存在连续函数$h$和对称函数$g(x_1,\cdots,x_n)=\gamma\circ MAX$，其中$\gamma$是一个连续函数，$MAX$是一个向量最大化操作（以$n$个向量作为输入，以元素方向最大化的方式输出一个新的向量），对于任意$S\in\mathcal{X}$得：
$$
|f(S)-\gamma(MAX(h(x_1),\cdots,h(x_n)))|<\epsilon
$$
其中$x_1,\cdots,x_n$是按照一定的顺序抽取的$S$的元素。

### 定理1证明

通过$f$的连续性，我们取$\delta_\epsilon$，如果$d_(S,S')<\delta_\epsilon,S\in\mathcal{X},S'\in\mathcal{X}$，可得$|f(S)-f(S')|<\epsilon$。

定义$K=\lceil1/\delta_\epsilon\rceil$，其中$[0,1]$被平均分成为$K$个区间，并且为了将点映射到区间的左边界定义一个辅助函数：$\sigma(x)=\frac{\lfloor K_x\rfloor}{K}$。

假设$\tilde{S}=\{\sigma(x):x\in S\}$，则$|f(S)-f(\tilde{S})<\epsilon$，因为$d_H(S,\tilde{S})<1/K\leq\delta_\epsilon$。

假设$h_k(x)=\exp\{-d(x,[\frac{K-1}{K},\frac{k}{K}])\}$是一个软指示函数，其中$d(x,I)$是点到集合（区间）的距离。

假设$\mathbf{h}(x)=[h_1(x);\cdots;h_K(x)]$，则$\mathbf{h}:\mathbb{R}\to\mathbb{R}^K$。

假设$v_j(x_1,\cdots,x_n)=\max\{\tilde{h}_j(x_1),\cdots,\tilde{h}_j(x_n)\}$，指示了在$S$中通过点的第$j$个区间的占用。

假设$\mathbf{v}=[v_1;\cdots;v_K]$，则$\mathbf{v}:\underbrace{\mathbb{R}\times\mathbb{R}}_n\to\{0,1\}^K$是一个对称函数，指示了在$S$中通过点的每个区间的占用。

定义$\tau:\{0,1\}^K\to\mathcal{X}$为$\tau(v)=\{\frac{k-1}{K}:v_k\geq1\}$，这个函数用于映射占用的向量到一个包含每一个占用区间的左端的集合中。很容易发现$\tau(\mathbf{v}(x_1,\cdots,x_n))\equiv\tilde{S}$，其中$x_1,\cdots,x_n$是按照一定顺序抽取的$S$的元素。

假设$\gamma:\mathbb{R}^K\to\mathbb{R}$是一个连续函数：$\gamma(\mathbf{v}=f(\tau(\mathbf{v}))),v\in\{0,1\}^K$，则
$$
|\gamma(\mathbf{v}(x_1,\cdots,x_n))-f(S)|=|f(\tau(\mathbf{v}(x_1,\cdots,x_n)))-f(S)|<\epsilon
$$
注意到：$\gamma(\mathbf{v}(x_1,\cdots,x_n))$可以被重写为：
$$
\begin{align*}
\gamma(\mathbf{v}(x_1,\cdots,x_n))
	&=\gamma(MAX(\mathbf{h}(x_1),\cdots,\mathbf{h}(x_n)))\\
	&=(\gamma\circ MAX)(\mathbf{h}(x_1),\cdots,\mathbf{h}(x_n))
\end{align*}
$$
显然，$\gamma\circ MAX$是一个对称函数。

### 定理2证明过程

我们定义$\mathbf{u}=MAX_{x_i\in S}\{h(x_i\}$为$f$的子网络，$f$用于映射一个$[0,1]^m$的点集合到一个$K$维度的向量。后续的定理说明输入集中小的扰动或者多余的噪声点很可能不会改变网络的输出。

### 定理2定义

假设$\mathbf{u}:\mathcal{X}\to\mathbb{R}^K$使得$\mathbf{u}=MAX_{x_i\in S}\{h(x_i)\}$和$f=\gamma\circ\mathbf{u}$。则
$$
\begin{align*}
	&(a)\;\forall S,\exists\mathcal{C}_S,\mathcal{N}_S\subseteq\mathcal{X},f(T)=f(S)如果\mathcal{C}_S\subseteq T\subseteq\mathcal{N}_S\\
	&(b)\;|\mathcal{C}_S|\leq K
\end{align*}
$$

### 定理2证明

显然，$\forall S\in\mathcal{X}$，$f(S)$是由$\mathbf{u}(S)$确定的。因此，我们仅需要证明：$\forall S,\exists\mathcal{C}_S,\mathcal{N}_S\subseteq\mathcal{X},f(T)=f(S)如果\mathcal{C}_S\subseteq T\subseteq\mathcal{N}_S$。

对于$\mathbf{u}$输出的第$j$个维度，存在至少一个$x_j\in\mathcal{X}$从而$h_j(x_j)=\mathbf{u}_j$，其中$h_j$是$h$的输出向量的第$j$个维度。将$\mathcal{C}_S$看作所有$x_j,j=1,\cdots,K$的并集，则$\mathcal{C}_S$满足上述的条件。

增加任何附加点$x$，这些点在不改变$\mathbf{u}$时，$\mathcal{C}_S$的所有维度满足$h(x)\leq\mathbf{u}(S)$。因此，增加所有这样的点的并集到$\mathcal{N}_S$中可以获得$\tau_S$。

## H.更多的可视化

### 分类可视化

![image-20211220112834515](images/机器学习/计算机视觉/三维处理/点云/点云特征/PointNet/image-20211220112834515.png)

图20：学习形状的全局特征的2D嵌入。我们使用t-SNE技术去可视化为ModelNet40测试分割数据集的形状中学习的全局形状特征。

我们使用t-SNE[^15]从PointNet中嵌入点云的全局签名（1024维）到2D空间中。图20展示了ModelNet40测试分割形状数据集的嵌入空间。相似的形状基于他们的语义类别聚集在一起。

### 分割可视化

我们在完整的CAD模型和模拟的Kinect局部扫描上展示了更多的分割结果。我们还可视化了失败的案例的错误分析。图21和图22展示了更多的基于完整的CAD模型和模拟的Kinect扫描上的分割结果。图23描述了一些失败的案例。请阅读错误分析的标题。

![image-20211220113436835](images/机器学习/计算机视觉/三维处理/点云/点云特征/PointNet/image-20211220113436835.png)

图21：PointNet在完整的CAD模型上的分割结果

![image-20211220113509395](images/机器学习/计算机视觉/三维处理/点云/点云特征/PointNet/image-20211220113509395.png)

图22：PointNet在模拟的Kinect扫描上的分割结果

![image-20211220113542355](images/机器学习/计算机视觉/三维处理/点云/点云特征/PointNet/image-20211220113542355.png)

图23：PointNet分割失败的案例。在本图中，我们总结了在分割应用中的六种共同的错误。预测与基准分割由第一和第二列给出，而不同的计算结果图展示在第三列。红点对应的给定点云的错误标签点。(a)描述了大多数的共同错误案例：边界上的点被错误标注了。在样本中，邻近桌子/椅子腿和顶之间的交集的点的标签预测是不准确的。然而，大多数分割算法受此类错误影响。(b)展示了奇特形状的错误。例如：本图中枝形吊灯和飞机在数据集中非常少见。(c)展示了小的部件可以被附近的大的部件覆盖。例如：飞机的喷气引擎（图中黄色的）受飞机的主体（绿色）和翅膀（紫色）影响被错误地分类。(d)展示了由于形状部件的内在模糊性引起的错误。例如：图中两个桌子的底部被分类为桌子腿和桌子基础（在[^29]中分类其他），而基准分割则完全相反。(e)描述了由局部扫描的不完整性引入的错误。对于本图中的两个帽子，几乎近半的点云都丢失了。(f)展示了当某些对象类别的训练数据较少导致无法覆盖全部变化时产生的错误案例。这里展示了这两种类别在整个数据集中分别是54个袋子和39个帽子。

### 场景语义解析可视化

![image-20211220142859920](images/机器学习/计算机视觉/三维处理/点云/点云特征/PointNet/image-20211220142859920.png)

图24：语义分割和对象检测的样例。第一行是输入点云，其中墙和天花板为了清晰而被隐藏。第二行和第三行是点上的语义分割的预测和基准，其中属于不同的语义区域点使用不同的颜色（椅子是红色，桌子是紫色，沙发是桔色，面板是灰色，书柜是绿色，地板是蓝色，窗口是蓝紫色，横梁是黄色，柱子是品红，门是黄褐色，杂物是黑色）。最后两行是使用包围盒的对象检测，其中预测盒来自于基于语义分割预测的连接的组件。

我们在图24中给出一个语义解析的可视化，我们基于两个办公室和一个会议室的语义分割和对象检测，展示了输入的点云、预测和评测基准。这个区域和房间在训练集中没有见过。

### 点函数可视化

我们的分类PointNet对每个点计算$K$维点特征（在可视化中$K=1024$），通过一个最大池化层聚集了所有的逐点局部特征到单个$K$维向量中，这个向量组成了全局形状描述符。

![image-20211220142039194](images/机器学习/计算机视觉/三维处理/点云/点云特征/PointNet/image-20211220142039194.png)

图19：点函数可视化。对于每个逐点函数$h$，我们对位于原点的直径为2的立方体中所有的点$p$计算了值$h(p)$，这个函数在训练PointNet时，从空间上覆盖了基于我们的输入形状规范化的单位球体。在本图中，我们可视化了所有的满足$h(p)>0.5$点$p$，这些点通过体素的亮度基于函数的值进行颜色编码。我们随机选择了15个点函数，并且可视化了它们的激活区域。

为了更深入地了解逐点函数$h$检测到了什么，我们对图19中较高的逐点函数值$f(p_i)$对应的点$p_i$进行可视化。这个可视化清晰地展示了不同的点函数学会了检测分散在整个空间的不同形状区域的点。
